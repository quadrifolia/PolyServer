#!/bin/bash
# server_setup.sh - Secure Debian 12 server setup for PolyServer applications
# Run as root after fresh Debian 12 (bookworm) instance creation

# Enhanced error handling
set -euo pipefail

# ========= Constants and Logging =========
readonly SCRIPT_NAME="secure-server-setup"
readonly LOG_FILE="/var/log/${SCRIPT_NAME}.log"
readonly BACKUP_DIR="/var/backups/server-setup"

# Ensure log directory exists
mkdir -p "$(dirname "$LOG_FILE")"
mkdir -p "$BACKUP_DIR"

# Logging functions
log_message() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] $*" | tee -a "$LOG_FILE"
}

log_error() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] ERROR: $*" | tee -a "$LOG_FILE" >&2
}

# Trap to handle script exit
cleanup() {
    local exit_code=$?
    if [ $exit_code -ne 0 ]; then
        log_error "Script failed with exit code $exit_code"
        log_message "Check $LOG_FILE for details"
    fi
}
trap cleanup EXIT

log_message "Starting server setup script"

# ========= Variables =========
USERNAME="{{DEPLOY_USER}}"                # Non-root user to create
HOSTNAME="{{HOSTNAME}}"                   # Server hostname
SSH_PORT="{{SSH_PORT}}"                   # Custom SSH port (more secure than default 22)
SSH_PUBLIC_KEY="{{SSH_PUBLIC_KEY}}"       # SSH public key for deploy user
BLOCK_DEVICE="/dev/sdb"                   # Block storage device (adjust if needed)
BACKUP_MOUNT="{{BACKUP_MOUNT}}"           # Backup mount point
LOGWATCH_EMAIL="{{LOGWATCH_EMAIL}}"       # Logwatch notification email

# Optional features configuration
NETDATA_ENABLED="{{NETDATA_ENABLED}}"     # Enable Netdata monitoring
DEPLOYMENT_MODE="{{DEPLOYMENT_MODE}}"     # Deployment mode (docker/standalone)

# SMTP Configuration from defaults.env
SMTP_ENABLED="{{SMTP_ENABLED}}"
SMTP_SERVER="{{SMTP_SERVER}}"
SMTP_PORT="{{SMTP_PORT}}"
SMTP_USERNAME="{{SMTP_USERNAME}}"
SMTP_PASSWORD="{{SMTP_PASSWORD}}"
SMTP_FROM_EMAIL="{{SMTP_FROM_EMAIL}}"
SMTP_USE_TLS="{{SMTP_USE_TLS}}"

# Check if running in Docker testing mode
if [ "$TESTING_MODE" = "true" ]; then
    echo "ðŸ³ Running in Docker testing mode - skipping some services that don't work in containers"
    DOCKER_MODE=true
else
    DOCKER_MODE=false
fi

# ========= Parameter Validation =========
log_message "ðŸ” Validating input parameters..."

# Validate SSH port
if ! validate_port "$SSH_PORT"; then
    log_error "Invalid SSH port configuration"
    exit 1
fi

# Validate SSH public key (if not in testing mode)
if [ "$TESTING_MODE" != "true" ] && [ -n "$SSH_PUBLIC_KEY" ]; then
    if ! validate_ssh_key "$SSH_PUBLIC_KEY"; then
        log_error "Invalid SSH public key configuration"
        exit 1
    fi
elif [ "$TESTING_MODE" != "true" ]; then
    log_error "SSH public key is required for security"
    exit 1
fi

# Validate email addresses
if [ -n "$LOGWATCH_EMAIL" ] && [ "$LOGWATCH_EMAIL" != "{{LOGWATCH_EMAIL}}" ]; then
    if ! validate_email "$LOGWATCH_EMAIL"; then
        log_error "Invalid logwatch email configuration"
        exit 1
    fi
fi

if [ "$SMTP_ENABLED" = "true" ] && [ -n "$SMTP_FROM_EMAIL" ] && [ "$SMTP_FROM_EMAIL" != "{{SMTP_FROM_EMAIL}}" ]; then
    if ! validate_email "$SMTP_FROM_EMAIL"; then
        log_error "Invalid SMTP from email configuration"
        exit 1
    fi
fi

# Validate hostname
if [ -z "$HOSTNAME" ] || [ "$HOSTNAME" = "{{HOSTNAME}}" ]; then
    log_error "Hostname must be configured"
    exit 1
fi

# Validate username
if [ -z "$USERNAME" ] || [ "$USERNAME" = "{{DEPLOY_USER}}" ]; then
    log_error "Deploy user must be configured"
    exit 1
fi

log_message "âœ… Parameter validation completed successfully"

# Helper function for systemctl commands in Docker mode
docker_systemctl() {
    if [ "$DOCKER_MODE" = "false" ]; then
        systemctl "$@"
    else
        echo "ðŸ³ Docker mode: skipping systemctl $*"
        return 0
    fi
}

# Package management functions
wait_for_dpkg_lock() {
    local timeout=300  # 5 minutes timeout
    local count=0
    
    log_message "Checking for package management locks..."
    
    while fuser /var/lib/dpkg/lock-frontend >/dev/null 2>&1 || fuser /var/cache/apt/archives/lock >/dev/null 2>&1; do
        if [ $count -ge $timeout ]; then
            log_error "Timeout waiting for package management lock - continuing anyway"
            break
        fi
        
        if [ $((count % 10)) -eq 0 ]; then
            log_message "Waiting for package management to complete... ($count/$timeout seconds)"
            # Show what process is holding the lock
            pgrep -af "(apt|dpkg|unattended)" || true
        fi
        
        sleep 1
        count=$((count + 1))
    done
    
    if [ $count -gt 0 ]; then
        log_message "Package management lock released after $count seconds"
    fi
}

# Enhanced package management with lock handling
safe_apt_update() {
    wait_for_dpkg_lock
    # Kill any running apt/dpkg processes
    pkill -f apt-get 2>/dev/null || true
    pkill -f dpkg 2>/dev/null || true
    sleep 2
    # Configure dpkg properly before update
    dpkg --configure -a
    apt-get update
}

safe_apt_install() {
    wait_for_dpkg_lock
    apt-get install -y "$@"
}

# Service management functions
start_service_with_retry() {
    local service="$1"
    local max_attempts=3
    local wait_time=5
    
    log_message "Starting service: $service"
    
    # Skip in Docker mode for services that don't work in containers
    if [ "$DOCKER_MODE" = "true" ]; then
        case "$service" in
            ufw|fail2ban|clamav-daemon|suricata)
                log_message "ðŸ³ Docker mode: skipping service $service"
                return 0
                ;;
        esac
    fi
    
    for attempt in $(seq 1 $max_attempts); do
        if docker_systemctl start "$service"; then
            sleep "$wait_time"
            if docker_systemctl is-active --quiet "$service"; then
                log_message "âœ… Service $service started successfully (attempt $attempt)"
                return 0
            fi
        fi
        log_message "âš ï¸ Service $service start attempt $attempt failed, retrying..."
        sleep $((wait_time * attempt))
    done
    
    log_error "âŒ Failed to start service $service after $max_attempts attempts"
    return 1
}

enable_and_start_service() {
    local service="$1"
    log_message "Enabling and starting service: $service"
    
    if [ "$DOCKER_MODE" = "true" ]; then
        case "$service" in
            ufw|fail2ban|clamav-daemon|suricata)
                log_message "ðŸ³ Docker mode: skipping service $service"
                return 0
                ;;
        esac
    fi
    
    docker_systemctl enable "$service"
    start_service_with_retry "$service"
}

# Input validation functions
validate_email() {
    local email="$1"
    if [[ "$email" =~ ^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$ ]]; then
        return 0
    else
        log_error "Invalid email format: $email"
        return 1
    fi
}

validate_ssh_key() {
    local key="$1"
    local temp_key_file
    
    if [ -z "$key" ]; then
        log_error "SSH key cannot be empty"
        return 1
    fi
    
    temp_key_file=$(mktemp)
    trap 'rm -f "$temp_key_file"' RETURN
    
    echo "$key" > "$temp_key_file"
    
    if ssh-keygen -l -f "$temp_key_file" >/dev/null 2>&1; then
        local key_bits
        key_bits=$(ssh-keygen -l -f "$temp_key_file" | awk '{print $1}')
        
        if [[ "$key" =~ ^ssh-ed25519 ]] || [ "$key_bits" -ge 2048 ]; then
            log_message "âœ… SSH key validation successful"
            return 0
        else
            log_error "SSH key too weak (minimum 2048 bits for RSA, or use Ed25519)"
            return 1
        fi
    else
        log_error "Invalid SSH key format"
        return 1
    fi
}

validate_port() {
    local port="$1"
    if [[ "$port" =~ ^[0-9]+$ ]] && [ "$port" -ge 1 ] && [ "$port" -le 65535 ]; then
        return 0
    else
        log_error "Invalid port number: $port (must be 1-65535)"
        return 1
    fi
}

# Configuration validation framework
validate_critical_configs() {
    local errors=0
    
    log_message "ðŸ” Validating critical configurations..."
    
    # SSH configuration validation
    log_message "Checking SSH configuration..."
    if [ "$DOCKER_MODE" = "false" ]; then
        if ! timeout 10 sshd -t 2>/dev/null; then
            log_error "SSH configuration validation failed"
            errors=$((errors + 1))
        else
            log_message "âœ… SSH configuration is valid"
        fi
    fi
    
    # UFW configuration validation  
    log_message "Checking UFW configuration..."
    if [ "$DOCKER_MODE" = "false" ]; then
        if ! timeout 10 ufw status >/dev/null 2>&1; then
            log_error "UFW configuration validation failed"
            errors=$((errors + 1))
        else
            log_message "âœ… UFW configuration is valid"
        fi
    fi
    
    # Fail2ban configuration validation
    log_message "Checking Fail2ban configuration..."
    if [ "$DOCKER_MODE" = "false" ]; then
        if ! timeout 15 fail2ban-client -t >/dev/null 2>&1; then
            log_message "âš ï¸ Fail2ban configuration validation timed out or failed"
            if ! docker_systemctl is-active --quiet fail2ban; then
                errors=$((errors + 1))
            fi
        else
            log_message "âœ… Fail2ban configuration is valid"
        fi
    fi
    
    # Nginx configuration validation (if nginx is installed)
    if command -v nginx >/dev/null 2>&1; then
        log_message "Checking Nginx configuration..."
        if ! nginx -t >/dev/null 2>&1; then
            log_error "Nginx configuration validation failed"
            errors=$((errors + 1))
        else
            log_message "âœ… Nginx configuration is valid"
        fi
    fi
    
    return $errors
}

# Backup and rollback system
create_rollback_point() {
    local checkpoint="$1"
    local timestamp
    timestamp=$(date +%s)
    local rollback_file="${BACKUP_DIR}/rollback-${checkpoint}-${timestamp}.tar.gz"
    
    log_message "ðŸ“¦ Creating rollback point: $checkpoint"
    
    # Create encrypted backup if gpg is available
    if command -v gpg >/dev/null 2>&1; then
        local encrypted_file="${rollback_file}.gpg"
        tar -czf - \
            /etc/ssh \
            /etc/ufw \
            /etc/fail2ban \
            /etc/nginx \
            /etc/postfix \
            2>/dev/null | gpg --symmetric --cipher-algo AES256 --compress-algo 1 --batch --yes --passphrase "server-backup-$(hostname)-$timestamp" > "$encrypted_file" 2>/dev/null
        
        if [ -f "$encrypted_file" ]; then
            echo "$encrypted_file" > "${BACKUP_DIR}/latest-rollback"
            log_message "âœ… Encrypted rollback point created: $checkpoint"
        fi
    else
        # Fallback to unencrypted backup
        tar -czf "$rollback_file" \
            /etc/ssh \
            /etc/ufw \
            /etc/fail2ban \
            /etc/nginx \
            /etc/postfix \
            2>/dev/null || log_message "âš ï¸ Some files missing during rollback creation"
        echo "$rollback_file" > "${BACKUP_DIR}/latest-rollback"
        log_message "âœ… Rollback point created: $checkpoint"
    fi
}

# ========= Basic server hardening =========
log_message "===== 1. Updating system packages ====="
safe_apt_update && apt-get upgrade -y

echo "===== 2. Setting hostname ====="
if [ "$DOCKER_MODE" = "false" ]; then
    hostnamectl set-hostname "$HOSTNAME"
else
    echo "ðŸ³ Skipping hostname setup in Docker mode"
fi

echo "===== 2.1 Setting root password for emergency access ====="
if [ "$DOCKER_MODE" = "false" ]; then
    echo "Setting a secure root password for console/emergency access..."
    echo "This is important for recovery scenarios when SSH key access fails."
    echo ""
    echo "Please set a strong root password:"
    passwd root
    echo "âœ… Root password configured for emergency console access"
    echo ""
else
    echo "ðŸ³ Skipping root password setup in Docker mode"
fi

echo "===== 3. Creating non-root user ====="
if ! id "$USERNAME" &>/dev/null; then
  if [ "$DOCKER_MODE" = "true" ]; then
    # Non-interactive user creation for Docker
    useradd -m -s /bin/bash "$USERNAME"
    echo "$USERNAME:$USERNAME" | chpasswd
  else
    # Determine if we should create user with or without password
    if [ -n "$SSH_PUBLIC_KEY" ]; then
      echo "SSH public key provided - creating user without password prompt"
      useradd -m -s /bin/bash "$USERNAME"
      # Generate a random password and immediately expire it to force key-only auth
      TEMP_PASS=$(openssl rand -base64 32)
      echo "$USERNAME:$TEMP_PASS" | chpasswd
      passwd -e "$USERNAME"
    else
      echo "No SSH public key provided - user will be prompted to set password"
      adduser --gecos "" "$USERNAME"
    fi
  fi
  usermod -aG sudo "$USERNAME"
  
  # Create SSH directory for the new user
  mkdir -p /home/$USERNAME/.ssh
  chmod 700 /home/$USERNAME/.ssh
  chown $USERNAME:$USERNAME /home/$USERNAME/.ssh
  
  # Set up SSH key if provided
  if [ -n "$SSH_PUBLIC_KEY" ]; then
    echo "Setting up SSH public key for $USERNAME"
    echo "$SSH_PUBLIC_KEY" > /home/$USERNAME/.ssh/authorized_keys
    chmod 600 /home/$USERNAME/.ssh/authorized_keys
    chown $USERNAME:$USERNAME /home/$USERNAME/.ssh/authorized_keys
    echo "SSH key configured successfully"
  else
    # Try to copy existing keys as fallback
    if [ -f ~/.ssh/authorized_keys ]; then
      echo "Copying existing SSH keys from root user"
      cp ~/.ssh/authorized_keys /home/$USERNAME/.ssh/
      chmod 600 /home/$USERNAME/.ssh/authorized_keys
      chown $USERNAME:$USERNAME /home/$USERNAME/.ssh/authorized_keys
    else
      echo "No SSH keys available - password authentication will be enabled"
    fi
  fi
fi

echo "===== 4. Securing SSH ====="
if [ "$DOCKER_MODE" = "false" ]; then
    # Backup original SSH config
    cp /etc/ssh/sshd_config /etc/ssh/sshd_config.bak
    
    # Determine password authentication setting based on key availability
    if [ -n "$SSH_PUBLIC_KEY" ] || [ -f /home/$USERNAME/.ssh/authorized_keys ]; then
        PASSWORD_AUTH="no"
        echo "SSH keys are available - disabling password authentication"
    else
        PASSWORD_AUTH="yes"
        echo "No SSH keys available - enabling password authentication for initial setup"
        echo "WARNING: Remember to add SSH keys and disable password auth later!"
    fi
    
    # Configure SSH
    cat > /etc/ssh/sshd_config << EOF
# Secure SSH Configuration
Port $SSH_PORT
Protocol 2
HostKey /etc/ssh/ssh_host_ed25519_key
HostKey /etc/ssh/ssh_host_rsa_key

# Authentication
LoginGraceTime 30
PermitRootLogin no
StrictModes yes
MaxAuthTries 3
MaxSessions 5
PubkeyAuthentication yes
PasswordAuthentication $PASSWORD_AUTH
PermitEmptyPasswords no
ChallengeResponseAuthentication no
UsePAM yes

# Forwarding / Tunneling
X11Forwarding no
AllowTcpForwarding no
AllowAgentForwarding no
PermitTunnel no

# Features
PrintMotd no
AcceptEnv LANG LC_*
Subsystem sftp /usr/lib/openssh/sftp-server

# Security
IgnoreRhosts yes
HostbasedAuthentication no
KexAlgorithms curve25519-sha256@libssh.org,diffie-hellman-group16-sha512,diffie-hellman-group18-sha512
Ciphers chacha20-poly1305@openssh.com,aes256-gcm@openssh.com,aes128-gcm@openssh.com
MACs hmac-sha2-512-etm@openssh.com,hmac-sha2-256-etm@openssh.com

# Allow users
AllowUsers $USERNAME
EOF
else
    echo "ðŸ³ Skipping SSH configuration in Docker mode"
fi

# Don't restart SSH yet - will do at the end to avoid disconnecting mid-setup

echo "===== 5. Setting up firewall ====="
if [ "$DOCKER_MODE" = "false" ]; then
    apt install -y ufw
    # Set default policies - deny incoming, allow outgoing
    ufw default deny incoming
    ufw default allow outgoing
    # Allow only necessary ports
    ufw allow $SSH_PORT/tcp comment "SSH"
    ufw allow 80/tcp comment "HTTP"
    ufw allow 443/tcp comment "HTTPS"
    # Application direct ports removed for security (using Nginx proxy instead)
    # Enable the firewall non-interactively
    echo "y" | ufw enable
    # Show the status of the firewall
    ufw status verbose
else
    echo "ðŸ³ Skipping firewall setup in Docker mode"
fi

echo "===== 6. Installing security packages ====="
if [ "$DOCKER_MODE" = "true" ]; then
    # Docker-compatible package list (excluding packages that don't work in containers)
    apt-get install -y unattended-upgrades apt-listchanges \
        gnupg-agent \
        logwatch clamav clamav-daemon lm-sensors \
        rkhunter chkrootkit apparmor apparmor-utils \
        nginx-extras git awscli
else
    # Full package list for production servers
    apt-get install -y fail2ban unattended-upgrades apt-listchanges \
        gnupg-agent \
        logwatch clamav clamav-daemon lm-sensors hddtemp \
        rkhunter chkrootkit unbound apparmor apparmor-utils \
        nginx-extras suricata git awscli
fi

echo "===== 6.0.1 Installing CPU microcode updates ====="

# Check if running in a virtual environment
VIRT_TYPE=""
if [ -f /proc/cpuinfo ] && grep -q "hypervisor" /proc/cpuinfo; then
    VIRT_TYPE="hypervisor"
elif systemd-detect-virt &>/dev/null; then
    VIRT_TYPE=$(systemd-detect-virt)
elif [ -f /sys/hypervisor/type ]; then
    VIRT_TYPE=$(cat /sys/hypervisor/type)
fi

# Detect CPU vendor and install appropriate microcode updates
CPU_VENDOR=$(grep vendor_id /proc/cpuinfo | head -1 | awk '{print $3}')
echo "Detected CPU vendor: $CPU_VENDOR"

if [ -n "$VIRT_TYPE" ] && [ "$VIRT_TYPE" != "none" ]; then
    echo "ðŸ” Virtualization detected: $VIRT_TYPE"
    echo "âš ï¸  Note: In virtualized environments (OVH, Hetzner, AWS, etc.):"
    echo "   - Microcode updates are typically managed by the host/hypervisor"
    echo "   - VM-level microcode installation may not affect actual CPU vulnerability mitigations"
    echo "   - Contact your hosting provider for physical host microcode status"
    echo ""
    echo "Installing microcode package anyway for completeness..."
fi

if [ "$CPU_VENDOR" = "AuthenticAMD" ]; then
    echo "AMD processor detected - installing AMD microcode updates..."
    
    # Check if non-free-firmware repository is available
    if ! apt-cache search amd64-microcode | grep -q amd64-microcode; then
        echo "Adding non-free-firmware repository for AMD microcode..."
        
        # Check if we're using the new sources.list format (Debian 12+)
        if [ -f /etc/apt/sources.list.d/debian.sources ]; then
            # Update existing debian.sources file to include non-free-firmware
            if ! grep -q "non-free-firmware" /etc/apt/sources.list.d/debian.sources; then
                echo "Updating debian.sources to include non-free-firmware..."
                sed -i 's/Components: main/Components: main non-free-firmware/' /etc/apt/sources.list.d/debian.sources
                apt-get update
            fi
        else
            # Add to traditional sources.list
            if ! grep -q "non-free-firmware" /etc/apt/sources.list; then
                echo "Adding non-free-firmware to sources.list..."
                sed -i 's/main$/main non-free-firmware/' /etc/apt/sources.list
                apt-get update
            fi
        fi
    fi
    
    # Install AMD microcode
    if apt-cache search amd64-microcode | grep -q amd64-microcode; then
        apt-get install -y amd64-microcode
        echo "âœ… AMD microcode installed successfully"
        echo "âš ï¸  Microcode will be active after next reboot"
    else
        echo "âš ï¸  AMD microcode package not available in repositories"
    fi
    
elif [ "$CPU_VENDOR" = "GenuineIntel" ]; then
    echo "Intel processor detected - installing Intel microcode updates..."
    apt-get install -y intel-microcode
    echo "âœ… Intel microcode installed successfully"
    echo "âš ï¸  Microcode will be active after next reboot"
    
else
    echo "Unknown or unsupported CPU vendor: $CPU_VENDOR"
    echo "Skipping microcode installation"
fi

# Update initramfs to include microcode and check for kernel updates
echo "===== 6.0.2 Updating system with microcode integration ====="

# Update initramfs to ensure microcode is loaded
echo "Updating initramfs to include microcode..."
update-initramfs -u -k all

# Check if kernel update is available and recommend it
echo "Checking for kernel updates..."
CURRENT_KERNEL=$(uname -r)
echo "Current kernel: $CURRENT_KERNEL"

# Check for available kernel updates
if apt list --upgradable 2>/dev/null | grep -q linux-image; then
    echo "âš ï¸  Kernel updates available:"
    apt list --upgradable 2>/dev/null | grep linux-image
    echo ""
    echo "ðŸ’¡ Kernel update recommendation:"
    echo "   Run: apt update && apt upgrade linux-image-*"
    echo "   Then reboot to activate microcode and kernel updates"
    KERNEL_UPDATE_NEEDED=true
else
    echo "âœ… Kernel is up to date"
    KERNEL_UPDATE_NEEDED=false
fi

# Check for backports kernel if available (often has better hardware support)
if apt-cache search linux-image | grep -q backports; then
    echo ""
    echo "ðŸ’¡ Backports kernel available for better hardware support:"
    apt-cache search linux-image | grep backports | head -3
    echo "   Consider: apt install -t bookworm-backports linux-image-amd64"
fi

# Show current CPU vulnerabilities status
echo ""
echo "Current CPU vulnerability status:"
if [ -d /sys/devices/system/cpu/vulnerabilities ]; then
    for vuln in /sys/devices/system/cpu/vulnerabilities/*; do
        vuln_name=$(basename "$vuln")
        vuln_status=$(cat "$vuln")
        printf "  %-25s %s\n" "$vuln_name:" "$vuln_status"
    done
else
    echo "  CPU vulnerability information not available"
fi

# Check if microcode is properly loaded
echo ""
echo "Microcode status:"
if dmesg | grep -i microcode | tail -5 | grep -q "updated"; then
    echo "âœ… Microcode updates detected in dmesg"
    dmesg | grep -i microcode | tail -2
else
    if [ -n "$VIRT_TYPE" ] && [ "$VIRT_TYPE" != "none" ]; then
        echo "â„¹ï¸  No microcode updates in dmesg (expected in virtualized environment)"
        echo "   Microcode management is handled by the hypervisor/host system"
    else
        echo "âš ï¸  Microcode updates not visible in dmesg (may require reboot)"
    fi
fi

# Check initramfs for microcode
if [ -f "/boot/initrd.img-$(uname -r)" ]; then
    if lsinitramfs "/boot/initrd.img-$(uname -r)" 2>/dev/null | grep -q microcode; then
        echo "âœ… Microcode files present in initramfs"
        lsinitramfs "/boot/initrd.img-$(uname -r)" 2>/dev/null | grep microcode | head -3
    else
        echo "âš ï¸  No microcode files found in initramfs"
    fi
fi
echo ""

echo "===== 6.1 Installing incident response and monitoring tools ====="
# System monitoring
apt-get install -y htop iotop sysstat atop bmon

# Network monitoring
apt-get install -y iftop nethogs tcpdump ethtool iperf3 netcat-openbsd

# Network diagnostics
apt-get install -y mtr-tiny arp-scan dnsutils net-tools traceroute whois

# File integrity
apt-get install -y debsums aide

# Configure lm-sensors with enhanced detection and logwatch integration
echo "===== 6.1.1 Configuring hardware sensors with enhanced detection ====="

# Enhanced sensor detection and configuration
echo "Running comprehensive sensor detection..."

# Run sensors-detect automatically with safe defaults
if command -v sensors-detect >/dev/null 2>&1; then
    echo "Running sensors-detect with safe automatic detection..."
    # Run sensors-detect with automatic yes to safe drivers only
    echo -e "y\ny\ny\ny\ny\nn" | sensors-detect --auto 2>/dev/null || true
    
    # Load detected modules
    if [ -f /etc/modules ]; then
        echo "Loading detected sensor modules..."
        systemctl restart systemd-modules-load 2>/dev/null || true
        # Try manual module loading for common sensors
        for module in coretemp k10temp it87 w83627ehf nct6775; do
            modprobe $module 2>/dev/null || true
        done
    fi
fi

# Re-check sensors after detection
if command -v sensors >/dev/null 2>&1; then
    # Wait for modules to initialize
    sleep 2
    
    # Check if sensors are now detected
    if sensors 2>/dev/null | grep -q "Â°C\|Â°F\|RPM\|V\|W"; then
        echo "âœ… Hardware sensors detected after module loading"
        
        # Show detected sensors
        echo "Detected sensors:"
        sensors 2>/dev/null | grep -E "Core|temp|fan|Â°C|Â°F|RPM|V|W" | head -10
        
        # Enable lm-sensors service
        systemctl enable lm-sensors 2>/dev/null || true
        systemctl start lm-sensors 2>/dev/null || true
        
        # Configure sensors for logwatch
        echo "Configuring sensors for logwatch integration..."
        mkdir -p /etc/logwatch/conf/services
        
        # Create sensors service configuration for logwatch
        cat > /etc/logwatch/conf/services/sensors.conf << 'EOF'
# Sensors monitoring for logwatch
Title = "Hardware Sensors"
LogFile = sensors
*OnlyService = sensors
*RemoveHeaders = Yes
EOF
        
        # Create sensor logging script for logwatch
        mkdir -p /var/log/sensors
        cat > /usr/local/bin/log-sensors << 'EOF'
#!/bin/bash
# Log sensor data for logwatch analysis
LOGFILE="/var/log/sensors/sensors.log"
DATE=$(date '+%Y-%m-%d %H:%M:%S')

# Ensure log directory exists
mkdir -p /var/log/sensors

# Log current sensor readings
echo "[$DATE] Sensor readings:" >> "$LOGFILE"
sensors >> "$LOGFILE" 2>/dev/null
echo "" >> "$LOGFILE"

# Check for critical temperatures and log alerts
if sensors 2>/dev/null | grep -E "CRITICAL|ALARM" | grep -v "+0.0"; then
    echo "[$DATE] CRITICAL: Sensor alerts detected!" >> "$LOGFILE"
    sensors 2>/dev/null | grep -E "CRITICAL|ALARM" >> "$LOGFILE"
    echo "" >> "$LOGFILE"
fi

# Rotate log if it gets too large (keep last 1000 lines)
if [ -f "$LOGFILE" ] && [ $(wc -l < "$LOGFILE") -gt 1000 ]; then
    tail -n 500 "$LOGFILE" > "${LOGFILE}.tmp" && mv "${LOGFILE}.tmp" "$LOGFILE"
fi
EOF
        
        chmod +x /usr/local/bin/log-sensors
        
        # Add sensor logging to cron (every 10 minutes)
        echo "*/10 * * * * root /usr/local/bin/log-sensors" >> /etc/crontab
        
        # Update logwatch configuration to include sensors
        if [ -f /etc/logwatch/conf/logwatch.conf ]; then
            # Check if sensors service already included
            if ! grep -q "sensors" /etc/logwatch/conf/logwatch.conf; then
                echo "Service = sensors" >> /etc/logwatch/conf/logwatch.conf
                echo "âœ… Sensors added to logwatch daily reports"
            fi
        fi
        
        # Create logrotate configuration for sensor logs
        cat > /etc/logrotate.d/sensors << EOF
/var/log/sensors/*.log {
    weekly
    rotate 4
    compress
    delaycompress
    missingok
    notifempty
    create 644 root root
}
EOF
        
        echo "âœ… Hardware sensors configured with logwatch integration"
        echo "   â€¢ Sensor data logged every 10 minutes"
        echo "   â€¢ Critical temperature alerts logged"
        echo "   â€¢ Included in daily logwatch reports"
        
        # Run initial sensor logging
        /usr/local/bin/log-sensors
        
    else
        echo "No hardware sensors detected even after module detection"
        echo "This is normal for virtual machines and cloud instances"
        
        # Disable sensors service and suppress warnings
        systemctl disable lm-sensors 2>/dev/null || true
        systemctl mask lm-sensors 2>/dev/null || true
        
        # Create empty sensors config to prevent startup warnings
        mkdir -p /etc/sensors.d
        cat > /etc/sensors.d/no-sensors.conf << 'EOF'
# No hardware sensors configuration
# This file prevents sensors warnings on systems without hardware monitoring
EOF
        echo "âœ… Sensors warnings suppressed for VPS/cloud environment"
        
        # Create fake sensor log for logwatch (prevents errors)
        mkdir -p /var/log/sensors
        cat > /var/log/sensors/sensors.log << EOF
# No hardware sensors available on this system
# This is normal for virtual machines and cloud instances
EOF
        
        # Still add sensors to logwatch but with a note about no sensors
        if [ -f /etc/logwatch/conf/logwatch.conf ]; then
            if ! grep -q "sensors" /etc/logwatch/conf/logwatch.conf; then
                echo "Service = sensors" >> /etc/logwatch/conf/logwatch.conf
                echo "âœ… Sensors service added to logwatch (will show 'no sensors' message)"
            fi
        fi
    fi
else
    echo "Sensors command not available - installing lm-sensors package"
    apt-get update && apt-get install -y lm-sensors
    echo "âœ… lm-sensors installed - rerun script or manually run sensors-detect"
fi

# Log monitoring
apt-get install -y logcheck logcheck-database

# Audit framework
apt-get install -y auditd audispd-plugins

# Enhanced shell environment
echo "===== 6.2 Installing enhanced shell environment ====="
apt-get install -y zsh vim git curl locales

# Configure locale to avoid character encoding issues
sed -i '/en_US.UTF-8/s/^# //g' /etc/locale.gen
locale-gen

# Install Oh My Zsh for deploy user
if id "$USERNAME" &>/dev/null; then
    echo "Installing Oh My Zsh for $USERNAME..."
    sudo -u $USERNAME sh -c "$(curl -fsSL https://raw.github.com/ohmyzsh/ohmyzsh/master/tools/install.sh)" "" --unattended
    
    # Configure Oh My Zsh with useful plugins
    sudo -u $USERNAME sed -i 's/plugins=(git)/plugins=(git docker sudo systemd colored-man-pages)/' /home/$USERNAME/.zshrc
fi

# Install Oh My Zsh for root user as well
echo "Installing Oh My Zsh for root..."
sh -c "$(curl -fsSL https://raw.github.com/ohmyzsh/ohmyzsh/master/tools/install.sh)" "" --unattended
sed -i 's/plugins=(git)/plugins=(git docker sudo systemd colored-man-pages)/' /root/.zshrc

# Configure vim globally with enhanced settings for server administration
cat > /etc/vim/vimrc.local << EOF
" PolyServer Enhanced Vim Configuration
" Optimized for server administration and configuration editing

" Basic settings
syntax on
set number
set ruler
set showcmd
set showmatch
set incsearch
set hlsearch
set ignorecase
set smartcase

" Indentation and formatting
set tabstop=4
set shiftwidth=4
set expandtab
set autoindent
set smartindent

" Interface enhancements
set laststatus=2
set wildmenu
set wildmode=longest:full,full
set scrolloff=3
set sidescrolloff=5

" File handling
set nobackup
set noswapfile
set autoread
set encoding=utf-8

" Mouse and clipboard (disabled for server use)
set mouse=
set clipboard=

" Security (disable modelines for security)
set nomodeline
set modelines=0

" Color scheme
colorscheme default

" Status line
set statusline=%F%m%r%h%w\ [FORMAT=%{&ff}]\ [TYPE=%Y]\ [POS=%l,%v][%p%%]\ %{strftime(\"%d/%m/%y\ -\ %H:%M\")}

" Useful key mappings for server configuration files
" Clear search highlighting
nnoremap <silent> <C-l> :nohlsearch<CR><C-l>

" Quick save
nnoremap <C-s> :w<CR>
inoremap <C-s> <Esc>:w<CR>a

" File type specific settings
augroup ServerConfigs
    autocmd!
    " Nginx configuration files
    autocmd BufRead,BufNewFile *.conf setlocal filetype=nginx
    autocmd BufRead,BufNewFile nginx.conf setlocal filetype=nginx
    autocmd BufRead,BufNewFile */nginx/* setlocal filetype=nginx
    
    " Shell scripts
    autocmd BufRead,BufNewFile *.sh setlocal filetype=sh
    autocmd FileType sh setlocal tabstop=2 shiftwidth=2
    
    " YAML files (Docker Compose, etc.)
    autocmd BufRead,BufNewFile *.yml,*.yaml setlocal filetype=yaml
    autocmd FileType yaml setlocal tabstop=2 shiftwidth=2
    
    " JSON files
    autocmd BufRead,BufNewFile *.json setlocal filetype=json
    autocmd FileType json setlocal tabstop=2 shiftwidth=2
    
    " Environment files
    autocmd BufRead,BufNewFile .env*,*.env setlocal filetype=sh
    
    " Log files (read-only, no line numbers for better readability)
    autocmd BufRead,BufNewFile *.log setlocal readonly nonumber nowrap
augroup END

" Highlight trailing whitespace
highlight ExtraWhitespace ctermbg=red guibg=red
match ExtraWhitespace /\s\+$/

" Show tabs and trailing spaces
set listchars=tab:>-,trail:Â·,extends:>,precedes:<
set list
EOF

# Source the vim config in the main vimrc
echo 'source /etc/vim/vimrc.local' >> /etc/vim/vimrc

# Create a vim configuration info file for reference
cat > /etc/vim/polyserver-vim-help.txt << EOF
PolyServer Vim Configuration - Quick Reference
=============================================

Key Features:
- Syntax highlighting enabled
- Line numbers and ruler
- Smart indentation (4 spaces, expanded tabs)
- Case-insensitive search with smart case
- No mouse support (server-optimized)
- No backup/swap files for cleaner filesystem
- Security hardened (modelines disabled)

File Type Support:
- Nginx configuration files (.conf, nginx.conf)
- Shell scripts (.sh) - 2-space indentation
- YAML files (.yml, .yaml) - 2-space indentation  
- JSON files (.json) - 2-space indentation
- Environment files (.env, .env.*) 
- Log files - read-only mode, no line numbers

Quick Keys:
- Ctrl+L: Clear search highlighting
- Ctrl+S: Quick save

Visual Aids:
- Trailing whitespace highlighted in red
- Tabs and spaces visible
- Status line shows file info and timestamp

To view this help: cat /etc/vim/polyserver-vim-help.txt
EOF

echo "Enhanced vim configuration installed with server administration optimizations"

# Create global aliases for all users
cat > /etc/profile.d/polyserver-aliases.sh << EOF
#!/bin/bash
alias ll="ls -la"
alias la="ls -A"
alias l="ls -CF"
alias grep="grep --color=auto"
alias fgrep="fgrep --color=auto"
alias egrep="egrep --color=auto"
EOF
chmod +x /etc/profile.d/polyserver-aliases.sh

# Create executable commands for non-interactive shells
cat > /usr/local/bin/ll << EOF
#!/bin/bash
ls -la "\$@"
EOF
chmod +x /usr/local/bin/ll

cat > /usr/local/bin/la << EOF
#!/bin/bash
ls -A "\$@"
EOF
chmod +x /usr/local/bin/la

# Add aliases to both users' shell configs
if id "$USERNAME" &>/dev/null; then
    echo 'source /etc/profile.d/polyserver-aliases.sh 2>/dev/null || true' >> /home/$USERNAME/.zshrc
fi
echo 'source /etc/profile.d/polyserver-aliases.sh 2>/dev/null || true' >> /root/.zshrc

echo "Enhanced shell environment configured with zsh, Oh My Zsh, vim enhancements, and useful aliases"

# ========= Configure Email System =========
echo "===== 6.5 Configuring Email System ====="

if [ "$SMTP_ENABLED" = "true" ]; then
    echo "SMTP configuration enabled - using external SMTP for reliable email delivery"
    echo "SMTP Server: $SMTP_SERVER:$SMTP_PORT"
    echo "From: $SMTP_FROM_EMAIL -> To: $LOGWATCH_EMAIL"
else
    echo "SMTP disabled - using local mail delivery (emails stored locally only)"
fi

# Pre-configure postfix for mail delivery
echo "postfix postfix/main_mailer_type string 'Internet Site'" | debconf-set-selections
echo "postfix postfix/mailname string $(hostname -f)" | debconf-set-selections

# Install mail system
apt-get install -y mailutils postfix

# Stop postfix for configuration
systemctl stop postfix 2>/dev/null || true

if [ "$SMTP_ENABLED" = "true" ]; then
    echo "Configuring external SMTP for reliable email delivery..."
    
    # Install SASL packages for SMTP authentication
    apt-get install -y libsasl2-modules
    
    # Configure postfix for external SMTP relay
    postconf -e "relayhost = [$SMTP_SERVER]:$SMTP_PORT"
    postconf -e "smtp_use_tls = yes"
    postconf -e "smtp_sasl_auth_enable = yes"
    postconf -e "smtp_sasl_security_options = noanonymous"
    postconf -e "smtp_sasl_password_maps = hash:/etc/postfix/sasl_passwd"
    postconf -e "smtp_tls_security_level = encrypt"
    postconf -e "smtp_tls_note_starttls_offer = yes"
    postconf -e "smtp_tls_CAfile = /etc/ssl/certs/ca-certificates.crt"
    
    # Disable SMTPUTF8 for compatibility with Amazon SES
    postconf -e "smtputf8_enable = no"
    
    # Critical: Configure postfix to send ALL mail via SMTP relay (satellite mode)
    postconf -e "mydestination ="
    postconf -e "myorigin = \$myhostname"
    postconf -e "inet_interfaces = loopback-only"
    postconf -e "mynetworks = 127.0.0.0/8"
    postconf -e "local_transport = error:local delivery is disabled"
    postconf -e "alias_maps ="
    postconf -e "alias_database ="
    postconf -e "local_recipient_maps ="
    postconf -e "mailbox_command ="
    postconf -e "mailbox_transport ="
    postconf -e "home_mailbox ="
    postconf -e "mail_spool_directory ="
    postconf -e "virtual_alias_maps ="
    postconf -e "virtual_mailbox_maps ="
    postconf -e "transport_maps ="
    
    # FORCE all mail to go via SMTP - override any local delivery attempts
    postconf -e "default_transport = smtp:[$SMTP_SERVER]:$SMTP_PORT"
    postconf -e "fallback_transport = smtp:[$SMTP_SERVER]:$SMTP_PORT"
    
    # Configure sender rewriting to use the SMTP from address
    postconf -e "sender_canonical_maps = regexp:/etc/postfix/sender_canonical"
    postconf -e "smtp_header_checks = regexp:/etc/postfix/smtp_header_checks"
    
    # Create recipient canonical map to redirect all local recipients
    cat > /etc/postfix/recipient_canonical << EOF
# Redirect all local recipients to external email address
root@$HOSTNAME    $LOGWATCH_EMAIL
$USERNAME@$HOSTNAME $LOGWATCH_EMAIL
admin@$HOSTNAME   $LOGWATCH_EMAIL
security@$HOSTNAME $LOGWATCH_EMAIL
postmaster@$HOSTNAME $LOGWATCH_EMAIL
webmaster@$HOSTNAME $LOGWATCH_EMAIL
root@\$(hostname)    $LOGWATCH_EMAIL
$USERNAME@\$(hostname) $LOGWATCH_EMAIL
admin@\$(hostname)   $LOGWATCH_EMAIL
security@\$(hostname) $LOGWATCH_EMAIL
postmaster@\$(hostname) $LOGWATCH_EMAIL
webmaster@\$(hostname) $LOGWATCH_EMAIL
EOF
    
    # Configure recipient canonical mapping
    postconf -e "recipient_canonical_maps = hash:/etc/postfix/recipient_canonical"
    postmap /etc/postfix/recipient_canonical
    
    # Create SASL password file
    cat > /etc/postfix/sasl_passwd << EOF
[$SMTP_SERVER]:$SMTP_PORT    $SMTP_USERNAME:$SMTP_PASSWORD
EOF
    
    # Secure the password file
    chmod 600 /etc/postfix/sasl_passwd
    chown root:root /etc/postfix/sasl_passwd
    
    # Create the hash database
    postmap /etc/postfix/sasl_passwd
    
    # Create sender canonical map to rewrite all From addresses
    cat > /etc/postfix/sender_canonical << EOF
# Rewrite all sender addresses to use the SMTP from address
/.*/    $SMTP_FROM_EMAIL
EOF
    
    # Create header checks to rewrite From headers
    cat > /etc/postfix/smtp_header_checks << EOF
# Rewrite From header to use proper SMTP from address
/^From:.*/ REPLACE From: $SMTP_FROM_EMAIL
EOF
    
    # Create hash databases for maps
    postmap /etc/postfix/sender_canonical
    postmap /etc/postfix/smtp_header_checks
    
    # Create aliases to redirect all local mail to the configured email address
    cat > /etc/aliases << EOF
# All local mail redirected to external email address
root: $LOGWATCH_EMAIL
$USERNAME: $LOGWATCH_EMAIL
admin: $LOGWATCH_EMAIL
security: $LOGWATCH_EMAIL
postmaster: $LOGWATCH_EMAIL
MAILER-DAEMON: $LOGWATCH_EMAIL
webmaster: $LOGWATCH_EMAIL
EOF

    # Build alias database
    newaliases

else
    echo "Configuring local-only mail system..."
    
    # Configure postfix for local-only delivery
    postconf -e "inet_interfaces = loopback-only"
    postconf -e "mydestination = \$myhostname, localhost.\$mydomain, localhost"
    postconf -e "myorigin = \$mydomain"
    postconf -e "relayhost ="
    postconf -e "mynetworks = 127.0.0.0/8"
    postconf -e "local_transport = local:\$myhostname"
    postconf -e "default_transport = local"
    
    # Create mail directories with proper permissions
    mkdir -p /var/mail
    chmod 1777 /var/mail
    mkdir -p /var/spool/mail
    chmod 1777 /var/spool/mail
    
    # Ensure mail directory ownership
    chown root:mail /var/mail
    chown root:mail /var/spool/mail
    
    # Create local mail aliases (all external emails go to root locally)
    cat > /etc/aliases << EOF
# Local mail aliases for server
# All external email addresses are redirected to local root account
root: root
$LOGWATCH_EMAIL: root
$USERNAME: root
webmaster: root
admin: root
security: root
postmaster: root
MAILER-DAEMON: root
EOF

    # Build alias database
    newaliases
fi

# Enable and start postfix with new configuration
create_rollback_point "postfix-config"
enable_and_start_service postfix

# Check if we're in a container environment
CONTAINER_ENV=""
if [ -f /.dockerenv ] || [ -n "${CONTAINER}" ] || [ "${TESTING_MODE}" = "true" ]; then
    CONTAINER_ENV="true"
    echo "ðŸ“¦ Container environment detected - mail testing will be simplified"
fi

echo "âœ… Email system configured"

# Test mail system
echo "===== Testing mail system ====="

# Skip intensive mail testing in container environments
if [ "$CONTAINER_ENV" = "true" ]; then
    echo "ðŸ“¦ Container environment - skipping detailed mail testing"
    echo "âœ… Mail system configuration completed"
    echo "ðŸ“§ Mail functionality will be available when deployed"
elif [ "$SMTP_ENABLED" = "true" ]; then
    echo "Testing external SMTP configuration..."
    
    # Create test message with proper From header
    cat > /tmp/smtp_test_email.txt << EOF
From: $SMTP_FROM_EMAIL
To: $LOGWATCH_EMAIL
Subject: SMTP Test - PolyServer Setup Complete

This is a test email from your PolyServer setup.
If you receive this email, external SMTP is working correctly.

Server: $(hostname)
Setup completed: $(date)
SMTP Server: $SMTP_SERVER
From Address: $SMTP_FROM_EMAIL
Destination: $LOGWATCH_EMAIL

All security notifications will be sent to this email address.
EOF
    
    # Send via sendmail
    /usr/sbin/sendmail -f "$SMTP_FROM_EMAIL" "$LOGWATCH_EMAIL" < /tmp/smtp_test_email.txt
    
    echo "âœ… Test email sent to $LOGWATCH_EMAIL via external SMTP"
    echo "ðŸ“§ Check your email inbox to confirm delivery"
    
    # Check mail queue for any issues (container-safe)
    sleep 3
    if command -v mailq >/dev/null 2>&1; then
        QUEUE_STATUS=$(mailq 2>/dev/null || echo "queue check failed")
        if [[ "$QUEUE_STATUS" == "Mail queue is empty" ]]; then
            echo "âœ… Mail queue is empty - email sent successfully"
        elif [[ "$QUEUE_STATUS" == "queue check failed" ]]; then
            echo "âš ï¸ Mail queue check failed (normal in container environments)"
            echo "âœ… SMTP test email sent (queue verification skipped)"
        else
            echo "âš ï¸ Mail queue status:"
            echo "$QUEUE_STATUS" | head -n 10
        fi
    else
        echo "âœ… SMTP test email sent (mailq not available)"
    fi
    
else
    echo "Testing local mail system..."
    
    # Create test message for local delivery
    echo "Subject: Local Mail Test - PolyServer Setup

Testing local mail system during PolyServer setup...
This test confirms local mail delivery is working.
All external emails will be stored locally.
Timestamp: $(date)
Server: $(hostname)
" | /usr/sbin/sendmail "${LOGWATCH_EMAIL:-root}"
    
    echo "âœ… Test email sent to local account"
    
    # Wait for delivery
    sleep 5
    
    # Check if mail was delivered locally
    if [ -f /var/mail/root ]; then
        echo "âœ… Local mail delivery confirmed in /var/mail/root"
        echo "Mail file size: $(stat -c%s /var/mail/root 2>/dev/null | numfmt --to=iec || echo "unknown")"
    elif [ -f /var/spool/mail/root ]; then
        echo "âœ… Local mail delivery confirmed in /var/spool/mail/root"
        echo "Mail file size: $(stat -c%s /var/spool/mail/root 2>/dev/null | numfmt --to=iec || echo "unknown")"
    else
        echo "âš ï¸ Mail file not found - checking postfix status and logs"
        systemctl status postfix --no-pager -l 2>/dev/null || echo "Postfix status check failed (normal in containers)"
        echo "Checking mail queue:"
        mailq 2>/dev/null || echo "Mail queue check failed (normal in container environments)"
        echo "âœ… Local mail test completed (delivery may be delayed in containers)"
    fi
fi

# Only check postfix configuration if not in container environment  
if [ "$CONTAINER_ENV" != "true" ]; then
    # Check postfix configuration and logs
    echo ""
    echo "Postfix configuration check:"
    if [ "$SMTP_ENABLED" = "true" ]; then
        postconf relayhost 2>/dev/null || echo "postconf failed"
        postconf smtp_sasl_auth_enable 2>/dev/null || echo "postconf failed"
        postconf smtp_use_tls 2>/dev/null || echo "postconf failed"
    else
        postconf inet_interfaces 2>/dev/null || echo "postconf failed"
        postconf mydestination 2>/dev/null || echo "postconf failed"
        postconf local_transport 2>/dev/null || echo "postconf failed"
    fi

    echo ""
    echo "Recent postfix logs:"
    tail -n 10 /var/log/mail.log 2>/dev/null || echo "Mail log not yet available"
fi

echo ""
if [ "$SMTP_ENABLED" = "true" ]; then
    echo "ðŸ“§ Mail system configured with external SMTP for reliable delivery"
    echo "ðŸ“§ All security notifications will be sent to: $LOGWATCH_EMAIL"
else
    echo "ðŸ“§ Mail system configured for local delivery only"
    echo "ðŸ“§ All email notifications will be stored in local root mailbox"
fi

# Clean up temporary files
rm -f /tmp/smtp_test_email.txt

# Configure automatic security updates (enabled by default)
cat > /etc/apt/apt.conf.d/20auto-upgrades << EOF
APT::Periodic::Update-Package-Lists "1";
APT::Periodic::Unattended-Upgrade "1";
APT::Periodic::AutocleanInterval "7";
EOF

# Configure unattended-upgrades for security patches only
cat > /etc/apt/apt.conf.d/50unattended-upgrades << EOF
Unattended-Upgrade::Allowed-Origins {
    "\${distro_id}:\${distro_codename}-security";
};

// Automatically reboot if required (at 2 AM)
Unattended-Upgrade::Automatic-Reboot "true";
Unattended-Upgrade::Automatic-Reboot-Time "02:00";

// Send email to admin if there are problems
Unattended-Upgrade::Mail "${LOGWATCH_EMAIL:-root}";
Unattended-Upgrade::MailReport "only-on-error";

// Remove unused dependencies
Unattended-Upgrade::Remove-Unused-Dependencies "true";

// Allow package downgrade if needed for security
Unattended-Upgrade::Allow-downgrade "true";
EOF

# Configure fail2ban for SSH
if [ "$DOCKER_MODE" = "false" ]; then
    # Ensure required log files exist before fail2ban starts
    echo "Creating required log files for fail2ban..."
    touch /var/log/auth.log
    touch /var/log/fail2ban.log
    chmod 640 /var/log/auth.log
    chmod 640 /var/log/fail2ban.log
    chown root:adm /var/log/auth.log
    chown root:adm /var/log/fail2ban.log
    
    # Create a test log entry to initialize auth.log
    logger -p auth.info "Server setup: Initializing auth.log for fail2ban"
    
    cat > /etc/fail2ban/jail.local << EOF
[DEFAULT]
# Explicitly configure IPv6 support (auto-detect based on system)
allowipv6 = auto

[sshd]
enabled = true
port = $SSH_PORT
filter = sshd
logpath = /var/log/auth.log
maxretry = 3
bantime = 3600
EOF
    
    # Test fail2ban configuration before starting
    echo "Testing fail2ban configuration..."
    if fail2ban-client -t; then
        echo "âœ… Fail2ban configuration is valid"
    else
        echo "âš ï¸ Fail2ban configuration test failed - checking for issues"
        fail2ban-client -t || true
    fi
    
    # Enable and start fail2ban with error handling
    create_rollback_point "fail2ban-config"
    
    # Stop fail2ban if it's already running to ensure clean start
    docker_systemctl stop fail2ban 2>/dev/null || true
    sleep 1
    
    if enable_and_start_service fail2ban; then
        # Test fail2ban client connection
        if [ "$DOCKER_MODE" = "false" ] && fail2ban-client status >/dev/null 2>&1; then
            log_message "âœ… Fail2ban client communication working"
            fail2ban-client status || true
        else
            log_message "âš ï¸ Fail2ban status check failed (may still be initializing)"
        fi
    else
        log_error "âŒ Failed to start fail2ban service"
        if [ "$DOCKER_MODE" = "false" ]; then
            systemctl status fail2ban --no-pager -l || true
        fi
    fi
else
    echo "ðŸ³ Skipping fail2ban configuration in Docker mode"
fi

# Configure hardware sensors
echo "===== 7. Configuring hardware monitoring ====="
if [ "$DOCKER_MODE" = "false" ]; then
    # Detect and configure sensors automatically
    yes | sensors-detect
else
    echo "ðŸ³ Skipping hardware sensor detection in Docker mode"
fi

# Configure ClamAV with resource optimization
echo "===== 8. Configuring ClamAV with resource optimization ====="
# Optimize ClamAV for production server environment with resource awareness
# This prevents ClamAV from consuming excessive CPU/memory that could impact applications

if [ "$DOCKER_MODE" = "false" ]; then
    # Stop services during configuration (only in non-Docker mode)
    systemctl stop clamav-daemon clamav-freshclam 2>/dev/null || true

    # Configure ClamAV daemon with resource-conscious settings
    cat > /etc/clamav/clamd.conf << 'EOF'
# ClamAV Daemon Configuration - Optimized for Production Servers
User clamav
LocalSocket /run/clamav/clamd.ctl
FixStaleSocket true
LocalSocketGroup clamav
LocalSocketMode 666

# Resource-balanced configuration for application servers
MaxThreads 2
MaxConnectionQueueLength 10
MaxQueue 100

# Optimize scanning performance vs resources
ReadTimeout 180
CommandReadTimeout 60
SendBufTimeout 200

# File size and scanning limits - balanced for application servers
MaxScanSize 100M
MaxFileSize 25M
MaxRecursion 10
MaxFiles 10000
MaxPartitions 50
MaxIconsPE 100

# Scan behavior - comprehensive security vs performance
ScanPE true
ScanELF true
ScanOLE2 true
ScanPDF true
ScanHTML true
ScanArchive true
ArchiveBlockEncrypted false
MaxDirectoryRecursion 15

# Memory and timeout optimizations
PCREMatchLimit 10000
PCRERecMatchLimit 5000
PCREMaxFileSize 25M
MaxScanTime 120000

# Logging - standard for production
LogFile /var/log/clamav/clamav.log
LogTime true
LogClean false
LogSyslog false
LogRotate true
LogVerbose false

# Network and detection settings
SelfCheck 3600
DatabaseDirectory /var/lib/clamav
OfficialDatabaseOnly false
Foreground false
Debug false

# Production detection settings
IdleTimeout 30
ExitOnOOM true
LeaveTemporaryFiles false
DetectPUA false
CrossFilesystems true

# Heuristic settings - balanced approach
AlgorithmicDetection true
Bytecode true
BytecodeSecurity TrustSigned
BytecodeTimeout 60000

# Enhanced detection for production servers
PhishingSignatures true
PhishingAlwaysBlockSSLMismatch false
PhishingAlwaysBlockCloak false
HeuristicScanPrecedence false
StructuredDataDetection false
ScanPartialMessages false
OLE2BlockMacros false
EOF

    # Configure freshclam with reduced frequency for production servers
    cat > /etc/clamav/freshclam.conf << 'EOF'
# ClamAV Freshclam Configuration - Optimized for Production Servers
DatabaseOwner clamav

# Moderate update frequency - 4 times daily for production balance
Checks 4

# Database mirrors and sources
DatabaseMirror db.us.clamav.net
DatabaseMirror db.local.clamav.net

# Logging
UpdateLogFile /var/log/clamav/freshclam.log
LogVerbose false
LogSyslog false
LogTime true
LogRotate true

# Download behavior - balanced for production
MaxAttempts 3
ConnectTimeout 60
ReceiveTimeout 60

# Notify clamd of updates
NotifyClamd /etc/clamav/clamd.conf

# Test database before loading
TestDatabases yes

# Bytecode updates
Bytecode true
EOF

    # Create systemd resource limits for ClamAV services
    echo "Setting up systemd resource limits for ClamAV services..."

    # ClamAV daemon resource limits for production servers
    mkdir -p /etc/systemd/system/clamav-daemon.service.d
    cat > /etc/systemd/system/clamav-daemon.service.d/resource-limits.conf << 'EOF'
[Service]
# Proper memory limits for ClamAV daemon (minimum 1GB required)
CPUQuota=40%
MemoryMax=1536M
MemoryHigh=1200M

# Process priority and I/O scheduling
Nice=10
IOSchedulingClass=2
IOSchedulingPriority=4

# Smart restart behavior with longer delays
Restart=on-failure
RestartSec=60
StartLimitInterval=1200
StartLimitBurst=2

# Watchdog configuration for production workloads
WatchdogSec=300

# OOM handling - kill ClamAV rather than other services
OOMPolicy=kill
OOMScoreAdjust=100

# Security isolation
PrivateTmp=true
ProtectSystem=strict
ProtectHome=true
NoNewPrivileges=true
ReadWritePaths=/var/lib/clamav /var/log/clamav /run/clamav

# Prevent memory fragmentation issues
TasksMax=50

# OOM handling - controlled termination
OOMPolicy=kill
OOMScoreAdjust=300

# Security and resource isolation
PrivateTmp=true
ProtectSystem=strict
ProtectHome=true
NoNewPrivileges=true
ReadWritePaths=/var/lib/clamav /var/log/clamav /run/clamav
EOF

    # Freshclam resource limits for production servers
    mkdir -p /etc/systemd/system/clamav-freshclam.service.d
    cat > /etc/systemd/system/clamav-freshclam.service.d/resource-limits.conf << 'EOF'
[Service]
# Proper memory limits for virus definition updates (minimum 768MB required)
CPUQuota=20%
MemoryMax=1024M
MemoryHigh=768M

# Process priority
Nice=15
IOSchedulingClass=2

# Restart behavior
Restart=on-failure
RestartSec=120
StartLimitInterval=1800
StartLimitBurst=2

# OOM handling
OOMPolicy=kill
OOMScoreAdjust=200

# Security isolation
PrivateTmp=true
ProtectSystem=strict
ProtectHome=true
NoNewPrivileges=true
ReadWritePaths=/var/lib/clamav /var/log/clamav

# Prevent resource conflicts during updates
TasksMax=20
EOF

    # Create log directory with proper permissions
    mkdir -p /var/log/clamav
    chown clamav:clamav /var/log/clamav
    chmod 755 /var/log/clamav

    # Set up logrotate for ClamAV logs
    cat > /etc/logrotate.d/clamav << 'EOF'
/var/log/clamav/*.log {
    weekly
    rotate 12
    compress
    delaycompress
    missingok
    notifempty
    create 644 clamav clamav
    postrotate
        systemctl reload clamav-daemon > /dev/null 2>&1 || true
    endscript
}
EOF

    # Reload systemd and start services with new configurations
    systemctl daemon-reload

    echo "âœ… ClamAV configured with resource allocation for production environment"
    echo "   â€¢ CPU limited to 40% (daemon) / 20% (updater)"
    echo "   â€¢ Memory INCREASED to 1536MB (daemon) / 1024MB (updater)"
    echo "   â€¢ Update frequency: 4x daily (production balance)"
    echo "   â€¢ Optimized scan limits and timeouts"
    echo "   â€¢ Enhanced security isolation and OOM protection"
fi

# Enable and start ClamAV services
create_rollback_point "clamav-config"
enable_and_start_service clamav-freshclam
enable_and_start_service clamav-daemon

if [ "$DOCKER_MODE" = "false" ]; then
    echo ""
    echo "ðŸ“‹ ClamAV Management Commands:"
    echo "   â€¢ Check status: systemctl status clamav-daemon clamav-freshclam"
    echo "   â€¢ View logs: journalctl -u clamav-daemon -f"
    echo "   â€¢ Manual scan: clamscan -r /path/to/scan"
    echo "   â€¢ Monitor resources: systemctl show clamav-daemon --property=CPUUsageNSec,MemoryCurrent"
fi

# Install Linux Malware Detect (maldet)
echo "===== 8.1 Installing Linux Malware Detect (maldet) ====="
# Create temporary directory for installation
mkdir -p /tmp/maldet
cd /tmp/maldet

# Download the latest version
wget http://www.rfxn.com/downloads/maldetect-current.tar.gz

# Extract and install
tar -xzf maldetect-current.tar.gz
MALDET_DIR=$(tar -tzf maldetect-current.tar.gz | head -1 | cut -f1 -d"/")
cd "$MALDET_DIR"
./install.sh

# Configure maldet with secure settings
cat > /usr/local/maldetect/conf.maldet << EOC
# Linux Malware Detect v1.6.x
# Configuration File

# Enable Email Alerting (1 = enabled, 0 = disabled)
email_alert="1"

# Email Address in which you want to receive scan reports and alerts
# Separate multiple email addresses with a space: "user@domain.com user2@domain.com"
email_addr="${LOGWATCH_EMAIL:-root}"

# Use with ClamAV (1 = enabled, 0 = disabled)
clamav_scan="1"

# Quarantine malicious files (1 = enabled, 0 = disabled)
quarantine_hits="1"

# Clean/Delete malicious files (1 = enabled, 0 = disabled)
quarantine_clean="0"

# Clean/Delete suspicious files (1 = enabled, 0 = disabled)
quarantine_suspend_user="0"

# Minimum userid value that can be suspended
quarantine_suspend_user_minuid="500"

# Enable Email Alerting for all scan users (1 = enabled, 0 = disabled)
email_subj="[MALWARE] ${HOSTNAME}: Linux Malware Detection on \\\${domain_count} domains"

# Use path names relative to a domain for cleaner reports
email_ignore_clean="1"

# Allow clean/delete operation to use signatures with HEX string matches below this value
quar_hex_min_suspect="70"

# The default find command to use, use of 'xargs' is required
# for 'find -exec' to queue and optimize processing of find matches
find_cmd="find \\\${scan_location} -type f -not -path '/proc/*' -not -path '/sys/*' -print0 | xargs -0 -P 10 -n 100"

# The default basis for determining file system ownership of a file
# should always be the username:group of the file/directory
file_owner_lookup="1"

# Size limit on files being scanned (in KB)
max_filesize="10240"

# When using the -r scan operation to scan root directory & user paths, the max directory depth
# that will be scanned, beyond that will be ignored.
maxdepth="15"

# The maximum amount of file download attempts that will be made before giving up
url_max_dl="3"

# The curl command line that handles all remote file transfers,
# adjust timeout and max-time to meet connectivity requirements.
curl_timeout="30"
curl_max_time="60"

# The maximum number of child processes that maldet should fork to handle scan operations,
# by default we fork one scan thread per available CPU.
scan_max_process="5"

# The maximum number of process operations that maldet should fork per signature in hex scan operations,
# limit this to 2 to reduce CPU load at expense of scan speed.
scan_max_process_hex="2"

# Additional paths for daily cron scan
scan_paths="/home /opt/polyserver /var/www"

# Do not scan mounts/paths defined here
scan_ignore_paths="/proc /sys /dev"

# Total CPU usage threshold (percentage) at which scanning will be suspended until usage drops
scan_cpumax="75"

# Allow maldet to download and install updated signatures from rfxn.com
autoupdate="1"

# Daily automatic updates of malware signatures
autoupdate_signatures="1"

# Daily automatic updates of maldet
autoupdate_version="1"

# When defined, the update process will source this external file from
# rfxn.com following the update if it exists. This is used to deploy
# critical configuration settings to all installations.
autoupdate_version_hashed="1"

# Run weekly cronjob at specific day and time
cron_weekly_day="2"  # 0 = Sunday, 1 = Monday, 2 = Tuesday, etc.
cron_weekly_hour="3" # Hour in 24h format
cron_daily_hour="3"  # Hour in 24h format
EOC

# Create maldet daily scan script with notifications
cat > /etc/cron.daily/maldet-scan << 'EOF'
#!/bin/bash
# Daily maldet scan script

# Log file
LOGFILE="/var/log/maldet/daily_scan.log"

# Make sure log directory exists
mkdir -p /var/log/maldet

# Start the log
echo "Linux Malware Detect daily scan started at $(date)" > $LOGFILE

# Run scan on important directories
/usr/local/sbin/maldet --scan-all /home /opt/polyserver /var/www >> $LOGFILE 2>&1

# Finish log
echo "Linux Malware Detect daily scan completed at $(date)" >> $LOGFILE

# Check for detections
if grep -q "malware hits" $LOGFILE; then
    HITS=$(grep "malware hits" $LOGFILE | grep -o '[0-9]\+')
    if [ "$HITS" -gt 0 ]; then
        # Send email alert if malware found
        cat $LOGFILE | mail -s "âš ï¸ MALWARE WARNING: $HITS malware hits found on $(hostname)" "${LOGWATCH_EMAIL:-root}"
    fi
fi
EOF

# Make scan script executable
chmod 755 /etc/cron.daily/maldet-scan

# Force initial maldet signature update
/usr/local/sbin/maldet --update-sigs

# Clean up
cd /
rm -rf /tmp/maldet

# Create daily scan script
cat > /etc/cron.daily/clamscan << 'EOF'
#!/bin/bash
LOGFILE="/var/log/clamav/daily_scan.log"
DIRTOSCAN="/home /opt/polyserver /var/www"

# Create log directory if it doesn't exist
mkdir -p /var/log/clamav

# Remove old logfile
rm -f $LOGFILE

# Start scanning
echo "ClamAV daily scan started at $(date)" >> $LOGFILE
clamscan -r -i $DIRTOSCAN >> $LOGFILE
echo "ClamAV daily scan completed at $(date)" >> $LOGFILE

# Send notification if viruses were found
if grep -q "Infected files: [1-9]" $LOGFILE; then
    VIRUS_COUNT=$(grep "Infected files:" $LOGFILE | cut -d: -f2 | tr -d ' ')
    echo "WARNING - $VIRUS_COUNT VIRUS(ES) FOUND ON $(hostname)" | mail -s "VIRUS ALERT on $(hostname)" "${LOGWATCH_EMAIL:-root}"
fi
EOF
chmod 755 /etc/cron.daily/clamscan

# Configure Logcheck
echo "===== 9. Configuring Logcheck ====="
# Set logcheck to use server level
sed -i 's/^REPORTLEVEL=.*/REPORTLEVEL="server"/' /etc/logcheck/logcheck.conf

# Set logcheck email recipient (same as logwatch)
sed -i "s/^SENDMAILTO=.*/SENDMAILTO=\"${LOGWATCH_EMAIL:-root}\"/" /etc/logcheck/logcheck.conf

# Set running frequency to daily (default is hourly)
sed -i 's/^CRON_DAILY_RUN=.*/CRON_DAILY_RUN="true"/' /etc/logcheck/logcheck.conf
sed -i 's/^CRON_HOURLY_RUN=.*/CRON_HOURLY_RUN="false"/' /etc/logcheck/logcheck.conf

# Remove hourly logcheck cron job if it exists
rm -f /etc/cron.hourly/logcheck 2>/dev/null || true

# Add ignore patterns for common application server activity
log_message "Adding logcheck ignore patterns for UFW and common server activity..."
cat >> /etc/logcheck/ignore.d.server/application-server-ignore << EOF
# Application server specific ignore patterns
# Ignore normal server activity patterns that are not security issues

# Normal SSH connection patterns
^\w{3} [ :0-9]{11} [._[:alnum:]-]+ sshd\[[0-9]+\]: Connection from [.[:digit:]]+ port [0-9]+ on [.[:digit:]]+ port [0-9]+$
^\w{3} [ :0-9]{11} [._[:alnum:]-]+ sshd\[[0-9]+\]: Accepted publickey for [[:alnum:]]+ from [.[:digit:]]+ port [0-9]+ ssh2: [[:alnum:][:space:]]+$
^\w{3} [ :0-9]{11} [._[:alnum:]-]+ sshd\[[0-9]+\]: pam_unix\(sshd:session\): session opened for user [[:alnum:]]+ by \(uid=[0-9]+\)$
^\w{3} [ :0-9]{11} [._[:alnum:]-]+ sshd\[[0-9]+\]: pam_unix\(sshd:session\): session closed for user [[:alnum:]]+$

# UFW firewall blocks - support both syslog and ISO 8601 formats
^\w{3} [ :0-9]{11} [._[:alnum:]-]+ kernel: \[UFW [[:upper:]]+\].*$
^[0-9]{4}-[0-9]{2}-[0-9]{2}T[0-9]{2}:[0-9]{2}:[0-9]{2}\.[0-9]+[+-][0-9]{4} [._[:alnum:]-]+ kernel: \[[0-9.]+\] \[UFW [[:upper:]]+\].*$

# Normal cron activity
^\w{3} [ :0-9]{11} [._[:alnum:]-]+ \/USR\/SBIN\/CRON\[[0-9]+\]: \([[:alnum:]]+\) CMD \(.*\)$
^\w{3} [ :0-9]{11} [._[:alnum:]-]+ cron\[[0-9]+\]: \([[:alnum:]]+\) CMD \(.*\)$

# Normal systemd activity
^\w{3} [ :0-9]{11} [._[:alnum:]-]+ systemd\[[0-9]+\]: .*\.service: Succeeded\.$
^\w{3} [ :0-9]{11} [._[:alnum:]-]+ systemd\[[0-9]+\]: Started .*\.$

# Normal postfix activity (for notifications)
^\w{3} [ :0-9]{11} [._[:alnum:]-]+ postfix/smtp\[[0-9]+\]: [A-F0-9]+: to=<.*>, relay=.*$
^\w{3} [ :0-9]{11} [._[:alnum:]-]+ postfix/cleanup\[[0-9]+\]: [A-F0-9]+: message-id=<.*>$
^\w{3} [ :0-9]{11} [._[:alnum:]-]+ postfix/qmgr\[[0-9]+\]: [A-F0-9]+: from=<.*>, size=[0-9]+, nrcpt=[0-9]+.*$

# Normal PHP-FPM activity (if using PHP)
^\w{3} [ :0-9]{11} [._[:alnum:]-]+ php-fpm\[[0-9]+\]: .*pool [[:alnum:]]+.*$

# Normal nginx activity
^\w{3} [ :0-9]{11} [._[:alnum:]-]+ nginx\[[0-9]+\]: .*$

# Normal Docker activity (if using Docker)
^\w{3} [ :0-9]{11} [._[:alnum:]-]+ dockerd\[[0-9]+\]: .*$
^\w{3} [ :0-9]{11} [._[:alnum:]-]+ containerd\[[0-9]+\]: .*$

EOF

log_message "âœ… Logcheck configured with application server ignore patterns"

# Configure and initialize AIDE (Advanced Intrusion Detection Environment)
if [ "$DOCKER_MODE" = "false" ]; then
    echo "Configuring AIDE for file integrity monitoring..."
    
    # Configure AIDE to run properly with mail functionality
    cat > /etc/default/aide << 'EOF'
# Configuration for AIDE
# Run AIDE checks as root to enable mail functionality
AIDE_USER="root"

# Mail configuration
MAILTO="root"
MAILSUBJECT="AIDE integrity check for $HOSTNAME"

# Quiet mode - don't output unless there are changes
QUIETREPORTS="yes"

# Skip the database check if the database doesn't exist yet
COPYNEWDB="no"
EOF

    # Create custom AIDE check script that handles mail properly
    cat > /usr/local/bin/aide-check << 'EOF'
#!/bin/bash
# Custom AIDE check script with proper mail handling

# Log file for AIDE output
AIDE_LOG="/var/log/aide/aide-check.log"
mkdir -p /var/log/aide

# Run AIDE check and capture output
echo "AIDE integrity check started at $(date)" > $AIDE_LOG
echo "=====================================" >> $AIDE_LOG

# Run AIDE check with proper error handling
if aide --check 2>&1 | tee -a $AIDE_LOG; then
    # AIDE completed successfully
    echo "AIDE check completed at $(date)" >> $AIDE_LOG
    
    # Check if there were any changes detected
    if grep -q "found differences" $AIDE_LOG || grep -q "File.*changed" $AIDE_LOG; then
        # Changes detected - send alert email
        cat $AIDE_LOG | mail -s "âš ï¸ AIDE ALERT: File integrity changes detected on $HOSTNAME" root
    else
        # No changes - log success
        echo "No integrity violations detected" >> $AIDE_LOG
    fi
else
    # AIDE failed
    echo "AIDE check failed at $(date)" >> $AIDE_LOG
    echo "AIDE integrity check failed on $HOSTNAME" | mail -s "ðŸš¨ AIDE ERROR: Check failed on $HOSTNAME" root
    exit 1
fi

# Rotate old logs
find /var/log/aide -name "aide-check.log.*" -mtime +30 -delete
if [ -f $AIDE_LOG ] && [ $(stat -c%s $AIDE_LOG) -gt 10485760 ]; then
    # Rotate if log is larger than 10MB
    mv $AIDE_LOG ${AIDE_LOG}.$(date +%Y%m%d)
    gzip ${AIDE_LOG}.$(date +%Y%m%d)
fi
EOF

    chmod 755 /usr/local/bin/aide-check

    # Override the default AIDE systemd service to use our custom script
    mkdir -p /etc/systemd/system/dailyaidecheck.service.d
    cat > /etc/systemd/system/dailyaidecheck.service.d/override.conf << 'EOF'
[Service]
# Override to use our custom AIDE check script
ExecStart=
ExecStart=/usr/local/bin/aide-check

# Ensure proper user and environment
User=root
Group=root

# Resource limits to prevent AIDE from overwhelming system
CPUQuota=25%
MemoryMax=512M
Nice=15
IOSchedulingClass=3

# Proper logging
StandardOutput=journal
StandardError=journal
EOF

    systemctl daemon-reload

    echo "Initializing AIDE database - this will take some time..."
    nice -n 19 aideinit
    
    echo "âœ… AIDE configured with proper mail functionality"
else
    echo "ðŸ³ Skipping AIDE initialization in Docker mode"
fi

# Configure Audit Framework (auditd)
echo "===== 10.1 Configuring Audit Framework ====="
# Configure audit daemon
cat > /etc/audit/auditd.conf << EOF
#
# This file controls the configuration of the audit daemon
#

local_events = yes
write_logs = yes
log_file = /var/log/audit/audit.log
log_group = adm
log_format = ENRICHED
flush = INCREMENTAL_ASYNC
freq = 50
max_log_file = 8
num_logs = 5
priority_boost = 4
name_format = HOSTNAME
##name = mydomain
max_log_file_action = ROTATE
space_left = 75
space_left_action = SYSLOG
verify_email = yes
action_mail_acct = ${LOGWATCH_EMAIL:-root}
admin_space_left = 50
admin_space_left_action = SUSPEND
disk_full_action = SUSPEND
disk_error_action = SUSPEND
use_libwrap = yes
##tcp_listen_port = 60
tcp_listen_queue = 5
tcp_max_per_addr = 1
##tcp_client_ports = 1024-65535
tcp_client_max_idle = 0
enable_krb5 = no
krb5_principal = auditd
##krb5_key_file = /etc/audit/audit.key
distribute_network = no
EOF

# Configure audit rules
cat > /etc/audit/rules.d/audit.rules << 'EOF'
## auditd rules for enhanced security monitoring

## First rule - delete all
-D

## Increase the buffers to survive stress events
## Adjust buffer size based on system activity
-b 8192

## This determines how long to wait in burst of events
--backlog_wait_time 0

## Set failure mode to syslog
-f 1

# DNS lookup monitoring
-w /etc/resolv.conf -p r -k dns_lookup
-a always,exit -F arch=b64 -S connect -F a1=0x2 -F key=dns_lookup
-a always,exit -F arch=b64 -S connect -F a1=0xA -F key=dns_lookup
-a always,exit -F arch=b64 -S sendto -F a1=0x2 -F key=dns_lookup
-a always,exit -F arch=b64 -S sendto -F a1=0xA -F key=dns_lookup
-a always,exit -F arch=b64 -S execve -F exe=/usr/bin/dig -F key=dns_lookup
-a always,exit -F arch=b64 -S execve -F exe=/usr/bin/nslookup -F key=dns_lookup
-a always,exit -F arch=b64 -S execve -F exe=/usr/bin/getent -F key=dns_lookup

## File System monitoring
-w /etc/fstab -p wa -k filesystem_modifications
-w /etc/group -p wa -k user_group_modifications
-w /etc/shadow -p wa -k password_modifications
-w /etc/security/opasswd -p wa -k password_modifications
-w /etc/sudoers -p wa -k sudoers_modifications
-w /etc/sudoers.d -p wa -k sudoers_modifications

## Login monitoring
-w /var/log/faillog -p wa -k login_failures
-w /var/log/lastlog -p wa -k login_activity
-w /var/run/faillock -p wa -k login_failures

## Process and system activity
-w /sbin/insmod -p x -k module_insertion
-w /sbin/rmmod -p x -k module_removal
-w /sbin/modprobe -p x -k module_insertion
-a always,exit -F arch=b64 -S mount -k mount_operations
-a always,exit -F arch=b32 -S mount -k mount_operations

## System startup scripts
-w /etc/init.d -p wa -k init_modifications
-w /etc/systemd -p wa -k systemd_modifications

## SSH configuration
-w /etc/ssh/sshd_config -p wa -k sshd_config_modifications
-w /etc/ssh/sshd_config.d -p wa -k sshd_config_modifications

## Network configuration
-w /etc/hosts -p wa -k hosts_file_modifications
-w /etc/network/interfaces -p wa -k network_modifications

## Web server (nginx)
-w /etc/nginx/nginx.conf -p wa -k nginx_config
-w /etc/nginx/conf.d -p wa -k nginx_config

## Docker configuration monitoring
-w /etc/docker/daemon.json -p wa -k docker_config
-w /etc/docker -p wa -k docker_config

## Application directories monitoring
-w /opt/polyserver/config -p wa -k application_config_changes
-w /opt/polyserver/scripts -p x -k application_script_execution

## Critical command executions
-a always,exit -F path=/usr/bin/curl -F perm=x -F key=data_exfiltration
-a always,exit -F path=/usr/bin/wget -F perm=x -F key=data_exfiltration
-a always,exit -F path=/usr/bin/base64 -F perm=x -F key=data_exfiltration
-a always,exit -F path=/bin/nc -F perm=x -F key=data_exfiltration
-a always,exit -F path=/bin/netcat -F perm=x -F key=data_exfiltration
-a always,exit -F path=/usr/bin/ssh -F perm=x -F key=outbound_ssh
-a always,exit -F path=/usr/bin/scp -F perm=x -F key=data_exfiltration
-a always,exit -F path=/usr/bin/sftp -F perm=x -F key=data_exfiltration

## AppArmor (Debian's default MAC system)
-w /etc/apparmor -p wa -k apparmor_modifications
-w /etc/apparmor.d -p wa -k apparmor_modifications

## Cron jobs
-w /etc/cron.allow -p wa -k cron_modifications
-w /etc/cron.deny -p wa -k cron_modifications
-w /etc/cron.d -p wa -k cron_modifications
-w /etc/cron.daily -p wa -k cron_modifications
-w /etc/cron.hourly -p wa -k cron_modifications
-w /etc/cron.monthly -p wa -k cron_modifications
-w /etc/cron.weekly -p wa -k cron_modifications
-w /etc/crontab -p wa -k cron_modifications

## Security tools configuration
-w /usr/local/maldetect/conf.maldet -p wa -k security_tool_config
-w /etc/rkhunter.conf -p wa -k security_tool_config
-w /etc/default/clamav-daemon -p wa -k security_tool_config
-w /etc/clamav/clamd.conf -p wa -k security_tool_config

# User modifications monitoring
-w /etc/passwd -p wa -k user_modify

# Time change monitoring
-a always,exit -F arch=b64 -S clock_settime -F key=changetime
-a always,exit -F arch=b32 -S clock_settime -F key=changetime

## Monitor Docker socket for access
-w /var/run/docker.sock -p rwa -k docker_socket_access

## Monitor for privilege escalation
-a always,exit -F arch=b64 -S setuid -S setgid -F exit=0 -k privilege_escalation
-a always,exit -F arch=b32 -S setuid -S setgid -F exit=0 -k privilege_escalation

## Detect unauthorized attempts to access restricted directories
-a always,exit -F dir=/root -F perm=r -F auid>=1000 -F key=unauthorized_access
-a always,exit -F dir=/etc/ssl/private -F perm=r -F auid>=1000 -F key=unauthorized_access

## Detect changes to backup scripts
-w /mnt/backup/backups -p wa -k backup_changes

## File integrity for binaries (limited to critical ones to reduce noise)
-w /usr/bin/sudo -p wa -k binary_modifications
-w /usr/bin/docker -p wa -k binary_modifications
-w /usr/bin/ssh -p wa -k binary_modifications
-w /usr/bin/nginx -p wa -k binary_modifications
-w /usr/bin/maldet -p wa -k binary_modifications

## Detect attempts to alter logs
-w /var/log -p wa -k log_tampering

## Make the configuration immutable until next reboot (uncomment if needed)
## WARNING: You will need to reboot to make changes after enabling this option
#-e 2
EOF

# Create daily audit report script
cat > /etc/cron.daily/audit-report << 'EOF'
#!/bin/bash
# Daily audit report script

# Set variables
DATE=$(date +%Y-%m-%d)
REPORT_DIR="/var/log/audit/reports"
LOG_FILE="/var/log/audit/audit.log"
MAIL_RECIPIENT="${LOGWATCH_EMAIL:-root}"
HOSTNAME=$(hostname)

# Create report directory if it doesn't exist
mkdir -p $REPORT_DIR

# Generate report filename
REPORT_FILE="${REPORT_DIR}/audit-report-${DATE}.txt"

# Start report
echo "===============================================================" > $REPORT_FILE
echo "Audit Report for $HOSTNAME on $DATE" >> $REPORT_FILE
echo "===============================================================" >> $REPORT_FILE
echo "" >> $REPORT_FILE

# System Summary
echo "SYSTEM SUMMARY" >> $REPORT_FILE
echo "===============" >> $REPORT_FILE
uname -a >> $REPORT_FILE
echo "" >> $REPORT_FILE
echo "Uptime: $(uptime)" >> $REPORT_FILE
echo "" >> $REPORT_FILE

# General Summary Report
echo "GENERAL SUMMARY" >> $REPORT_FILE
echo "===============" >> $REPORT_FILE
ausearch --start today --end now | aureport --summary -i >> $REPORT_FILE
echo "" >> $REPORT_FILE

# Authentication Report
echo "AUTHENTICATION EVENTS" >> $REPORT_FILE
echo "====================" >> $REPORT_FILE
ausearch --start today --end now | aureport --auth --summary -i >> $REPORT_FILE
echo "" >> $REPORT_FILE

# User Modification Events
echo "USER MODIFICATION EVENTS" >> $REPORT_FILE
echo "=======================" >> $REPORT_FILE
ausearch -k user_modify --start today --end now -i >> $REPORT_FILE
echo "" >> $REPORT_FILE

# Executable Summary
echo "EXECUTABLE SUMMARY" >> $REPORT_FILE
echo "=================" >> $REPORT_FILE
ausearch --start today --end now | aureport --executable --summary -i >> $REPORT_FILE
echo "" >> $REPORT_FILE

# Suspicious Command Executions
echo "SUSPICIOUS COMMAND EXECUTIONS" >> $REPORT_FILE
echo "============================" >> $REPORT_FILE
ausearch -k data_exfiltration --start today --end now -i >> $REPORT_FILE
echo "" >> $REPORT_FILE

# File Modification Events
echo "CONFIG FILE MODIFICATION EVENTS" >> $REPORT_FILE
echo "=============================" >> $REPORT_FILE
ausearch -k sshd_config_modifications --start today --end now -i >> $REPORT_FILE
ausearch -k nginx_config --start today --end now -i >> $REPORT_FILE
ausearch -k docker_config --start today --end now -i >> $REPORT_FILE
ausearch -k application_config_changes --start today --end now -i >> $REPORT_FILE
ausearch -k security_tool_config --start today --end now -i >> $REPORT_FILE
echo "" >> $REPORT_FILE

# Privilege Escalation
echo "PRIVILEGE ESCALATION EVENTS" >> $REPORT_FILE
echo "=========================" >> $REPORT_FILE
ausearch -k privilege_escalation --start today --end now -i >> $REPORT_FILE
echo "" >> $REPORT_FILE

# Unauthorized Access Attempts
echo "UNAUTHORIZED ACCESS ATTEMPTS" >> $REPORT_FILE
echo "==========================" >> $REPORT_FILE
ausearch -k unauthorized_access --start today --end now -i >> $REPORT_FILE
echo "" >> $REPORT_FILE

# Binary Modifications
echo "BINARY MODIFICATION EVENTS" >> $REPORT_FILE
echo "=========================" >> $REPORT_FILE
ausearch -k binary_modifications --start today --end now -i >> $REPORT_FILE
echo "" >> $REPORT_FILE

# Docker Socket Access
echo "DOCKER SOCKET ACCESS" >> $REPORT_FILE
echo "===================" >> $REPORT_FILE
ausearch -k docker_socket_access --start today --end now -i >> $REPORT_FILE
echo "" >> $REPORT_FILE

# Audit System Status
echo "AUDIT SYSTEM STATUS" >> $REPORT_FILE
echo "==================" >> $REPORT_FILE
auditctl -s >> $REPORT_FILE
echo "" >> $REPORT_FILE
auditctl -l >> $REPORT_FILE
echo "" >> $REPORT_FILE

# Check for empty report (only headings) and add note if so
if [ $(grep -v "^$\|^=\|^[A-Z]" $REPORT_FILE | wc -l) -eq 0 ]; then
    echo "No significant audit events recorded for this period." >> $REPORT_FILE
fi

# Email report if there are significant events
if grep -q "type=\|command=\|success=\|.*=yes\|modified\|executed" $REPORT_FILE; then
    cat $REPORT_FILE | mail -s "Audit Report for $HOSTNAME - $DATE" $MAIL_RECIPIENT
fi

# Cleanup old reports (keep 30 days)
find $REPORT_DIR -name "audit-report-*.txt" -mtime +30 -delete

exit 0
EOF

chmod 750 /etc/cron.daily/audit-report

# Configure auditd systemd resource limits
echo "===== 9.1.1 Configuring Auditd Resource Management ====="
mkdir -p /etc/systemd/system/auditd.service.d
cat > /etc/systemd/system/auditd.service.d/resource-limits.conf << 'EOF'
[Service]
# Resource limits to prevent auditd from overwhelming system
CPUQuota=20%
MemoryMax=256M
MemoryHigh=200M
Nice=0
IOSchedulingClass=1
IOSchedulingPriority=4
OOMPolicy=continue
OOMScoreAdjust=-100

# Security and isolation (limited for auditd requirements)
NoNewPrivileges=true
ProtectHome=true
ReadWritePaths=/var/log/audit /etc/audit

# Restart policy for audit reliability
Restart=always
RestartSec=60
TimeoutStartSec=60
TimeoutStopSec=30

# Watchdog configuration
WatchdogSec=120
NotifyAccess=main
EOF

systemctl daemon-reload

# Enable and start auditd
docker_systemctl enable auditd
docker_systemctl restart auditd

# Initial audit test
if [ "$DOCKER_MODE" = "false" ]; then
    echo "Testing audit system..."
    auditctl -l
else
    echo "ðŸ³ Skipping audit system test in Docker mode"
fi

# Create audit log rotation configuration
cat > /etc/logrotate.d/auditd << EOF
/var/log/audit/audit.log {
    rotate 10
    weekly
    size 50M
    compress
    delaycompress
    missingok
    notifempty
    postrotate
        docker_systemctl reload auditd > /dev/null 2>&1 || true
    endscript
}
EOF

# Configure ModSecurity WAF
echo "===== 10.2 Configuring ModSecurity Web Application Firewall ====="
if [ "$DOCKER_MODE" = "false" ]; then
    # Install libmodsecurity3 for Debian
    apt-get install -y libmodsecurity3 libmodsecurity-dev

    # Enable ModSecurity in Nginx
    mkdir -p /etc/nginx/modsec
    cat > /etc/nginx/modsec/main.conf << EOF
# Include the recommended configuration
Include /etc/nginx/modsec/modsecurity.conf

# Include OWASP Core Rule Set (CRS)
Include /etc/nginx/modsec/owasp-crs/crs-setup.conf
Include /etc/nginx/modsec/owasp-crs/rules/*.conf
EOF

    # Download OWASP CRS
    mkdir -p /etc/nginx/modsec/owasp-crs
    rm -rf /etc/nginx/modsec/owasp-crs
    git clone https://github.com/coreruleset/coreruleset.git /etc/nginx/modsec/owasp-crs
    cp /etc/nginx/modsec/owasp-crs/crs-setup.conf.example /etc/nginx/modsec/owasp-crs/crs-setup.conf

    # Create application-agnostic ModSecurity configuration
    cat > /etc/nginx/modsec/modsecurity.conf << EOF
# ModSecurity configuration for PolyServer applications

# -- Rule engine initialization ----------------------------------------------
SecRuleEngine On

# -- Request body handling ---------------------------------------------------
SecRequestBodyAccess On
SecRequestBodyLimit 13107200
SecRequestBodyNoFilesLimit 131072
SecRequestBodyInMemoryLimit 131072

# Buffer response bodies
SecResponseBodyAccess On
SecResponseBodyMimeType text/plain text/html text/xml application/json
SecResponseBodyLimit 1048576

# -- Filesystem configuration ------------------------------------------------
SecTmpDir /tmp/
SecDataDir /tmp/

# -- Audit log configuration -------------------------------------------------
SecAuditEngine RelevantOnly
SecAuditLogRelevantStatus "^(?:5|4(?!04))"
SecAuditLogParts ABIJDEFHZ
SecAuditLogType Serial
SecAuditLog /var/log/nginx/modsec_audit.log

# -- Debug log configuration -------------------------------------------------
SecDebugLog /var/log/nginx/modsec_debug.log
SecDebugLogLevel 1

# -- Application specific exceptions ----------------------------------------
# Add custom rules here for your specific applications
# Examples:
# SecRule REQUEST_URI "@beginsWith /api/" "id:1000,phase:1,pass,nolog,ctl:ruleRemoveById=942100"
# SecRule REQUEST_URI "@beginsWith /admin/" "id:1001,phase:1,pass,nolog,ctl:ruleRemoveById=942100"
EOF

    # Configure Nginx to use ModSecurity
    cat > /etc/nginx/conf.d/modsecurity.conf << EOF
modsecurity on;
modsecurity_rules_file /etc/nginx/modsec/main.conf;
EOF
else
    echo "ðŸ³ Skipping ModSecurity configuration in Docker mode (module not available)"
fi

# Install comprehensive nginx security configuration
echo "===== 10.2.1 Installing Nginx Security Configuration ====="

# Create security configuration for blocking common attacks
cat > /etc/nginx/conf.d/security.conf << 'EOF'
# Nginx Security Configuration for PolyServer Applications
# This file contains security rules to block common attacks and sensitive file access

# Hide nginx version information
server_tokens off;

# Block access to sensitive files and directories
location ~ /\. {
    # Block access to hidden files (.git, .env, .htaccess, etc.)
    access_log off;
    log_not_found off;
    deny all;
}

location ~ ^/(\.well-known/acme-challenge/)(.*)$ {
    # Allow Let's Encrypt ACME challenge (exception to hidden files rule)
    allow all;
}

# Block access to common sensitive files
location ~* \.(env|git|gitignore|gitmodules|htaccess|htpasswd|ini|log|sh|sql|conf|config|bak|backup|swp|tmp)$ {
    access_log off;
    log_not_found off;
    deny all;
}

# Block access to README and documentation files
location ~* ^/(readme|README|changelog|CHANGELOG|license|LICENSE|install|INSTALL|upgrade|UPGRADE|todo|TODO).*$ {
    access_log off;
    log_not_found off;
    deny all;
}

# Block access to common admin paths (application-agnostic protection)
location ~* ^/(admin|administrator|wp-admin|wp-login|wp-config|wp-content|wp-includes|wp-json|xmlrpc|phpmyadmin|pma|mysql|adminer|cpanel|plesk|webmail|roundcube|squirrelmail)(.*)$ {
    access_log off;
    log_not_found off;
    return 444; # Close connection without response
}

# Block access to common CMS and framework paths
location ~* ^/(drupal|joomla|wordpress|magento|prestashop|opencart|typo3|concrete5|modx|craft|laravel|symfony|codeigniter|cakephp|zend|yii)(.*)$ {
    access_log off;
    log_not_found off;
    return 444;
}

# Block access to common development/testing paths
location ~* ^/(test|tests|testing|dev|development|staging|demo|backup|backups|old|new|temp|tmp|cache|logs|vendor|node_modules|bower_components)(.*)$ {
    access_log off;
    log_not_found off;
    return 444;
}

# Block access to common exploit paths
location ~* ^/(shell|webshell|c99|c100|r57|r99|backdoor|hack|hacked|exploit|virus|trojan|worm|bot|zombie|scanner|scan|probe|brute|force|attack)(.*)$ {
    access_log off;
    log_not_found off;
    return 444;
}

# Block requests for non-existent scripts that are commonly probed
location ~* \.(asp|aspx|jsp|cgi|pl|py|rb|php|php3|php4|php5|phtml|shtml)$ {
    access_log off;
    log_not_found off;
    return 444;
}

# Block common vulnerability scanners and bad user agents
if ($http_user_agent ~* (nikto|sqlmap|fimap|nessus|openvas|nmap|masscan|zmap|zap|burp|netsparker|acunetix|appscan|webscarab|w3af|skipfish|wapiti|whatweb|gobuster|dirb|dirbuster|ffuf|feroxbuster|nuclei|httpx|subfinder)) {
    access_log off;
    return 444;
}

# Block empty user agents and common bot patterns
if ($http_user_agent ~ ^$) {
    access_log off;
    return 444;
}

# Block suspicious referrers
if ($http_referer ~* (babes|click|diamond|forsale|girl|jewelry|love|nudit|organic|poker|porn|sex|teen|video|webcam|zippo)) {
    access_log off;
    return 444;
}

# Block requests with suspicious query strings
if ($args ~* (\.\./|<script|GLOBALS|globals|javascript:|vbscript:|onload|onerror|onclick)) {
    access_log off;
    return 444;
}

# Block SQL injection attempts in query strings
if ($args ~* (union|select|insert|delete|update|drop|create|alter|exec|execute|script|javascript|vbscript)) {
    access_log off;
    return 444;
}
EOF

# Create proxy parameters file for reusable proxy settings
cat > /etc/nginx/conf.d/proxy_params << 'EOF'
# Common proxy parameters for applications
# This file contains reusable proxy settings

# Timeout settings
proxy_connect_timeout 90s;
proxy_send_timeout 240s;
proxy_read_timeout 240s;

# Use HTTP/1.1 for proxying
proxy_http_version 1.1;

# Enable WebSockets support
proxy_set_header Upgrade $http_upgrade;
proxy_set_header Connection "upgrade";

# Pass important headers for proper operation
proxy_set_header Host $http_host;
proxy_set_header X-Real-IP $remote_addr;
proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
proxy_set_header X-Forwarded-Proto $scheme;
proxy_set_header X-Forwarded-Host $http_host;
proxy_set_header X-Forwarded-Port $server_port;

# Performance optimizations
proxy_buffering off;
proxy_request_buffering off;
proxy_cache_bypass $http_upgrade;
proxy_redirect off;

# Security settings
proxy_hide_header X-Powered-By;
proxy_hide_header Server;
EOF

# Set proper permissions
chmod 644 /etc/nginx/conf.d/security.conf
chmod 644 /etc/nginx/conf.d/proxy_params

echo "Nginx security configuration installed"

# Configure AppArmor for applications
echo "===== 10.3 Setting up AppArmor for applications ====="
echo "AppArmor profile templates are available in /etc/apparmor.d/"
echo "Customize application-specific profiles as needed for your deployments"

# Configure Suricata IDS
echo "===== 10.4 Setting up Suricata Network IDS ====="
if [ "$DOCKER_MODE" = "false" ]; then
    # Configure network interface
    INTERFACE=$(ip -o -4 route show to default | awk '{print $5}')

    # Basic Suricata configuration 
    cat > /etc/suricata/suricata.yaml << EOF
%YAML 1.1
---
# Suricata configuration for PolyServer applications
vars:
  address-groups:
    HOME_NET: "[192.168.0.0/16,10.0.0.0/8,172.16.0.0/12]"
    EXTERNAL_NET: "!$HOME_NET"
    
  port-groups:
    HTTP_PORTS: "80"
    HTTPS_PORTS: "443"
    DB_PORTS: "3306,5432,1521,1433,27017"
    
default-rule-path: /etc/suricata/rules
rule-files:
  - suricata.rules
  - application-custom.rules

af-packet:
  - interface: $INTERFACE
    cluster-id: 99
    cluster-type: cluster_flow
    defrag: yes
    use-mmap: yes
    tpacket-v3: yes
    
# Enable basic alerts
detect-engine:
  profile: medium
  sgh-mpm-context: auto
  inspection-recursion-limit: 3000

# App layer protocol configuration
app-layer:
  protocols:
    # Essential protocols for production applications
    http:
      enabled: yes
    tls:
      enabled: yes
    ssh:
      enabled: yes
    dns:
      enabled: yes
    smtp:
      enabled: yes
    ftp:
      enabled: yes
    http2:
      enabled: yes
    
    # Database and enterprise protocols (might be needed)
    smb:
      enabled: yes
    nfs:
      enabled: yes
    
    # Disable industrial/IoT protocols not needed for web applications
    dcerpc:
      enabled: no
    modbus:
      enabled: no
    enip:
      enabled: no
    dnp3:
      enabled: no
    ntp:
      enabled: no
    tftp:
      enabled: no
    ikev2:
      enabled: no
    krb5:
      enabled: no
    dhcp:
      enabled: no
    snmp:
      enabled: no
    sip:
      enabled: no
    rfb:
      enabled: no
    mqtt:
      enabled: no
    rdp:
      enabled: no
  
# Log configuration
outputs:
  - fast:
      enabled: yes
      filename: fast.log
      
  - eve-log:
      enabled: yes
      filetype: regular
      filename: eve.json
      types:
        - alert
        - http
        - dns
        - tls
        - flow
EOF

# Create custom rules template for applications
cat > /etc/suricata/rules/application-custom.rules << EOF
# Custom application-specific rules
# Add your application-specific Suricata rules here

# Example: Alert on potential SQL injection attempts
# alert http \$EXTERNAL_NET any -> \$HOME_NET any (msg:"APP SQL Injection Attempt"; flow:established,to_server; http.uri; content:"/api/"; nocase; pcre:"/(\%27)|(\')|(\-\-)|(%23)|(#)/i"; classtype:web-application-attack; sid:3000001; rev:1;)

# Example: Alert on brute force attempts 
# alert http \$EXTERNAL_NET any -> \$HOME_NET any (msg:"APP Authentication Brute Force Attempt"; flow:established,to_server; http.uri; content:"/login"; threshold:type threshold, track by_src, count 5, seconds 60; classtype:attempted-admin; sid:3000002; rev:1;)
EOF

# Set up Suricata log rotation
cat > /etc/logrotate.d/suricata << EOF
/var/log/suricata/*.log /var/log/suricata/*.json {
    daily
    rotate 7
    compress
    delaycompress
    missingok
    notifempty
    create 0640 root adm
    postrotate
        systemctl restart suricata
    endscript
}
EOF

# Install Trivy for container scanning
curl -sfL https://raw.githubusercontent.com/aquasecurity/trivy/main/contrib/install.sh | sh -s -- -b /usr/local/bin

# Create directory for security logs
mkdir -p /var/log/security/trivy

# Create cron job for daily container scanning
cat > /etc/cron.daily/trivy-scan << 'EOF'
#!/bin/bash
# Daily container vulnerability scanning

REPORT_DIR="/var/log/security/trivy"
DATE=$(date +%Y-%m-%d)
MAIL_RECIPIENT="${LOGWATCH_EMAIL:-root}"
HOSTNAME=$(hostname)
TRIVYLOG="${REPORT_DIR}/trivy-${DATE}.log"

# Create report directory if it doesn't exist
mkdir -p $REPORT_DIR

# Update Trivy vulnerability database
/usr/local/bin/trivy image --download-db-only > /dev/null 2>&1

# Start log file
echo "===== Container Vulnerability Scan Report: $DATE =====" > $TRIVYLOG

# Scan running containers
CONTAINERS=$(docker ps --format "{{.Image}}")
for IMAGE in $CONTAINERS; do
    echo "Scanning image: $IMAGE" >> $TRIVYLOG
    /usr/local/bin/trivy image --no-progress --severity HIGH,CRITICAL $IMAGE >> $TRIVYLOG
    echo "-----------------------------------------" >> $TRIVYLOG
done

# Email report if vulnerabilities found
if grep -q "CRITICAL\|HIGH" $TRIVYLOG; then
    cat $TRIVYLOG | mail -s "âš ï¸ CONTAINER VULNERABILITIES: Found on $HOSTNAME" $MAIL_RECIPIENT
fi

# Cleanup old reports
find $REPORT_DIR -name "trivy-*.log" -mtime +30 -delete
EOF

chmod 755 /etc/cron.daily/trivy-scan

    # Configure Suricata systemd resource limits
    echo "===== 10.4.1 Configuring Suricata Resource Management ====="
    mkdir -p /etc/systemd/system/suricata.service.d
    cat > /etc/systemd/system/suricata.service.d/resource-limits.conf << 'EOF'
[Service]
# Resource limits to prevent Suricata from overwhelming system
CPUQuota=50%
MemoryMax=1G
MemoryHigh=800M
Nice=5
IOSchedulingClass=2
IOSchedulingPriority=4
OOMPolicy=kill
OOMScoreAdjust=200

# Security and isolation
PrivateTmp=true
NoNewPrivileges=true
ProtectHome=true
ProtectSystem=strict
ReadWritePaths=/var/log/suricata /var/lib/suricata /run/suricata

# Restart policy for network IDS reliability
Restart=always
RestartSec=60
TimeoutStartSec=120
TimeoutStopSec=30

# Watchdog configuration
WatchdogSec=300
NotifyAccess=main
EOF

    systemctl daemon-reload

    # Enable and start Suricata
    systemctl enable suricata
    systemctl start suricata
else
    echo "ðŸ³ Skipping Suricata configuration in Docker mode"
fi

# Configure Logwatch
echo "===== 10. Configuring Logwatch ====="
mkdir -p /var/cache/logwatch

# Create Logwatch configuration
cat > /etc/logwatch/conf/logwatch.conf << EOF
# Logwatch Configuration

# Default logwatch output format
Output = mail

# Default person to mail reports to
MailTo = ${LOGWATCH_EMAIL:-root}

# Default logwatch format
Format = html

# Default range
Range = yesterday

# Default detail level
Detail = Med

# Include hardware sensors in output
Service = zz-lm_sensors

# Support for lm_sensors data
Service = zz-disk_space

# Enhanced email/sendmail reporting
Service = postfix
Service = sendmail

# Always show empty sections
Show_Empty_Sections = yes
EOF

# Create enhanced postfix/sendmail service configuration for detailed reporting
mkdir -p /etc/logwatch/conf/services
cat > /etc/logwatch/conf/services/postfix.conf << EOF
# Enhanced Postfix reporting for servers
Title = "Mail System (Postfix/Sendmail)"
LogFile = mail
LogFile = maillog
*OnlyService = postfix
*RemoveHeaders = Yes
Detail = High
EOF

# Create custom sendmail/postfix logwatch script for server-specific analysis
mkdir -p /etc/logwatch/scripts/services
cat > /etc/logwatch/scripts/services/postfix << 'EOF'
#!/usr/bin/perl
# Enhanced Postfix/Sendmail analysis for servers
# Focuses on security-relevant email events

use strict;
use warnings;

my %sent_count = ();
my %received_count = ();
my %rejected_count = ();
my %bounced_count = ();
my %smtp_stats = ();
my %security_events = ();
my %relay_attempts = ();
my @critical_events = ();

while (my $line = <STDIN>) {
    chomp $line;
    
    # Skip lines that don't contain postfix/sendmail
    next unless $line =~ /(postfix|sendmail)/;
    
    # Extract timestamp
    my ($timestamp) = $line =~ /^(\w+\s+\d+\s+\d+:\d+:\d+)/;
    
    # Count sent messages
    if ($line =~ /status=sent/) {
        $sent_count{total}++;
        if ($line =~ /relay=([^,\s]+)/) {
            $sent_count{$1}++;
        }
    }
    
    # Count received messages
    elsif ($line =~ /status=deferred|status=bounced/) {
        $bounced_count{total}++;
        if ($line =~ /(Connection refused|timeout|Host not found)/i) {
            $bounced_count{$1}++;
        }
    }
    
    # Track SMTP security events
    elsif ($line =~ /(SASL|TLS|SSL)/) {
        if ($line =~ /SASL.*authentication failed/i) {
            $security_events{"SASL Authentication Failed"}++;
            push @critical_events, "$timestamp: SASL auth failure";
        }
        elsif ($line =~ /(TLS|SSL).*established/i) {
            $smtp_stats{"TLS Connections"}++;
        }
        elsif ($line =~ /Anonymous TLS connection established/i) {
            $smtp_stats{"Anonymous TLS"}++;
        }
    }
    
    # Track relay attempts (security concern)
    elsif ($line =~ /Relay access denied/i) {
        $security_events{"Unauthorized Relay Attempts"}++;
        if ($line =~ /from=<([^>]*)>.*to=<([^>]*)>/) {
            push @critical_events, "$timestamp: Relay attempt from $1 to $2";
        }
    }
    
    # Track connection rejections
    elsif ($line =~ /(reject|blocked|denied)/i) {
        $rejected_count{total}++;
        if ($line =~ /Client host rejected/i) {
            $rejected_count{"Host Rejection"}++;
        }
        elsif ($line =~ /Sender address rejected/i) {
            $rejected_count{"Sender Rejection"}++;
        }
    }
    
    # Track postfix warnings and errors
    elsif ($line =~ /(warning|error|fatal)/i) {
        if ($line =~ /warning.*SASL/i) {
            $security_events{"SASL Warnings"}++;
        }
        elsif ($line =~ /error.*timeout/i) {
            $smtp_stats{"Timeout Errors"}++;
        }
    }
    
    # Track queue statistics
    elsif ($line =~ /postfix\/qmgr.*removed/) {
        $smtp_stats{"Messages Processed"}++;
    }
}

# Generate report
print "\n";
print "=" x 60 . "\n";
print "SERVER MAIL SYSTEM REPORT\n";
print "=" x 60 . "\n\n";

# Mail delivery statistics
if (keys %sent_count || keys %bounced_count) {
    print "ðŸ“§ MAIL DELIVERY STATISTICS:\n";
    print "-" x 30 . "\n";
    
    if ($sent_count{total}) {
        print "âœ… Successfully sent: $sent_count{total} messages\n";
        foreach my $relay (sort keys %sent_count) {
            next if $relay eq 'total';
            print "   â†’ via $relay: $sent_count{$relay}\n";
        }
    }
    
    if ($bounced_count{total}) {
        print "âš ï¸  Bounced/Deferred: $bounced_count{total} messages\n";
        foreach my $reason (sort keys %bounced_count) {
            next if $reason eq 'total';
            print "   â†’ $reason: $bounced_count{$reason}\n";
        }
    }
    
    if ($rejected_count{total}) {
        print "ðŸš« Rejected: $rejected_count{total} messages\n";
        foreach my $reason (sort keys %rejected_count) {
            next if $reason eq 'total';
            print "   â†’ $reason: $rejected_count{$reason}\n";
        }
    }
    print "\n";
}

# SMTP/TLS statistics
if (keys %smtp_stats) {
    print "ðŸ” SMTP/TLS STATISTICS:\n";
    print "-" x 25 . "\n";
    foreach my $stat (sort keys %smtp_stats) {
        print "â€¢ $stat: $smtp_stats{$stat}\n";
    }
    print "\n";
}

# Security events (important for servers)
if (keys %security_events) {
    print "ðŸš¨ SECURITY EVENTS:\n";
    print "-" x 20 . "\n";
    foreach my $event (sort keys %security_events) {
        my $count = $security_events{$event};
        my $indicator = $count > 5 ? "âš ï¸ " : "â€¢ ";
        print "$indicator$event: $count\n";
    }
    print "\n";
}

# Critical events detail
if (@critical_events) {
    print "ðŸ” CRITICAL EVENT DETAILS:\n";
    print "-" x 28 . "\n";
    foreach my $event (@critical_events) {
        print "â€¢ $event\n";
    }
    print "\n";
}

# Recommendations for servers
if ($security_events{"Unauthorized Relay Attempts"} > 0) {
    print "âš ï¸  SECURITY RECOMMENDATIONS:\n";
    print "-" x 32 . "\n";
    print "â€¢ Review relay restrictions in postfix configuration\n";
    print "â€¢ Consider implementing stricter sender verification\n";
    print "â€¢ Monitor source IPs for relay attempts\n\n";
}

if (!$smtp_stats{"TLS Connections"} && $sent_count{total}) {
    print "âš ï¸  TLS RECOMMENDATIONS:\n";
    print "-" x 23 . "\n";
    print "â€¢ Consider enforcing TLS for all SMTP connections\n";
    print "â€¢ Review SMTP authentication security\n\n";
}

print "ðŸ“‹ For detailed logs, check: /var/log/mail.log\n";
print "ðŸ”§ Mail queue status: mailq\n";
print "ðŸ“Š Postfix configuration: postconf -n\n\n";
EOF

chmod +x /etc/logwatch/scripts/services/postfix

# Create logwatch cron job - use only cron.d for precise timing
# Remove any existing daily cron to prevent duplicates
rm -f /etc/cron.daily/00logwatch

# Configure logwatch to run once daily at 6:00 AM
cat > /etc/cron.d/logwatch << EOF
# Daily logwatch execution for server
# Run at 6:00 AM daily to analyze previous day's logs
0 6 * * * root /usr/sbin/logwatch --output mail --format html --range yesterday --detail high
EOF

# Create custom service for lm_sensors
mkdir -p /etc/logwatch/scripts/services
cat > /etc/logwatch/scripts/services/zz-lm_sensors << 'EOF'
#!/bin/bash
echo "Hardware Sensor Information:"
echo ""
sensors | grep -v "Adapter:" | grep -v "^$" | sed -e 's/^/   /'
echo ""
echo "Disk Temperature:"
echo ""
hddtemp /dev/sd? 2>/dev/null | sed -e 's/^/   /' || echo "   No disk temperature data available"
EOF
chmod 755 /etc/logwatch/scripts/services/zz-lm_sensors

# Create service definition
mkdir -p /etc/logwatch/conf/services
cat > /etc/logwatch/conf/services/zz-lm_sensors.conf << EOF
# Logwatch configuration file for lm_sensors

Title = "Hardware Sensors"
EOF

# Configure RKHunter
echo "===== 10. Configuring RKHunter ====="
if [ "$DOCKER_MODE" = "false" ]; then
    # Update rkhunter database
    rkhunter --update

    # Set up RKHunter properties
    cat > /etc/rkhunter.conf.local << EOF
# RKHunter configuration overrides

# Update database on a daily basis
UPDATE_MIRRORS=1
MIRRORS_MODE=0
UPDATE_MIRRORS=1
WEB_CMD="DISABLED"

# Mail options - same email as logwatch
MAIL-ON-WARNING=${LOGWATCH_EMAIL:-root}
COPY_LOG_ON_ERROR=1

# Scan options
SCAN_DEV_DIR=1
SCAN_WORLD_WRITABLE=1
ALLOW_SSH_ROOT_USER=no
XINETD_ALLOWED_SVC=
DISABLE_CHECK_PORTS=0

# Allow certain whitelisted files
#ALLOWHIDDENDIR=/dev/.udev
#ALLOWHIDDENFILE=/dev/.blkid.tab
EOF

# Create RKHunter scan script
cat > /etc/cron.daily/rkhunter-scan << 'EOF'
#!/bin/bash
# Run a daily RKHunter scan

# Log file
LOGFILE="/var/log/rkhunter/daily_scan.log"

# Create log directory if it doesn't exist
mkdir -p /var/log/rkhunter

# Clear previous log
echo "RKHunter daily scan started at $(date)" > $LOGFILE

# Run the scan
rkhunter --check --skip-keypress --report-warnings-only >> $LOGFILE 2>&1

# Add completion time
echo "RKHunter daily scan completed at $(date)" >> $LOGFILE

# Check for warnings and alert if found
if grep -q "Warning:" $LOGFILE; then
    WARNING_COUNT=$(grep -c "Warning:" $LOGFILE)
    ADMIN_EMAIL=$(grep "^MAIL-ON-WARNING=" /etc/rkhunter.conf.local | cut -d= -f2)
    # If no email is set, use root
    if [ -z "$ADMIN_EMAIL" ]; then
        ADMIN_EMAIL="root"
    fi
    
    # Send email alert
    cat $LOGFILE | mail -s "âš ï¸ ROOTKIT WARNING: ${WARNING_COUNT} suspicious items found on $(hostname)" "$ADMIN_EMAIL"
fi
EOF
chmod 755 /etc/cron.daily/rkhunter-scan

    # Run initial scan to establish baseline
    echo "Running initial RKHunter scan to create baseline..."
    rkhunter --propupd
    rkhunter --check --skip-keypress --report-warnings-only
else
    echo "ðŸ³ Skipping RKHunter configuration in Docker mode"
fi

# Configure chkrootkit daily scan
cat > /etc/cron.daily/chkrootkit-scan << 'EOF'
#!/bin/bash
# Run a daily chkrootkit scan

# Log file
LOGFILE="/var/log/chkrootkit/daily_scan.log"

# Create log directory if it doesn't exist
mkdir -p /var/log/chkrootkit

# Clear previous log
echo "chkrootkit daily scan started at $(date)" > $LOGFILE

# Run the scan
chkrootkit -q >> $LOGFILE 2>&1

# Add completion time
echo "chkrootkit daily scan completed at $(date)" >> $LOGFILE

# Check for warnings and alert if found (chkrootkit outputs "INFECTED" when it finds something)
if grep -q "INFECTED" $LOGFILE; then
    ADMIN_EMAIL=$(grep "^MAIL-ON-WARNING=" /etc/rkhunter.conf.local | cut -d= -f2)
    # If no email is set, use root
    if [ -z "$ADMIN_EMAIL" ]; then
        ADMIN_EMAIL="root"
    fi
    
    # Send email alert
    cat $LOGFILE | mail -s "âš ï¸ ROOTKIT WARNING: Possible rootkit found on $(hostname)" "$ADMIN_EMAIL"
fi
EOF
chmod 755 /etc/cron.daily/chkrootkit-scan

# ========= Block Storage Setup =========
echo "===== 7. Setting up block storage for backups ====="
if [ -e "$BLOCK_DEVICE" ]; then
  mkdir -p $BACKUP_MOUNT
  
  # Check if the device is already formatted
  if ! blkid $BLOCK_DEVICE &>/dev/null; then
    echo "Formatting block storage device"
    mkfs.ext4 $BLOCK_DEVICE
  fi
  
  # Add to fstab for auto-mounting
  if ! grep -q "$BACKUP_MOUNT" /etc/fstab; then
    echo "$BLOCK_DEVICE $BACKUP_MOUNT ext4 defaults,noatime 0 2" >> /etc/fstab
  fi
  
  # Mount the device
  mount $BACKUP_MOUNT || true
  
  # Create backup directories
  mkdir -p $BACKUP_MOUNT/backups
  chmod 750 $BACKUP_MOUNT/backups
fi

# ========= Docker Installation =========
# Check if we need Docker (deployment mode is "docker" or just always install for flexibility)
if [ "$DEPLOYMENT_MODE" = "docker" ] || [ "$DOCKER_MODE" = "false" ]; then
    echo "===== 8. Installing Docker and Docker Compose ====="
    echo "Installing Docker for deployment mode: $DEPLOYMENT_MODE"
    
    apt-get install -y apt-transport-https ca-certificates curl software-properties-common gnupg lsb-release

    # Add Docker repository for Debian
    curl -fsSL https://download.docker.com/linux/debian/gpg | gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg
    echo "deb [arch=amd64 signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/debian $(lsb_release -cs) stable" | tee /etc/apt/sources.list.d/docker.list > /dev/null
    apt-get update
    apt-get install -y docker-ce docker-ce-cli containerd.io docker-compose-plugin

    # Start Docker
    docker_systemctl enable docker
    docker_systemctl start docker

    # Add user to Docker group
    usermod -aG docker $USERNAME

    # Docker security hardening
    cat > /etc/docker/daemon.json << EOF
{
  "log-driver": "json-file",
  "log-opts": {
    "max-size": "10m",
    "max-file": "3"
  },
  "live-restore": true,
  "userland-proxy": false,
  "no-new-privileges": true,
  "icc": false
}
EOF

    docker_systemctl restart docker
    
    if [ "$DEPLOYMENT_MODE" = "docker" ]; then
        echo "Docker mode: Container orchestration ready for applications"
        
        # Create Docker networks for applications
        docker network create polyserver-network 2>/dev/null || echo "Network polyserver-network already exists"
        
        # Create directories for Docker-managed volumes
        mkdir -p /opt/polyserver/docker/{volumes,compose}
        chown -R $USERNAME:$USERNAME /opt/polyserver/docker
    fi
else
    echo "ðŸ³ Skipping Docker installation (testing mode)"
fi

# ========= Install Netdata Monitoring =========
echo "===== 8.1 Installing Netdata monitoring ====="
if [ "$DOCKER_MODE" = "false" ] && [ "$NETDATA_ENABLED" = "true" ]; then
    echo "Installing Netdata monitoring agent..."
    
    # Download and run the official installer
    echo "Downloading Netdata installer..."
    if curl -o /tmp/netdata-kickstart.sh https://get.netdata.cloud/kickstart.sh; then
        echo "Running Netdata installation..."
        
        # Check if claim token is provided via template variables
        NETDATA_CLAIM_TOKEN="{{NETDATA_CLAIM_TOKEN}}"
        NETDATA_CLAIM_ROOMS="{{NETDATA_CLAIM_ROOMS}}"
        
        if [ -n "$NETDATA_CLAIM_TOKEN" ] && [ "$NETDATA_CLAIM_TOKEN" != "{{NETDATA_CLAIM_TOKEN}}" ]; then
            echo "Installing with Netdata Cloud integration (from configuration)..."
            sh /tmp/netdata-kickstart.sh --stable-channel --disable-telemetry --claim-token "$NETDATA_CLAIM_TOKEN" --claim-rooms "$NETDATA_CLAIM_ROOMS"
        else
            echo "Installing without Netdata Cloud (local monitoring only)..."
            sh /tmp/netdata-kickstart.sh --stable-channel --disable-telemetry --dont-wait
        fi
        
        # Clean up installer
        rm -f /tmp/netdata-kickstart.sh
    else
        echo "âš ï¸ Failed to download Netdata installer, trying fallback method..."
        
        # Fallback: install via package manager
        if command -v apt-get >/dev/null 2>&1; then
            apt-get update
            apt-get install -y netdata
        else
            echo "âŒ Failed to install Netdata - please install manually"
            echo "   Visit: https://learn.netdata.cloud/docs/installing/one-line-installer-for-all-linux-systems"
            NETDATA_ENABLED="false"
        fi
    fi
    
    # Check if Netdata was successfully installed
    if ! command -v netdata >/dev/null 2>&1 && ! systemctl is-active --quiet netdata; then
        echo "âŒ Netdata installation verification failed"
        NETDATA_ENABLED="false"
    fi
fi

if [ "$DOCKER_MODE" = "false" ] && [ "$NETDATA_ENABLED" = "true" ] && [ "$NETDATA_ENABLED" != "false" ]; then
    # Configure Netdata for secure server monitoring
    echo "Configuring Netdata for secure server monitoring..."
    
    # Create minimal security-focused configuration
    cat > /etc/netdata/netdata.conf << 'EOF'
[global]
    # SECURITY: Bind to localhost only (access via SSH tunnel or Nginx proxy)
    bind socket to IP = 127.0.0.1
    default port = 19999
    
    # Performance optimized for server
    page cache size = 32
    dbengine multihost disk space = 128
    
[web]
    # No authentication needed since localhost-only
    web files owner = root
    web files group = netdata
    
EOF

    # Enable and start Netdata
    docker_systemctl enable netdata
    docker_systemctl restart netdata

    # Wait for Netdata to start
    sleep 3

    # Optional Netdata Cloud Integration (show instructions if not configured)
    NETDATA_CLAIM_TOKEN="{{NETDATA_CLAIM_TOKEN}}"
    NETDATA_CLAIM_ROOMS="{{NETDATA_CLAIM_ROOMS}}"
    
    if [ -z "$NETDATA_CLAIM_TOKEN" ] || [ "$NETDATA_CLAIM_TOKEN" = "{{NETDATA_CLAIM_TOKEN}}" ]; then
        echo ""
        echo "ðŸ“Š NETDATA CLOUD INTEGRATION (Optional)"
        echo "======================================"
        echo "To add this server to Netdata Cloud for centralized monitoring:"
        echo ""
        echo "1. Sign up/login at: https://app.netdata.cloud"
        echo "2. Create a new space or select existing space"
        echo "3. Go to 'Connect Nodes' and copy your claim token"
        echo "4. Run the following command on this server:"
        echo ""
        echo "   sudo /opt/netdata/bin/netdata-claim.sh \\"
        echo "     -token=YOUR_CLAIM_TOKEN \\"
        echo "     -rooms=YOUR_ROOM_ID \\"
        echo "     -url=https://app.netdata.cloud"
        echo ""
        echo "5. Your server will appear in Netdata Cloud within 1-2 minutes"
        echo ""
        echo "ðŸ“ To set up automatic claiming, add these to your .env file:"
        echo "   NETDATA_CLAIM_TOKEN=your_claim_token"
        echo "   NETDATA_CLAIM_ROOMS=your_room_id"
        echo ""
    else
        echo "âœ… Netdata Cloud integration configured from template variables"
        echo "   â€¢ Server should appear in your Netdata Cloud dashboard within a few minutes"
        echo "   â€¢ Login at: https://app.netdata.cloud"
    fi

    # Create Netdata log rotation
    cat > /etc/logrotate.d/netdata << 'EOF'
/var/log/netdata/*.log {
    daily
    rotate 14
    missingok
    notifempty
    compress
    delaycompress
    postrotate
        systemctl reload netdata > /dev/null 2>&1 || true
    endscript
}
EOF

    # Create access script for easy local access
    cat > /usr/local/bin/netdata-access << 'EOF'
#!/bin/bash
# Quick access to local Netdata dashboard
echo "ðŸŒ Opening Netdata dashboard..."
echo "   Local URL: http://127.0.0.1:19999"
echo "   SSH Tunnel: ssh -L 19999:127.0.0.1:19999 user@server"
echo "   Netdata Cloud: https://app.netdata.cloud"
EOF
    chmod +x /usr/local/bin/netdata-access

    echo "âœ… Netdata monitoring installed and configured"
    echo "   â€¢ Local access: http://127.0.0.1:19999 (via SSH tunnel)"
    echo "   â€¢ Quick access command: netdata-access"
elif [ "$DOCKER_MODE" = "false" ] && [ "$NETDATA_ENABLED" != "true" ]; then
    echo "ðŸ“Š Netdata monitoring disabled (NETDATA_ENABLED=false)"
    echo "   To enable: Set NETDATA_ENABLED=true in your configuration"
else
    echo "ðŸ³ Skipping Netdata configuration in Docker mode"
fi

# ========= Setup Directories =========
echo "===== 9. Setting up PolyServer directories ====="
mkdir -p /opt/polyserver/{data,backups,config,scripts}
chown -R $USERNAME:$USERNAME /opt/polyserver
chmod -R 750 /opt/polyserver

# ========= Setup Unbound DNS Cache =========
echo "===== 10. Setting up Unbound DNS cache ====="
if [ "$DOCKER_MODE" = "false" ]; then
    # Enable and start Unbound service
    docker_systemctl enable unbound
    docker_systemctl start unbound

    # Configure DHCP client to preserve DNS settings
    cat > /etc/dhcp/dhclient.conf << EOF
# dhclient.conf - Configuration for DHCP client
# This configuration preserves the DNS settings across DHCP renewals

# Don't override the nameserver with the one provided by DHCP
supersede domain-name-servers 127.0.0.1;

# Request basic network configuration from DHCP server
request subnet-mask, broadcast-address, time-offset, routers,
        domain-name, domain-name-servers, domain-name-search,
        host-name, netbios-name-servers, netbios-scope, interface-mtu,
        ntp-servers;

# Timeout settings
timeout 60;
retry 60;
reboot 10;
select-timeout 5;
initial-interval 2;
EOF

# Update resolv.conf right now
echo "nameserver 127.0.0.1" > /etc/resolv.conf

# Configure system to use our DNS resolver (Debian networking)
# Debian uses traditional /etc/network/interfaces or systemd-resolved
# Make resolv.conf immutable to prevent DHCP from overwriting it
chattr +i /etc/resolv.conf

# Configure systemd-resolved to use our local DNS
if systemctl is-active --quiet systemd-resolved; then
  mkdir -p /etc/systemd/resolved.conf.d
  cat > /etc/systemd/resolved.conf.d/local-dns.conf << EOF
[Resolve]
DNS=127.0.0.1
FallbackDNS=8.8.8.8 1.1.1.1
DNSSEC=yes
DNSOverTLS=opportunistic
Cache=yes
EOF
  systemctl restart systemd-resolved
fi

# Configure Unbound
cat > /etc/unbound/unbound.conf.d/local.conf << EOF
server:
    # Bind to localhost only for security
    interface: 127.0.0.1
    access-control: 127.0.0.1 allow
    
    # Verbosity level (1 is standard)
    verbosity: 1
    
    # Performance optimizations
    prefetch: yes
    cache-min-ttl: 3600      # Cache results for at least 1 hour
    cache-max-ttl: 86400     # Maximum cache time = 1 day
    msg-cache-size: 128m     # Increase cache size for faster responses
    rrset-cache-size: 256m   # Cache DNS record sets
    neg-cache-size: 64m      # Cache negative responses
    
    # Security settings
    hide-identity: yes
    hide-version: yes
    use-caps-for-id: yes
    qname-minimisation: yes
    
    # Logging settings
    log-queries: no
    log-replies: no
    log-servfail: yes
    logfile: "/var/log/unbound.log"
    
    # DNSSEC validation
    auto-trust-anchor-file: "/var/lib/unbound/root.key"
    val-clean-additional: yes

# Forward queries to upstream DNS providers
forward-zone:
    name: "."
    forward-addr: 8.8.8.8    # Google DNS
    forward-addr: 1.1.1.1    # Cloudflare DNS
EOF

    # Restart Unbound service to apply changes
    docker_systemctl restart unbound

    # Create log file with proper permissions
    touch /var/log/unbound.log
    chmod 640 /var/log/unbound.log
    chown unbound:adm /var/log/unbound.log

    # Add log rotation configuration
    cat > /etc/logrotate.d/unbound << EOF
/var/log/unbound.log {
    weekly
    rotate 12
    compress
    delaycompress
    missingok
    notifempty
    create 640 unbound adm
    postrotate
        service unbound restart > /dev/null
    endscript
}
EOF

    # Test DNS resolution
    echo "Testing DNS resolution through Unbound..."
    dig @127.0.0.1 google.com | grep -A2 "ANSWER SECTION"
else
    echo "ðŸ³ Skipping Unbound DNS cache setup in Docker mode"
fi

# ========= Configure comprehensive log rotation =========
echo "===== 10.5 Setting up comprehensive log rotation ====="

# Nginx log rotation (includes ModSecurity logs)
cat > /etc/logrotate.d/nginx << 'EOF'
/var/log/nginx/*.log {
    daily
    rotate 30
    compress
    delaycompress
    missingok
    notifempty
    create 0640 www-data adm
    sharedscripts
    prerotate
        if [ -d /etc/logrotate.d/httpd-prerotate ]; then \
            run-parts /etc/logrotate.d/httpd-prerotate; \
        fi \
    endprerotate
    postrotate
        systemctl reload nginx > /dev/null 2>&1 || true
    endscript
}

# ModSecurity audit logs (separate rotation for large files)
/var/log/nginx/modsec_audit.log /var/log/nginx/modsec_debug.log {
    daily
    rotate 14
    size 100M
    compress
    delaycompress
    missingok
    notifempty
    create 0640 www-data adm
    copytruncate
}
EOF

# Security scan logs rotation
cat > /etc/logrotate.d/security-scans << 'EOF'
# ClamAV scan logs
/var/log/clamav/daily_scan.log {
    weekly
    rotate 12
    compress
    delaycompress
    missingok
    notifempty
    create 0644 root root
}

# Malware detection logs
/var/log/maldet/daily_scan.log {
    weekly
    rotate 12
    compress
    delaycompress
    missingok
    notifempty
    create 0644 root root
}

# RKHunter scan logs
/var/log/rkhunter/daily_scan.log {
    weekly
    rotate 12
    compress
    delaycompress
    missingok
    notifempty
    create 0644 root root
}

# chkrootkit scan logs
/var/log/chkrootkit/daily_scan.log {
    weekly
    rotate 12
    compress
    delaycompress
    missingok
    notifempty
    create 0644 root root
}
EOF

# Container security logs rotation
cat > /etc/logrotate.d/container-security << 'EOF'
# Trivy container vulnerability scan logs
/var/log/security/trivy/*.log {
    weekly
    rotate 8
    compress
    delaycompress
    missingok
    notifempty
    create 0644 root root
}

# Docker logs (if using json-file driver)
/var/lib/docker/containers/*/*.log {
    daily
    rotate 7
    size 100M
    compress
    delaycompress
    missingok
    notifempty
    copytruncate
}
EOF

# PolyServer application logs rotation
cat > /etc/logrotate.d/polyserver << 'EOF'
# PolyServer application logs
/opt/polyserver/logs/*.log {
    daily
    rotate 30
    compress
    delaycompress
    missingok
    notifempty
    create 0644 deploy deploy
    copytruncate
}

# PolyServer backup logs
/opt/polyserver/backups/*.log {
    weekly
    rotate 12
    compress
    delaycompress
    missingok
    notifempty
    create 0644 deploy deploy
}

# DSGVO/GDPR logs
/var/log/dsgvo/*.log {
    monthly
    rotate 24
    compress
    delaycompress
    missingok
    notifempty
    create 0644 root root
}

# Security incident logs
/var/log/security/incidents/*.log {
    monthly
    rotate 36
    compress
    delaycompress
    missingok
    notifempty
    create 0600 root root
}
EOF

# Fail2ban log rotation (enhance default)
cat > /etc/logrotate.d/fail2ban << 'EOF'
/var/log/fail2ban.log {
    weekly
    rotate 12
    compress
    delaycompress
    missingok
    notifempty
    create 0644 root root
    postrotate
        systemctl reload fail2ban > /dev/null 2>&1 || true
    endscript
}
EOF

# UFW firewall log rotation
cat > /etc/logrotate.d/ufw << 'EOF'
/var/log/ufw.log {
    daily
    rotate 30
    compress
    delaycompress
    missingok
    notifempty
    create 0640 root adm
}
EOF

# Logwatch logs rotation
cat > /etc/logrotate.d/logwatch << 'EOF'
/var/log/logwatch/*.log {
    monthly
    rotate 12
    compress
    delaycompress
    missingok
    notifempty
    create 0644 root root
}
EOF

echo "Comprehensive log rotation configured for all PolyServer components"

# Enhanced application-specific log rotation (avoiding system conflicts)
# Only configure logs that are not managed by default system logrotate

# Sudo activity logs (extend default retention for security monitoring)
cat > /etc/logrotate.d/polyserver-sudo << 'EOF'
# Sudo activity logs (important for privilege escalation monitoring)
/var/log/sudo.log {
    daily
    rotate 90
    compress
    delaycompress
    missingok
    notifempty
    create 0640 root adm
    postrotate
        systemctl reload rsyslog > /dev/null 2>&1 || true
    endscript
}
EOF

# AIDE logs (application-specific)
cat > /etc/logrotate.d/polyserver-aide << 'EOF'
# AIDE integrity check logs
/var/log/aide/aide-check.log {
    weekly
    rotate 12
    compress
    delaycompress
    missingok
    notifempty
    create 0640 root root
}
EOF

# Note: auth.log, syslog, and kern.log are already managed by system default logrotate
# We avoid creating conflicting configurations for these files

echo "âœ… Application-specific log rotation configured (avoiding system conflicts)"

# ========= Additional security hardening =========
echo "===== 11. Additional security hardening ====="

echo "===== 11.1 Setting up system resource limits (ulimits) ====="
# Prevent resource exhaustion attacks with sensible limits
cat > /etc/security/limits.d/server.conf << EOF
# Server Resource Limits
# Prevent resource exhaustion attacks and improve system stability

# Limits for all users
* soft nofile 4096
* hard nofile 8192
* soft nproc 1024
* hard nproc 2048
* soft core 0
* hard core 0
* soft memlock 64
* hard memlock 64

# Deploy user limits
{{USERNAME}} soft nofile 2048
{{USERNAME}} hard nofile 4096
{{USERNAME}} soft nproc 512
{{USERNAME}} hard nproc 1024
{{USERNAME}} soft maxlogins 10
{{USERNAME}} hard maxlogins 20

# Root user (for system processes)
root soft nofile 8192
root hard nofile 16384
root soft nproc 4096
root hard nproc 8192

# Service accounts
www-data soft nofile 2048
www-data hard nofile 4096
www-data soft nproc 512
www-data hard nproc 1024
EOF

echo "âœ… System resource limits configured to prevent resource exhaustion attacks"

echo "===== 11.2 Adding systemd journal rate limiting ====="
# Prevent log flooding that could fill disk space
mkdir -p /etc/systemd/journald.conf.d
cat > /etc/systemd/journald.conf.d/99-server-limits.conf << EOF
# Server Journal Configuration
# Prevent disk space exhaustion from excessive logging

[Journal]
# Limit journal size to prevent disk full
SystemMaxUse=1G
SystemKeepFree=2G
SystemMaxFileSize=100M
RuntimeMaxUse=200M
RuntimeKeepFree=1G
RuntimeMaxFileSize=20M

# Rate limiting to prevent log flooding
RateLimitIntervalSec=30s
RateLimitBurst=10000

# Compress logs to save space
Compress=yes

# Forward to syslog (rsyslog) for processing
ForwardToSyslog=yes
ForwardToConsole=no
EOF

docker_systemctl restart systemd-journald
echo "âœ… Systemd journal rate limiting configured"

echo "===== 11.3 Adding kernel security parameters ====="
# Set secure kernel parameters including auto-reboot on panic
cat > /etc/sysctl.d/99-server-security.conf << EOF
# Server Security Kernel Parameters

# Network security
net.ipv4.ip_forward = 0
net.ipv4.conf.all.send_redirects = 0
net.ipv4.conf.default.send_redirects = 0
net.ipv4.conf.all.accept_redirects = 0
net.ipv4.conf.default.accept_redirects = 0
net.ipv4.conf.all.accept_source_route = 0
net.ipv4.conf.default.accept_source_route = 0
net.ipv4.conf.all.log_martians = 1
net.ipv4.conf.default.log_martians = 1
net.ipv4.icmp_echo_ignore_broadcasts = 1
net.ipv4.icmp_ignore_bogus_error_responses = 1
net.ipv4.tcp_syncookies = 1

# IPv6 security (disable if not needed)
net.ipv6.conf.all.disable_ipv6 = 1
net.ipv6.conf.default.disable_ipv6 = 1

# Process security
kernel.dmesg_restrict = 1
kernel.kptr_restrict = 2
kernel.yama.ptrace_scope = 1

# File system security
fs.suid_dumpable = 0
fs.protected_hardlinks = 1
fs.protected_symlinks = 1

# Automatic reboot after kernel panic (headless environment)
kernel.panic = 10
kernel.panic_on_oops = 1
EOF

# Apply kernel parameters
if [ "$DOCKER_MODE" = "false" ]; then
    sysctl -p /etc/sysctl.d/99-server-security.conf
    echo "âœ… Kernel security parameters and panic auto-reboot configured"
else
    echo "ðŸ³ Docker mode: skipping sysctl parameter application (not permitted in containers)"
fi

echo "===== 11.4 Blacklisting unused filesystem modules ====="
# Disable unused filesystems that could be security risks
cat > /etc/modprobe.d/blacklist-filesystems.conf << EOF
# Blacklist unused filesystems for security

# Legacy/rare filesystems
blacklist cramfs
blacklist freevxfs
blacklist jffs2
blacklist hfs
blacklist hfsplus
blacklist squashfs
blacklist udf

# FireWire - rarely needed on servers
blacklist firewire-core
blacklist firewire-ohci
blacklist firewire-sbp2

# Bluetooth - not needed on servers
blacklist bluetooth
blacklist btusb
blacklist rfcomm
blacklist bnep

# Wireless - typically not needed on servers
blacklist cfg80211
blacklist mac80211
EOF

echo "âœ… Unused filesystem modules blacklisted for security"

echo "===== 11.5 Creating systemd timer services for reliable security monitoring ====="
# Create systemd timers to ensure critical security scans run even if cron missed

# Malware detection service
cat > /etc/systemd/system/maldet-scan.service << 'EOF'
[Unit]
Description=Linux Malware Detect Daily Scan
After=network.target

[Service]
Type=oneshot
ExecStart=/etc/cron.daily/maldet-scan
User=root
StandardOutput=journal
StandardError=journal
TimeoutSec=7200
EOF

# Malware detection timer (runs daily, catches up missed runs)
cat > /etc/systemd/system/maldet-scan.timer << 'EOF'
[Unit]
Description=Run malware detection daily
Requires=maldet-scan.service

[Timer]
OnCalendar=daily
RandomizedDelaySec=30min
Persistent=yes
AccuracySec=1min

[Install]
WantedBy=timers.target
EOF

# ClamAV scan service
cat > /etc/systemd/system/clamscan.service << 'EOF'
[Unit]
Description=ClamAV Daily Virus Scan
After=network.target

[Service]
Type=oneshot
ExecStart=/etc/cron.daily/clamscan
User=root
StandardOutput=journal
StandardError=journal
TimeoutSec=7200
EOF

# ClamAV scan timer (runs daily, catches up missed runs)
cat > /etc/systemd/system/clamscan.timer << 'EOF'
[Unit]
Description=Run ClamAV scan daily
Requires=clamscan.service

[Timer]
OnCalendar=daily
RandomizedDelaySec=45min
Persistent=yes
AccuracySec=1min

[Install]
WantedBy=timers.target
EOF

# Trivy container scan service (if Docker mode)
if [ "$DEPLOYMENT_MODE" = "docker" ]; then
cat > /etc/systemd/system/trivy-scan.service << 'EOF'
[Unit]
Description=Trivy Container Security Scan
After=network.target docker.service
Requires=docker.service

[Service]
Type=oneshot
ExecStart=/etc/cron.daily/trivy-scan
User=root
StandardOutput=journal
StandardError=journal
TimeoutSec=3600
EOF

cat > /etc/systemd/system/trivy-scan.timer << 'EOF'
[Unit]
Description=Run Trivy container scan daily
Requires=trivy-scan.service

[Timer]
OnCalendar=daily
RandomizedDelaySec=60min
Persistent=yes
AccuracySec=1min

[Install]
WantedBy=timers.target
EOF
fi

# Rootkit scan service
cat > /etc/systemd/system/rkhunter-scan.service << 'EOF'
[Unit]
Description=RKHunter Rootkit Scan
After=network.target

[Service]
Type=oneshot
ExecStart=/etc/cron.daily/rkhunter-scan
User=root
StandardOutput=journal
StandardError=journal
TimeoutSec=1800
EOF

# Rootkit scan timer (runs daily, catches up missed runs)
cat > /etc/systemd/system/rkhunter-scan.timer << 'EOF'
[Unit]
Description=Run rootkit scan daily
Requires=rkhunter-scan.service

[Timer]
OnCalendar=daily
RandomizedDelaySec=90min
Persistent=yes
AccuracySec=1min

[Install]
WantedBy=timers.target
EOF

# Enable and start the timer services
systemctl daemon-reload
systemctl enable maldet-scan.timer
systemctl enable clamscan.timer
systemctl enable rkhunter-scan.timer

if [ "$DEPLOYMENT_MODE" = "docker" ]; then
    systemctl enable trivy-scan.timer
    systemctl start trivy-scan.timer
fi

systemctl start maldet-scan.timer
systemctl start clamscan.timer
systemctl start rkhunter-scan.timer

echo "âœ… Systemd timer services created and enabled for security scans"
echo "   â€¢ maldet-scan.timer - daily malware detection (with randomized delay)"
echo "   â€¢ clamscan.timer - daily antivirus scan (with randomized delay)"
echo "   â€¢ rkhunter-scan.timer - daily rootkit scan (with randomized delay)"
if [ "$DEPLOYMENT_MODE" = "docker" ]; then
    echo "   â€¢ trivy-scan.timer - daily container vulnerability scan"
fi
echo "   â€¢ All timers use Persistent=yes to run missed executions on boot"
echo "   â€¢ Randomized delays prevent all scans running simultaneously"

# Verify timers are active
echo ""
echo "Security scan timer status:"
systemctl list-timers maldet-scan.timer clamscan.timer rkhunter-scan.timer --no-pager || true

# ========= Now restart SSH with new configuration =========
echo "===== 12. Restarting SSH to apply security settings ====="
docker_systemctl restart sshd

echo "===== 13. Optional DSGVO/GDPR Compliance Setup ====="
echo "Setting up DSGVO/GDPR compliance framework..."

# Copy DSGVO setup script to the scripts directory first
mkdir -p /opt/polyserver/scripts
if [ -f "/opt/polyserver/scripts/setup-dsgvo.sh" ]; then
    DSGVO_SETUP_SCRIPT="/opt/polyserver/scripts/setup-dsgvo.sh"
else
    # Look for the script in the current directory structure
    CURRENT_DIR=$(dirname "${BASH_SOURCE[0]}")
    if [ -f "$CURRENT_DIR/setup-dsgvo.sh" ]; then
        cp "$CURRENT_DIR/setup-dsgvo.sh" "/opt/polyserver/scripts/"
        DSGVO_SETUP_SCRIPT="/opt/polyserver/scripts/setup-dsgvo.sh"
        chmod +x "$DSGVO_SETUP_SCRIPT"
    fi
fi

if [ -f "$DSGVO_SETUP_SCRIPT" ]; then
    echo "Running DSGVO compliance setup..."
    # Run non-interactively by providing default answers
    echo "y" | bash "$DSGVO_SETUP_SCRIPT" || echo "DSGVO setup completed with warnings"
else
    echo "DSGVO setup script not found. You can run it later manually."
    echo "Make sure to install DSGVO compliance files before running compliance checks."
fi

echo "===== 14. Advanced Security Hardening ====="
echo "Implementing comprehensive security enhancements..."

# APT Package Pinning for critical security packages
echo "Setting up APT package pinning for critical security packages..."
cat > /etc/apt/preferences.d/security-packages << 'EOF'
# Pin critical security packages to prevent accidental downgrades
Package: openssh-server openssh-client
Pin: version *
Pin-Priority: 1001

Package: fail2ban
Pin: version *
Pin-Priority: 1001

Package: ufw
Pin: version *
Pin-Priority: 1001

Package: auditd
Pin: version *
Pin-Priority: 1001

Package: sudo
Pin: version *
Pin-Priority: 1001

Package: clamav clamav-daemon clamav-freshclam
Pin: version *
Pin-Priority: 1001

Package: rkhunter chkrootkit
Pin: version *
Pin-Priority: 1001
EOF

# Full Disk Encryption Detection
echo "Checking for Full Disk Encryption (LUKS)..."
if lsblk -f | grep -q crypto_LUKS; then
    echo "âœ… Full disk encryption (LUKS) detected and active"
    echo "LUKS_ENCRYPTION=enabled" >> /etc/security-status.conf
else
    echo "âš ï¸ No LUKS encryption detected - consider enabling FDE for enhanced security"
    echo "LUKS_ENCRYPTION=disabled" >> /etc/security-status.conf
fi

# IPv6 Security (belt and suspenders approach)
echo "Implementing IPv6 security hardening..."
if command -v ufw >/dev/null 2>&1; then
    # Additional IPv6 rules as extra protection
    ufw --force enable
    # Block all IPv6 by default (additional layer beyond sysctl)
    ip6tables -P INPUT DROP 2>/dev/null || true
    ip6tables -P FORWARD DROP 2>/dev/null || true
    ip6tables -P OUTPUT DROP 2>/dev/null || true
    echo "âœ… IPv6 traffic blocked via ip6tables (additional protection)"
fi

# Filesystem Mount Options Security Audit
echo "Auditing filesystem mount options for security compliance..."
MOUNT_AUDIT_LOG="/var/log/security/mount-audit.log"
mkdir -p "$(dirname "$MOUNT_AUDIT_LOG")"

{
    echo "=== Filesystem Mount Security Audit - $(date) ==="
    echo "Checking critical mount points for security options..."
    
    # Check /tmp mount options
    if mount | grep -E '^[^ ]+ on /tmp ' | grep -E '(noexec|nodev|nosuid)'; then
        echo "âœ… /tmp has security mount options"
    else
        echo "âš ï¸ /tmp missing security options (noexec,nodev,nosuid recommended)"
    fi
    
    # Check /var/tmp mount options  
    if mount | grep -E '^[^ ]+ on /var/tmp ' | grep -E '(noexec|nodev|nosuid)'; then
        echo "âœ… /var/tmp has security mount options"
    else
        echo "âš ï¸ /var/tmp missing security options (noexec,nodev,nosuid recommended)"
    fi
    
    # Check /home mount options
    if mount | grep -E '^[^ ]+ on /home ' | grep -E 'nodev'; then
        echo "âœ… /home has nodev option"
    else
        echo "âš ï¸ /home missing nodev option"
    fi
    
    # Check for world-writable mount points
    echo ""
    echo "Checking for potentially dangerous mount options..."
    mount | grep -E '(exec|dev|suid)' | grep -v -E '(noexec|nodev|nosuid)' || echo "No dangerous mount options found"
    
    echo ""
} >> "$MOUNT_AUDIT_LOG"

cat "$MOUNT_AUDIT_LOG"

# Service Whitelist Audit
echo "Performing service whitelist security audit..."
SERVICE_AUDIT_LOG="/var/log/security/service-audit.log"

# Define allowed services (extend as needed for your applications)
ALLOWED_SERVICES="
ssh|sshd
systemd-
NetworkManager
cron|crond
rsyslog
dbus
getty
user@
session-
auditd
fail2ban
ufw
docker
containerd
nginx
netdata
unbound
clamav
freshclam
maldet
rkhunter
"

{
    echo "=== Service Whitelist Audit - $(date) ==="
    echo "Checking running services against security whitelist..."
    
    # Get all running services
    RUNNING_SERVICES=$(systemctl list-units --type=service --state=running --no-legend | awk '{print $1}' | sed 's/\.service$//')
    
    echo "Currently running services:"
    echo "$RUNNING_SERVICES"
    echo ""
    
    echo "Services not in whitelist (review for security):"
    for service in $RUNNING_SERVICES; do
        if ! echo "$ALLOWED_SERVICES" | grep -qE "^${service}"; then
            # Check if it matches any pattern in the whitelist
            WHITELISTED=false
            while read -r pattern; do
                if [[ "$service" =~ $pattern ]]; then
                    WHITELISTED=true
                    break
                fi
            done <<< "$ALLOWED_SERVICES" 2>/dev/null
            
            if [ "$WHITELISTED" = "false" ]; then
                echo "âš ï¸ $service - verify this service is necessary"
            fi
        fi
    done
    
    echo ""
} >> "$SERVICE_AUDIT_LOG"

cat "$SERVICE_AUDIT_LOG"

# Enhanced Persistence Detection System
echo "Setting up enhanced persistence detection monitoring..."
BASELINE_DIR="/var/lib/security/baselines"
mkdir -p "$BASELINE_DIR"

# Create persistence monitoring script
cat > /usr/local/bin/check-persistence-locations.sh << 'EOF'
#!/bin/bash
# Enhanced Persistence Detection System
# Monitors common persistence locations for unauthorized changes

BASELINE_DIR="/var/lib/security/baselines"
LOG_FILE="/var/log/security/persistence-detection.log"
MAIL_RECIPIENT="{{LOGWATCH_EMAIL}}"

# Logging function
log_message() {
    echo "$(date '+%Y-%m-%d %H:%M:%S') - $1" | tee -a "$LOG_FILE"
}

# Check a specific location for changes
check_persistence_location() {
    local location="$1"
    local name="$2"
    local baseline_file="$BASELINE_DIR/${name}.baseline"
    local current_file="/tmp/${name}.current"
    
    if [ -d "$location" ] || [ -f "$location" ]; then
        find "$location" -type f -exec stat -c "%n %Y %s" {} \; 2>/dev/null | sort > "$current_file"
        
        if [ -f "$baseline_file" ]; then
            if ! diff -q "$baseline_file" "$current_file" >/dev/null 2>&1; then
                log_message "ALERT: Changes detected in $name ($location)"
                diff "$baseline_file" "$current_file" | head -20 >> "$LOG_FILE"
                echo "PERSISTENCE ALERT: Changes detected in $name on $(hostname)" | \
                    mail -s "SECURITY ALERT: Persistence Detection" "$MAIL_RECIPIENT" 2>/dev/null || true
            fi
        else
            # First run - create baseline
            cp "$current_file" "$baseline_file"
            log_message "Created baseline for $name ($location)"
        fi
        rm -f "$current_file"
    fi
}

# Monitor autostart locations
log_message "Starting persistence detection scan..."

# System-wide autostart locations
check_persistence_location "/etc/init.d" "init_scripts"
check_persistence_location "/etc/systemd/system" "systemd_system"
check_persistence_location "/etc/systemd/user" "systemd_user"
check_persistence_location "/etc/cron.d" "cron_d"
check_persistence_location "/etc/cron.daily" "cron_daily"
check_persistence_location "/etc/cron.hourly" "cron_hourly"
check_persistence_location "/etc/cron.weekly" "cron_weekly"
check_persistence_location "/etc/cron.monthly" "cron_monthly"
check_persistence_location "/etc/rc.local" "rc_local"
check_persistence_location "/etc/profile.d" "profile_d"
check_persistence_location "/etc/bash.bashrc" "bash_bashrc"

# User autostart locations (for existing users)
for user_home in /home/*; do
    if [ -d "$user_home" ]; then
        username=$(basename "$user_home")
        check_persistence_location "$user_home/.bashrc" "bashrc_$username"
        check_persistence_location "$user_home/.profile" "profile_$username"
        check_persistence_location "$user_home/.config/autostart" "autostart_$username"
        check_persistence_location "$user_home/.config/systemd/user" "systemd_user_$username"
    fi
done

# Check for new SUID/SGID binaries
find /usr /bin /sbin /opt -type f \( -perm -4000 -o -perm -2000 \) 2>/dev/null | sort > "/tmp/suid_sgid.current"
if [ -f "$BASELINE_DIR/suid_sgid.baseline" ]; then
    if ! diff -q "$BASELINE_DIR/suid_sgid.baseline" "/tmp/suid_sgid.current" >/dev/null 2>&1; then
        log_message "ALERT: SUID/SGID binary changes detected"
        diff "$BASELINE_DIR/suid_sgid.baseline" "/tmp/suid_sgid.current" | head -20 >> "$LOG_FILE"
        echo "SUID/SGID ALERT: Binary permission changes detected on $(hostname)" | \
            mail -s "SECURITY ALERT: SUID/SGID Changes" "$MAIL_RECIPIENT" 2>/dev/null || true
    fi
else
    cp "/tmp/suid_sgid.current" "$BASELINE_DIR/suid_sgid.baseline"
    log_message "Created SUID/SGID baseline"
fi
rm -f "/tmp/suid_sgid.current"

log_message "Persistence detection scan completed"
EOF

chmod +x /usr/local/bin/check-persistence-locations.sh

# Run initial baseline creation
echo "Creating initial security baselines..."
/usr/local/bin/check-persistence-locations.sh

# Add to cron for regular monitoring
cat > /etc/cron.d/persistence-detection << 'EOF'
# Enhanced Persistence Detection - runs every 4 hours
0 */4 * * * root /usr/local/bin/check-persistence-locations.sh >/dev/null 2>&1
EOF

# Create log rotation for security logs
cat > /etc/logrotate.d/security-monitoring << 'EOF'
/var/log/security/*.log {
    rotate 12
    monthly
    compress
    delaycompress
    missingok
    notifempty
    create 640 root root
}
EOF

# Final security status summary
echo "Creating security status summary..."
cat > /etc/security-status.conf << EOF
# PolyServer Security Status Configuration
HARDENING_LEVEL=enhanced
APT_PINNING=enabled
PERSISTENCE_MONITORING=enabled
SERVICE_AUDIT=enabled
MOUNT_AUDIT=enabled
SECURITY_BASELINE_DATE=$(date +%Y-%m-%d)
EOF

echo "âœ… Advanced security hardening completed!"
echo ""
echo "Security enhancements implemented:"
echo "   â€¢ APT package pinning for critical security packages"
echo "   â€¢ Full disk encryption detection and status logging"  
echo "   â€¢ IPv6 security hardening (belt and suspenders approach)"
echo "   â€¢ Filesystem mount option security audit"
echo "   â€¢ Service whitelist audit against security baseline"
echo "   â€¢ Enhanced persistence detection monitoring"
echo "   â€¢ SUID/SGID binary monitoring"
echo "   â€¢ Automated security baseline creation and monitoring"
echo ""
echo "Security logs location: /var/log/security/"
echo "Security baselines: /var/lib/security/baselines/"
echo "Security status: /etc/security-status.conf"

echo "===== 15. Advanced Security Refinements ====="

# AppArmor Profile Enforcement Verification
echo "Verifying AppArmor profile enforcement..."
if command -v aa-status >/dev/null 2>&1; then
    echo "Current AppArmor status:"
    aa-status
    
    # Check if profiles are in enforce mode
    PROFILES_ENFORCE=$(aa-status --complain 2>/dev/null | wc -l)
    PROFILES_COMPLAIN=$(aa-status --enforce 2>/dev/null | wc -l)
    
    if [ "$PROFILES_COMPLAIN" -gt 0 ]; then
        echo "âš ï¸ $PROFILES_COMPLAIN AppArmor profiles in complain mode - consider enforcing:"
        aa-status --complain 2>/dev/null || true
        echo "   To enforce: sudo aa-enforce /etc/apparmor.d/<profile>"
    fi
    
    # Create custom SSH profile for enhanced protection
    cat > /etc/apparmor.d/usr.sbin.sshd << 'EOF'
#include <tunables/global>

/usr/sbin/sshd {
  #include <abstractions/authentication>
  #include <abstractions/base>
  #include <abstractions/consoles>
  #include <abstractions/nameservice>
  #include <abstractions/wutmp>

  capability sys_chroot,
  capability sys_resource,
  capability chown,
  capability fowner,
  capability kill,
  capability setgid,
  capability setuid,
  capability audit_write,
  capability dac_override,
  capability dac_read_search,
  capability sys_tty_config,

  /dev/log w,
  /dev/null rw,
  /dev/ptmx rw,
  /dev/pts/* rw,
  /dev/tty rw,
  /dev/urandom r,

  /etc/default/locale r,
  /etc/environment r,
  /etc/group r,
  /etc/hosts.allow r,
  /etc/hosts.deny r,
  /etc/ld.so.cache r,
  /etc/localtime r,
  /etc/motd r,
  /etc/passwd r,
  /etc/security/** r,
  /etc/shadow r,
  /etc/ssh/** r,

  # Allow access to user authorized_keys files
  /home/*/.ssh/authorized_keys r,
  /home/*/.ssh/authorized_keys2 r,

  /proc/*/fd/ r,
  /proc/*/mounts r,
  /proc/*/stat r,
  /proc/sys/crypto/fips_enabled r,

  /run/sshd.pid w,
  /run/systemd/sessions/* rw,
  /run/utmp rw,

  /usr/bin/** PUx,
  /bin/** PUx,
  /usr/sbin/sshd mr,

  /var/log/auth.log w,
  /var/log/btmp w,
  /var/log/lastlog rw,
  /var/log/wtmp rw,

  # Site-specific additions and overrides. See local/README for details.
  #include <local/usr.sbin.sshd>
}
EOF

    # Create nginx AppArmor profile for web servers
    if [ "$DEPLOYMENT_MODE" != "docker" ]; then
        cat > /etc/apparmor.d/usr.sbin.nginx << 'EOF'
#include <tunables/global>

/usr/sbin/nginx {
  #include <abstractions/base>
  #include <abstractions/nameservice>

  capability dac_override,
  capability setgid,
  capability setuid,

  /etc/nginx/** r,
  /etc/ssl/certs/ r,
  /etc/ssl/certs/** r,
  /etc/ssl/private/ r,
  /etc/ssl/private/** r,

  /proc/*/auxv r,
  /proc/sys/kernel/ngroups_max r,

  /run/nginx.pid rw,
  /var/log/nginx/** w,
  /var/www/** r,

  /usr/sbin/nginx mr,
  /usr/share/nginx/** r,

  # Site-specific additions and overrides. See local/README for details.
  #include <local/usr.sbin.nginx>
}
EOF
        apparmor_parser -r /etc/apparmor.d/usr.sbin.nginx 2>/dev/null || echo "Nginx AppArmor profile created"
        echo "âœ… Nginx AppArmor profile created"
    fi
    
    # Load and enforce the SSH profile
    # Create the local include directory and file to prevent parser errors
    mkdir -p /etc/apparmor.d/local
    touch /etc/apparmor.d/local/usr.sbin.sshd
    
    # Add a comment to the local file
    cat > /etc/apparmor.d/local/usr.sbin.sshd << 'EOF'
# Site-specific additions and overrides for /usr/sbin/sshd
# This file can be used to add additional rules specific to this system
# Format: standard AppArmor rules
EOF
    
    apparmor_parser -r /etc/apparmor.d/usr.sbin.sshd 2>/dev/null || echo "AppArmor SSH profile created (will be active after sshd restart)"
    echo "âœ… AppArmor SSH profile created and loaded"
else
    echo "âš ï¸ AppArmor not available or not installed"
fi

# Unattended Reboot Warning System
echo "Configuring unattended reboot warning system..."
cat > /etc/apt/apt.conf.d/51unattended-upgrades-server << 'EOF'
// Enhanced server configuration for unattended upgrades
Unattended-Upgrade::Automatic-Reboot "true";
Unattended-Upgrade::Automatic-Reboot-WithUsers "false";
Unattended-Upgrade::Automatic-Reboot-Time "04:00";

// Warning system before reboot
Unattended-Upgrade::SyslogEnable "true";
Unattended-Upgrade::SyslogFacility "daemon";
EOF

# Create pre-reboot warning script
cat > /usr/local/bin/unattended-reboot-warning.sh << 'EOF'
#!/bin/bash
# Pre-reboot warning for unattended upgrades

# Check if reboot is required
if [ -f /var/run/reboot-required ]; then
    # Send wall message to all logged in users
    echo "SYSTEM NOTICE: Unattended upgrade requires reboot. System will reboot at 04:00 AM." | wall
    
    # Log to syslog
    logger -p daemon.warning "Server scheduled for automatic reboot due to unattended upgrade"
    
    # Send email notification
    echo "Server $(hostname) is scheduled for automatic reboot at 04:00 AM due to security updates requiring reboot." | \
        mail -s "SERVER NOTICE: Scheduled Reboot Tonight" {{LOGWATCH_EMAIL}}
fi
EOF

chmod +x /usr/local/bin/unattended-reboot-warning.sh

# Add to daily cron to warn users
echo "0 20 * * * root /usr/local/bin/unattended-reboot-warning.sh" >> /etc/crontab

echo "âœ… Unattended reboot warning system configured"

# Suricata Rules Maintenance
echo "Setting up Suricata rules maintenance..."
if command -v suricata-update >/dev/null 2>&1; then
    # Configure suricata-update
    suricata-update update-sources
    suricata-update enable-source et/open
    suricata-update enable-source oisf/trafficid
    
    # Create weekly rules update job
    cat > /etc/cron.weekly/suricata-update << 'EOF'
#!/bin/bash
# Weekly Suricata rules update

# Update rule sources
/usr/bin/suricata-update update-sources

# Update rules
/usr/bin/suricata-update

# Test configuration
if suricata -T -c /etc/suricata/suricata.yaml; then
    # Restart Suricata if config is valid
    systemctl reload suricata || systemctl restart suricata
    logger -p daemon.info "Suricata rules updated successfully"
else
    # Notify of configuration error
    echo "Suricata configuration test failed after rules update on $(hostname)" | \
        mail -s "SERVER ERROR: Suricata Rules Update Failed" {{LOGWATCH_EMAIL}}
    logger -p daemon.error "Suricata rules update failed - configuration test error"
fi
EOF
    
    chmod +x /etc/cron.weekly/suricata-update
    echo "âœ… Suricata rules auto-update configured"
else
    echo "âš ï¸ suricata-update not available - install with: apt install suricata-update"
fi

# Enhanced OpenSSH HMAC Tuning
echo "Applying enhanced OpenSSH HMAC tuning..."
cat >> /etc/ssh/sshd_config << 'EOF'

# Enhanced HMAC configuration - disable SHA-1 completely
MACs hmac-sha2-256-etm@openssh.com,hmac-sha2-512-etm@openssh.com,hmac-sha2-256,hmac-sha2-512

# Ensure no weak algorithms
PubkeyAcceptedKeyTypes rsa-sha2-512,rsa-sha2-256,ecdsa-sha2-nistp256,ecdsa-sha2-nistp384,ecdsa-sha2-nistp521,ssh-ed25519
KexAlgorithms curve25519-sha256,curve25519-sha256@libssh.org,ecdh-sha2-nistp256,ecdh-sha2-nistp384,ecdh-sha2-nistp521,diffie-hellman-group16-sha512,diffie-hellman-group18-sha512,diffie-hellman-group14-sha256
EOF

echo "âœ… Enhanced SSH HMAC configuration applied (no SHA-1)"

# Systemd Watchdog for Critical Services
echo "Configuring systemd watchdog for critical services..."

# Enhanced fail2ban service with watchdog
mkdir -p /etc/systemd/system/fail2ban.service.d
cat > /etc/systemd/system/fail2ban.service.d/watchdog.conf << 'EOF'
[Service]
WatchdogSec=60
Restart=on-failure
RestartSec=30
StartLimitInterval=600
StartLimitBurst=2
EOF

# Enhanced Suricata service with watchdog
mkdir -p /etc/systemd/system/suricata.service.d
cat > /etc/systemd/system/suricata.service.d/watchdog.conf << 'EOF'
[Service]
WatchdogSec=120
Restart=on-failure
RestartSec=30
StartLimitInterval=1200
StartLimitBurst=2
EOF

# SSH service watchdog
mkdir -p /etc/systemd/system/ssh.service.d
cat > /etc/systemd/system/ssh.service.d/watchdog.conf << 'EOF'
[Service]
WatchdogSec=30
Restart=on-failure
RestartSec=5
StartLimitInterval=300
StartLimitBurst=5
EOF

# Nginx service watchdog (if not Docker mode)
if [ "$DEPLOYMENT_MODE" != "docker" ]; then
    mkdir -p /etc/systemd/system/nginx.service.d
    cat > /etc/systemd/system/nginx.service.d/watchdog.conf << 'EOF'
[Service]
WatchdogSec=30
Restart=on-failure
RestartSec=5
StartLimitInterval=300
StartLimitBurst=5
EOF
fi

systemctl daemon-reload
echo "âœ… Systemd watchdog configured for critical services"

# Daily Security Configuration Backup
echo "Setting up daily security configuration backup..."
cat > /etc/cron.daily/security-config-backup << 'EOF'
#!/bin/bash
# Daily backup of critical security configurations

BACKUP_DIR="/var/backups/security-configs"
DATE=$(date +%Y%m%d)
BACKUP_FILE="$BACKUP_DIR/security-config-$DATE.tar.gz"

# Create backup directory
mkdir -p "$BACKUP_DIR"

# Create comprehensive backup
tar -czf "$BACKUP_FILE" \
    /etc/fail2ban \
    /etc/suricata \
    /etc/ssh \
    /etc/audit \
    /etc/ufw \
    /etc/apparmor.d \
    /etc/nginx \
    /etc/cron.d \
    /etc/cron.daily \
    /etc/cron.hourly \
    /etc/cron.weekly \
    /etc/systemd/system \
    /var/lib/security/baselines \
    /etc/security-status.conf \
    /etc/logrotate.d \
    2>/dev/null

# Verify backup
if [ -f "$BACKUP_FILE" ]; then
    # Check backup integrity
    if tar -tzf "$BACKUP_FILE" >/dev/null 2>&1; then
        logger -p daemon.info "Security configuration backup completed: $BACKUP_FILE"
        
        # Keep only last 30 days of backups
        find "$BACKUP_DIR" -name "security-config-*.tar.gz" -mtime +30 -delete
        
        # Report backup size
        BACKUP_SIZE=$(du -h "$BACKUP_FILE" | cut -f1)
        echo "Security configuration backup completed: $BACKUP_SIZE ($BACKUP_FILE)" >> /var/log/backup.log
    else
        logger -p daemon.error "Security configuration backup corrupted: $BACKUP_FILE"
        echo "BACKUP ERROR: Security configuration backup corrupted on $(hostname)" | \
            mail -s "SERVER ERROR: Backup Failure" {{LOGWATCH_EMAIL}}
    fi
else
    logger -p daemon.error "Security configuration backup failed"
    echo "BACKUP ERROR: Security configuration backup failed on $(hostname)" | \
        mail -s "SERVER ERROR: Backup Failure" {{LOGWATCH_EMAIL}}
fi

# Quick integrity check of critical configs
for config in /etc/ssh/sshd_config /etc/suricata/suricata.yaml /etc/fail2ban/jail.local /etc/nginx/nginx.conf; do
    if [ -f "$config" ]; then
        case "$config" in
            */sshd_config)
                sshd -t 2>/dev/null || echo "WARNING: SSH config validation failed" >> /var/log/backup.log
                ;;
            */suricata.yaml)
                suricata -T -c "$config" >/dev/null 2>&1 || echo "WARNING: Suricata config validation failed" >> /var/log/backup.log
                ;;
            */jail.local)
                fail2ban-client -t >/dev/null 2>&1 || echo "WARNING: Fail2ban config validation failed" >> /var/log/backup.log
                ;;
            */nginx.conf)
                nginx -t >/dev/null 2>&1 || echo "WARNING: Nginx config validation failed" >> /var/log/backup.log
                ;;
        esac
    fi
done
EOF

chmod +x /etc/cron.daily/security-config-backup

# Run initial backup
echo "Creating initial security configuration backup..."
/etc/cron.daily/security-config-backup

echo "âœ… Daily security configuration backup system configured"
echo ""
echo "Advanced security refinements completed:"
echo "   â€¢ AppArmor profile enforcement verification and custom profiles (SSH + Nginx)"
echo "   â€¢ Unattended reboot warning system (wall messages + email alerts)"
echo "   â€¢ Suricata rules maintenance with weekly auto-updates"
echo "   â€¢ Enhanced OpenSSH HMAC tuning (SHA-1 completely disabled)"
echo "   â€¢ Systemd watchdog for fail2ban, suricata, SSH, and nginx services"
echo "   â€¢ Daily automated backup of all security configurations"
if [ "$NETDATA_ENABLED" = "true" ]; then
    echo "   â€¢ Netdata monitoring with optional Cloud integration"
fi
echo ""
echo "Configuration backup location: /var/backups/security-configs/"
echo "Backup retention: 30 days"

echo "===== 16. Final configuration validation ====="
log_message "Performing final configuration validation..."

if validate_critical_configs; then
    log_message "âœ… All critical configurations validated successfully"
else
    log_error "âš ï¸ Some configuration validation issues detected"
    log_message "Check $LOG_FILE for details"
fi

echo "===== 17. Setup complete! ====="
log_message "Server setup completed successfully"
echo "Server has been secured and Docker installed."
echo "IMPORTANT: SSH is now running on port $SSH_PORT"
echo "Use the following command to connect: ssh -p $SSH_PORT $USERNAME@your-server-ip"
echo ""
echo "Next steps:"
echo "1. Edit /etc/dsgvo/contacts.conf to add your DPO contact information"
echo "2. Complete /etc/dsgvo/data_inventory.json with your actual data"
echo "3. Run compliance check: /opt/polyserver/scripts/dsgvo-compliance-check.sh"
if [ "$NETDATA_ENABLED" = "true" ]; then
    echo "4. Access Netdata dashboard: ssh -L 19999:127.0.0.1:19999 {{USERNAME}}@server"
    echo "5. Add to Netdata Cloud (optional): run 'netdata-access' for instructions"
    echo "6. Deploy your applications using the PolyServer foundation"
else
    echo "4. Deploy your applications using the PolyServer foundation"
fi
