#!/bin/bash
# server_setup.sh - Secure Debian 13 server setup for PolyServer applications
# Run as root after fresh Debian 13 (trixie) instance creation

# Enhanced error handling with trap
set -Eeuo pipefail

# Root and OS verification
if [ "$(id -u)" -ne 0 ]; then echo "Run as root"; exit 1; fi
. /etc/os-release
case "$ID:$VERSION_ID" in debian:12*|debian:13*) : ;; *) echo "This script targets Debian 12/13"; exit 1;; esac

# Error trap function
error_trap() {
    local exit_code=$?
    local line_number=$1
    log_message "âŒ ERROR: Script failed at line $line_number with exit code $exit_code"
    log_message "âŒ Command: ${BASH_COMMAND}"
    echo "Setup failed! Check $LOG_FILE for details." >&2
    exit $exit_code
}

# Set trap for errors
trap 'error_trap $LINENO' ERR

# ========= Constants and Logging =========
readonly SCRIPT_NAME="secure-server-setup"
readonly LOG_FILE="/var/log/${SCRIPT_NAME}.log"
readonly BACKUP_DIR="/var/backups/server-setup"

# Ensure log directory exists
mkdir -p "$(dirname "$LOG_FILE")"
mkdir -p "$BACKUP_DIR"

# Logging functions
log_message() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] $*" | tee -a "$LOG_FILE"
}

log_error() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] ERROR: $*" | tee -a "$LOG_FILE" >&2
}

# Trap to handle script exit
cleanup() {
    local exit_code=$?
    if [ $exit_code -ne 0 ]; then
        log_error "Script failed with exit code $exit_code"
        log_message "Check $LOG_FILE for details"
    fi
}
trap cleanup EXIT

log_message "Starting server setup script"

# ========= Variables =========
USERNAME="{{DEPLOY_USER}}"                # Non-root user to create
HOSTNAME="{{HOSTNAME}}"                   # Server hostname
SSH_PORT="{{SSH_PORT}}"                   # Custom SSH port (more secure than default 22)
SSH_PUBLIC_KEY="{{SSH_PUBLIC_KEY}}"       # SSH public key for deploy user
BLOCK_DEVICE="/dev/sdb"                   # Block storage device (adjust if needed)
BACKUP_MOUNT="{{BACKUP_MOUNT}}"           # Backup mount point
LOGWATCH_EMAIL="{{LOGWATCH_EMAIL}}"       # Logwatch notification email

# Optional features configuration
NETDATA_ENABLED="{{NETDATA_ENABLED}}"     # Enable Netdata monitoring
DEPLOYMENT_MODE="{{DEPLOYMENT_MODE}}"     # Deployment mode (docker/baremetal)

# Optional Security Components (resource-conscious defaults)
: "${INSTALL_CLAMAV:=false}"              # Install ClamAV antivirus (high resource usage) - optional
: "${INSTALL_MALDET:=false}"              # Install Linux Malware Detect (medium resource usage) - optional
: "${INSTALL_RKHUNTER:=true}"             # Install rootkit detection tools (low resource usage) - ENABLED BY DEFAULT
: "${INSTALL_SURICATA:=true}"             # Install Suricata IDS (medium resource usage) - ENABLED BY DEFAULT

# SMTP Configuration from defaults.env
SMTP_ENABLED="{{SMTP_ENABLED}}"
SMTP_SERVER="{{SMTP_SERVER}}"
SMTP_PORT="{{SMTP_PORT}}"
SMTP_USERNAME="{{SMTP_USERNAME}}"
SMTP_PASSWORD="{{SMTP_PASSWORD}}"
SMTP_FROM_EMAIL="{{SMTP_FROM_EMAIL}}"
SMTP_USE_TLS="{{SMTP_USE_TLS}}"

# Check if running in Docker testing mode
TESTING_MODE="${TESTING_MODE:-false}"
if [ "$TESTING_MODE" = "true" ]; then
    echo "ðŸ³ Running in Docker testing mode - skipping some services that don't work in containers"
    DOCKER_MODE=true
else
    DOCKER_MODE=false
fi


# ========= System Resource Detection =========
detect_system_resources() {
    log_message "ðŸ” Detecting system resources for optimization..."
    
    # Detect CPU cores
    CPU_CORES=$(nproc 2>/dev/null || echo "")
    if [ -z "$CPU_CORES" ] || [ "$CPU_CORES" -eq 0 ]; then
        CPU_CORES=$(grep -c ^processor /proc/cpuinfo 2>/dev/null || echo "")
    fi
    
    # Detect total RAM in MB
    TOTAL_RAM_KB=$(grep MemTotal /proc/meminfo 2>/dev/null | awk '{print $2}' || echo "")
    if [ -n "$TOTAL_RAM_KB" ]; then
        TOTAL_RAM_MB=$((TOTAL_RAM_KB / 1024))
        TOTAL_RAM_GB=$((TOTAL_RAM_MB / 1024))
    else
        TOTAL_RAM_MB=""
        TOTAL_RAM_GB=""
    fi
    
    # Detect available RAM (excluding buffers/cache)
    AVAILABLE_RAM_KB=$(grep MemAvailable /proc/meminfo 2>/dev/null | awk '{print $2}' || echo "")
    if [ -n "$AVAILABLE_RAM_KB" ]; then
        AVAILABLE_RAM_MB=$((AVAILABLE_RAM_KB / 1024))
    else
        AVAILABLE_RAM_MB=""
    fi
    
    # Verify detection results
    if [ -n "$CPU_CORES" ] && [ "$CPU_CORES" -gt 0 ] && [ -n "$TOTAL_RAM_MB" ] && [ "$TOTAL_RAM_MB" -gt 0 ]; then
        if [ -n "$AVAILABLE_RAM_MB" ]; then
            log_message "âœ… Auto-detected: ${CPU_CORES} CPU cores, ${TOTAL_RAM_MB}MB total RAM (${AVAILABLE_RAM_MB}MB available)"
        else
            log_message "âœ… Auto-detected: ${CPU_CORES} CPU cores, ${TOTAL_RAM_MB}MB RAM (${TOTAL_RAM_GB}GB)"
        fi
        RESOURCE_DETECTION_SUCCESS=true
    else
        log_message "âš ï¸ Auto-detection failed or returned invalid values"
        RESOURCE_DETECTION_SUCCESS=false
    fi
    
    # Fallback: ask user if detection failed or values seem unreasonable
    if [ "$RESOURCE_DETECTION_SUCCESS" = "false" ] || [ "$CPU_CORES" -gt 128 ] || [ "$TOTAL_RAM_GB" -gt 1024 ]; then
        echo ""
        echo "ðŸ¤” System resource detection failed or returned unrealistic values."
        echo "Please manually specify your server resources for optimal configuration:"
        echo ""
        
        while true; do
            read -p "Number of CPU cores [1-128]: " -r USER_CPU_CORES
            if [[ "$USER_CPU_CORES" =~ ^[0-9]+$ ]] && [ "$USER_CPU_CORES" -ge 1 ] && [ "$USER_CPU_CORES" -le 128 ]; then
                CPU_CORES=$USER_CPU_CORES
                break
            else
                echo "Please enter a valid number of CPU cores (1-128)"
            fi
        done
        
        while true; do
            read -p "Total RAM in GB [1-1024]: " -r USER_TOTAL_RAM_GB
            if [[ "$USER_TOTAL_RAM_GB" =~ ^[0-9]+$ ]] && [ "$USER_TOTAL_RAM_GB" -ge 1 ] && [ "$USER_TOTAL_RAM_GB" -le 1024 ]; then
                TOTAL_RAM_GB=$USER_TOTAL_RAM_GB
                TOTAL_RAM_MB=$((TOTAL_RAM_GB * 1024))
                break
            else
                echo "Please enter a valid amount of RAM in GB (1-1024)"
            fi
        done
        
        # Estimate available RAM as 85% of total for manual input
        AVAILABLE_RAM_MB=$((TOTAL_RAM_MB * 85 / 100))
        log_message "âœ… User-specified: ${CPU_CORES} CPU cores, ${TOTAL_RAM_GB}GB RAM (~${AVAILABLE_RAM_MB}MB estimated available)"
    fi
    
    # Calculate optimization parameters
    calculate_optimization_parameters
}

calculate_optimization_parameters() {
    # Nginx optimization
    NGINX_WORKERS=$CPU_CORES
    if [ "$NGINX_WORKERS" -gt 8 ]; then
        NGINX_WORKERS=8
    fi
    NGINX_WORKER_CONNECTIONS=1024  # Standard for most workloads
    NGINX_CLIENT_BODY_BUFFER_SIZE="16k"
    NGINX_CLIENT_HEADER_BUFFER_SIZE="1k"
    
    # Reserve memory for system (OS, monitoring, security tools)
    SYSTEM_RESERVED_RAM=1024  # MB
    if [ "$TOTAL_RAM_MB" -lt 2048 ]; then
        SYSTEM_RESERVED_RAM=512  # Less overhead for small systems
    fi
    AVAILABLE_APP_RAM=$((TOTAL_RAM_MB - SYSTEM_RESERVED_RAM))
    if [ "$AVAILABLE_APP_RAM" -lt 512 ]; then
        AVAILABLE_APP_RAM=512
    fi
    
    # PHP-FPM optimization (production-ready settings)
    PHP_PROCESS_MEMORY=48  # MB per process (conservative for production)
    PHP_MAX_CHILDREN=$((AVAILABLE_APP_RAM / PHP_PROCESS_MEMORY / 2))  # Use 50% for PHP
    PHP_START_SERVERS=$((PHP_MAX_CHILDREN / 4))
    PHP_MIN_SPARE_SERVERS=$((PHP_MAX_CHILDREN / 8))
    PHP_MAX_SPARE_SERVERS=$((PHP_MAX_CHILDREN / 2))
    
    # Ensure reasonable PHP-FPM bounds
    if [ "$PHP_MAX_CHILDREN" -lt 4 ]; then
        PHP_MAX_CHILDREN=4
        PHP_START_SERVERS=2
        PHP_MIN_SPARE_SERVERS=1
        PHP_MAX_SPARE_SERVERS=2
    elif [ "$PHP_MAX_CHILDREN" -gt 100 ]; then
        PHP_MAX_CHILDREN=100
        PHP_START_SERVERS=25
        PHP_MIN_SPARE_SERVERS=10
        PHP_MAX_SPARE_SERVERS=50
    fi
    
    # PHP memory limits based on available RAM
    if [ "$TOTAL_RAM_GB" -ge 8 ]; then
        PHP_MEMORY_LIMIT="256M"
        PHP_MAX_EXECUTION_TIME=120
    elif [ "$TOTAL_RAM_GB" -ge 4 ]; then
        PHP_MEMORY_LIMIT="128M"
        PHP_MAX_EXECUTION_TIME=90
    else
        PHP_MEMORY_LIMIT="64M"
        PHP_MAX_EXECUTION_TIME=60
    fi
    
    # Node.js PM2 optimization
    PM2_INSTANCES=$((CPU_CORES - 1))
    if [ "$PM2_INSTANCES" -lt 1 ]; then
        PM2_INSTANCES=1
    elif [ "$PM2_INSTANCES" -gt 8 ]; then
        PM2_INSTANCES=8
    fi
    
    # Database optimization (MariaDB/MySQL)
    DB_MAX_CONNECTIONS=$((TOTAL_RAM_GB * 15))
    if [ "$DB_MAX_CONNECTIONS" -lt 20 ]; then
        DB_MAX_CONNECTIONS=20
    elif [ "$DB_MAX_CONNECTIONS" -gt 500 ]; then
        DB_MAX_CONNECTIONS=500
    fi
    
    # InnoDB settings (30% for mixed servers, can be increased for DB-dedicated)
    INNODB_BUFFER_POOL_MB=$((TOTAL_RAM_MB * 30 / 100))
    if [ "$INNODB_BUFFER_POOL_MB" -lt 128 ]; then
        INNODB_BUFFER_POOL_MB=128
    fi
    
    # InnoDB additional settings
    INNODB_LOG_FILE_SIZE=$((INNODB_BUFFER_POOL_MB / 4))  # 25% of buffer pool
    if [ "$INNODB_LOG_FILE_SIZE" -lt 32 ]; then
        INNODB_LOG_FILE_SIZE=32
    elif [ "$INNODB_LOG_FILE_SIZE" -gt 512 ]; then
        INNODB_LOG_FILE_SIZE=512
    fi
    
    # Query cache (disabled by default in MySQL 8.0+, but MariaDB still uses it)
    QUERY_CACHE_SIZE=$((TOTAL_RAM_MB * 5 / 100))  # 5% of RAM
    if [ "$QUERY_CACHE_SIZE" -lt 16 ]; then
        QUERY_CACHE_SIZE=16
    elif [ "$QUERY_CACHE_SIZE" -gt 128 ]; then
        QUERY_CACHE_SIZE=128
    fi
    
    # Redis optimization (if installed)
    REDIS_MAXMEMORY=$((TOTAL_RAM_MB * 25 / 100))  # 25% for Redis cache
    if [ "$REDIS_MAXMEMORY" -lt 64 ]; then
        REDIS_MAXMEMORY=64
    fi
    
    log_message "ðŸ“Š Calculated optimization parameters:"
    log_message "   ðŸŒ Nginx: $NGINX_WORKERS workers, $NGINX_WORKER_CONNECTIONS connections/worker"
    log_message "   ðŸ˜ PHP-FPM: max_children=$PHP_MAX_CHILDREN, start=$PHP_START_SERVERS, spare=$PHP_MIN_SPARE_SERVERS-$PHP_MAX_SPARE_SERVERS"
    log_message "   âš¡ Node.js PM2: $PM2_INSTANCES cluster instances"
    log_message "   ðŸ—„ï¸ Database: max_connections=$DB_MAX_CONNECTIONS, innodb_buffer_pool=${INNODB_BUFFER_POOL_MB}MB"
    log_message "   ðŸ“ Redis: maxmemory=${REDIS_MAXMEMORY}MB"
}

# Update PHP-FPM configuration with calculated values
update_php_fpm_config() {
    log_message "Updating PHP-FPM configuration with calculated values..."
    
    # Check if PHP config files exist from deployment
    PHP_POOL_CONFIG="/etc/php/8.4/fpm/pool.d/security.conf"
    PHP_INI_CONFIG="/etc/php/8.4/mods-available/99-security.ini"
    
    # Update PHP-FPM pool configuration if it exists
    if [ -f "$PHP_POOL_CONFIG" ]; then
        sed -i "s/^pm.max_children = .*/pm.max_children = $PHP_MAX_CHILDREN/" "$PHP_POOL_CONFIG"
        sed -i "s/^pm.start_servers = .*/pm.start_servers = $PHP_START_SERVERS/" "$PHP_POOL_CONFIG"
        sed -i "s/^pm.min_spare_servers = .*/pm.min_spare_servers = $PHP_MIN_SPARE_SERVERS/" "$PHP_POOL_CONFIG"
        sed -i "s/^pm.max_spare_servers = .*/pm.max_spare_servers = $PHP_MAX_SPARE_SERVERS/" "$PHP_POOL_CONFIG"
        
        # Update memory limit and execution time in pool config
        sed -i "s/php_admin_value\[memory_limit\] = .*/php_admin_value[memory_limit] = $PHP_MEMORY_LIMIT/" "$PHP_POOL_CONFIG"
        sed -i "s/php_admin_value\[max_execution_time\] = .*/php_admin_value[max_execution_time] = $PHP_MAX_EXECUTION_TIME/" "$PHP_POOL_CONFIG"
        sed -i "s/php_admin_value\[max_input_time\] = .*/php_admin_value[max_input_time] = $PHP_MAX_EXECUTION_TIME/" "$PHP_POOL_CONFIG"
        
        log_message "âœ… Updated PHP-FPM pool configuration: $PHP_POOL_CONFIG"
    else
        log_message "âš ï¸  PHP-FPM pool config not found at: $PHP_POOL_CONFIG"
    fi
    
    # Update PHP ini configuration if it exists
    if [ -f "$PHP_INI_CONFIG" ]; then
        # Note: PHP ini settings are also set in pool config, so we mainly ensure consistency
        log_message "âœ… PHP ini configuration exists: $PHP_INI_CONFIG"
    else
        log_message "âš ï¸  PHP ini config not found at: $PHP_INI_CONFIG"
    fi
}

# Helper function for systemctl commands in Docker mode
docker_systemctl() {
    if [ "$DOCKER_MODE" = "false" ]; then
        systemctl "$@"
    else
        echo "ðŸ³ Docker mode: skipping systemctl $*"
        return 0
    fi
}

# Package management functions
wait_for_dpkg_lock() {
    local timeout=300  # 5 minutes timeout
    local count=0
    
    log_message "Checking for package management locks..."
    
    while fuser /var/lib/dpkg/lock-frontend >/dev/null 2>&1 || fuser /var/cache/apt/archives/lock >/dev/null 2>&1; do
        if [ $count -ge $timeout ]; then
            log_error "Timeout waiting for package management lock - continuing anyway"
            break
        fi
        
        if [ $((count % 10)) -eq 0 ]; then
            log_message "Waiting for package management to complete... ($count/$timeout seconds)"
            # Show what process is holding the lock
            pgrep -af "(apt|dpkg|unattended)" || true
        fi
        
        sleep 1
        count=$((count + 1))
    done
    
    if [ $count -gt 0 ]; then
        log_message "Package management lock released after $count seconds"
    fi
}

# Enhanced package management with lock handling
safe_apt_update() {
    wait_for_dpkg_lock
    # Configure dpkg properly before update
    dpkg --configure -a
    apt-get update
}

safe_apt_install() {
    wait_for_dpkg_lock
    apt-get install -y "$@"
}

# Service management functions
start_service_with_retry() {
    local service="$1"
    local max_attempts=3
    local wait_time=5
    
    log_message "Starting service: $service"
    
    # Skip in Docker mode for services that don't work in containers
    if [ "$DOCKER_MODE" = "true" ]; then
        case "$service" in
            ufw|fail2ban|clamav-daemon|suricata)
                log_message "ðŸ³ Docker mode: skipping service $service"
                return 0
                ;;
        esac
    fi
    
    for attempt in $(seq 1 $max_attempts); do
        if docker_systemctl start "$service"; then
            sleep "$wait_time"
            if docker_systemctl is-active --quiet "$service"; then
                log_message "âœ… Service $service started successfully (attempt $attempt)"
                return 0
            fi
        fi
        log_message "âš ï¸ Service $service start attempt $attempt failed, retrying..."
        sleep $((wait_time * attempt))
    done
    
    log_error "âŒ Failed to start service $service after $max_attempts attempts"
    return 1
}

enable_and_start_service() {
    local service="$1"
    log_message "Enabling and starting service: $service"
    
    if [ "$DOCKER_MODE" = "true" ]; then
        case "$service" in
            ufw|fail2ban|clamav-daemon|suricata)
                log_message "ðŸ³ Docker mode: skipping service $service"
                return 0
                ;;
        esac
    fi
    
    docker_systemctl enable "$service"
    start_service_with_retry "$service"
}

# Input validation functions
validate_email() {
    local email="$1"
    if [[ "$email" =~ ^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$ ]]; then
        return 0
    else
        log_error "Invalid email format: $email"
        return 1
    fi
}

validate_ssh_key() {
    local key="$1"
    local temp_key_file
    
    if [ -z "$key" ]; then
        log_error "SSH key cannot be empty"
        return 1
    fi
    
    temp_key_file=$(mktemp)
    trap 'rm -f "$temp_key_file"' RETURN
    
    echo "$key" > "$temp_key_file"
    
    if ssh-keygen -l -f "$temp_key_file" >/dev/null 2>&1; then
        local key_bits
        key_bits=$(ssh-keygen -l -f "$temp_key_file" | awk '{print $1}')
        
        if [[ "$key" =~ ^ssh-ed25519 ]] || [ "$key_bits" -ge 2048 ]; then
            log_message "âœ… SSH key validation successful"
            return 0
        else
            log_error "SSH key too weak (minimum 2048 bits for RSA, or use Ed25519)"
            return 1
        fi
    else
        log_error "Invalid SSH key format"
        return 1
    fi
}

validate_port() {
    local port="$1"
    if [[ "$port" =~ ^[0-9]+$ ]] && [ "$port" -ge 1 ] && [ "$port" -le 65535 ]; then
        return 0
    else
        log_error "Invalid port number: $port (must be 1-65535)"
        return 1
    fi
}

# ========= Parameter Validation =========
log_message "ðŸ” Validating input parameters..."

# Validate SSH port
if ! validate_port "$SSH_PORT"; then
    log_error "Invalid SSH port configuration"
    exit 1
fi

# Validate SSH public key (if not in testing mode)
if [ "$TESTING_MODE" != "true" ] && [ -n "$SSH_PUBLIC_KEY" ]; then
    if ! validate_ssh_key "$SSH_PUBLIC_KEY"; then
        log_error "Invalid SSH public key configuration"
        exit 1
    fi
elif [ "$TESTING_MODE" != "true" ]; then
    log_error "SSH public key is required for security"
    exit 1
fi

# Validate email addresses
if [ -n "$LOGWATCH_EMAIL" ] && [ "$LOGWATCH_EMAIL" != "{{LOGWATCH_EMAIL}}" ]; then
    if ! validate_email "$LOGWATCH_EMAIL"; then
        log_error "Invalid logwatch email configuration"
        exit 1
    fi
fi

if [ "$SMTP_ENABLED" = "true" ] && [ -n "$SMTP_FROM_EMAIL" ] && [ "$SMTP_FROM_EMAIL" != "{{SMTP_FROM_EMAIL}}" ]; then
    if ! validate_email "$SMTP_FROM_EMAIL"; then
        log_error "Invalid SMTP from email configuration"
        exit 1
    fi
fi

# Validate hostname
if [ -z "$HOSTNAME" ] || [ "$HOSTNAME" = "{{HOSTNAME}}" ]; then
    log_error "Hostname must be configured"
    exit 1
fi

# Validate username
if [ -z "$USERNAME" ] || [ "$USERNAME" = "{{DEPLOY_USER}}" ]; then
    log_error "Deploy user must be configured"
    exit 1
fi

log_message "âœ… Parameter validation completed successfully"

# Configuration validation framework
validate_critical_configs() {
    local errors=0
    
    log_message "ðŸ” Validating critical configurations..."
    
    # SSH configuration validation
    log_message "Checking SSH configuration..."
    if [ "$DOCKER_MODE" = "false" ]; then
        if ! timeout 10 sshd -t 2>/dev/null; then
            log_error "SSH configuration validation failed"
            errors=$((errors + 1))
        else
            log_message "âœ… SSH configuration is valid"
        fi
    fi
    
    # UFW configuration validation  
    log_message "Checking UFW configuration..."
    if [ "$DOCKER_MODE" = "false" ]; then
        if ! timeout 10 ufw status >/dev/null 2>&1; then
            log_error "UFW configuration validation failed"
            errors=$((errors + 1))
        else
            log_message "âœ… UFW configuration is valid"
            # Check UFW status verbose for IPv6 and configuration details
            ufw_status=$(ufw status verbose 2>/dev/null)
            if echo "$ufw_status" | grep -q "IPV6: yes"; then
                log_message "âœ… UFW IPv6 support enabled"
            else
                log_message "âš ï¸ UFW IPv6 support disabled"
            fi
            if echo "$ufw_status" | grep -q "Status: active"; then
                log_message "âœ… UFW firewall is active"
            else
                log_error "UFW firewall is inactive"
                errors=$((errors + 1))
            fi
        fi
    fi
    
    # Fail2ban configuration validation
    log_message "Checking Fail2ban configuration..."
    if [ "$DOCKER_MODE" = "false" ]; then
        if ! timeout 15 fail2ban-client -t >/dev/null 2>&1; then
            log_message "âš ï¸ Fail2ban configuration validation timed out or failed"
            if ! docker_systemctl is-active --quiet fail2ban; then
                errors=$((errors + 1))
            fi
        else
            log_message "âœ… Fail2ban configuration is valid"
            # Check if fail2ban is using UFW backend as configured
            if fail2ban-client status 2>/dev/null | grep -q "sshd"; then
                log_message "âœ… Fail2ban SSH jail is active"
            else
                log_message "âš ï¸ Fail2ban SSH jail not found"
            fi
        fi
    fi
    
    # Nginx configuration validation (if nginx is installed)
    if command -v nginx >/dev/null 2>&1; then
        log_message "Checking Nginx configuration..."
        if ! nginx -t >/dev/null 2>&1; then
            log_error "Nginx configuration validation failed"
            errors=$((errors + 1))
        else
            log_message "âœ… Nginx configuration is valid"
        fi
    fi
    
    # AppArmor configuration validation
    log_message "Checking AppArmor status..."
    if [ "$DOCKER_MODE" = "false" ]; then
        if command -v aa-status >/dev/null 2>&1; then
            if aa_status_output=$(aa-status 2>/dev/null); then
                if echo "$aa_status_output" | grep -q "apparmor module is loaded"; then
                    log_message "âœ… AppArmor is enabled and loaded"
                    # Count enforce/complain profiles
                    enforce_count=$(echo "$aa_status_output" | grep -c "profiles are in enforce mode" || echo "0")
                    complain_count=$(echo "$aa_status_output" | grep -c "profiles are in complain mode" || echo "0")
                    if [ "$enforce_count" -gt 0 ] || [ "$complain_count" -gt 0 ]; then
                        log_message "âœ… AppArmor profiles active (enforce: $enforce_count, complain: $complain_count)"
                    else
                        log_message "âš ï¸ AppArmor enabled but no active profiles found"
                    fi
                else
                    log_error "AppArmor module not loaded"
                    errors=$((errors + 1))
                fi
            else
                log_error "Failed to get AppArmor status"
                errors=$((errors + 1))
            fi
        else
            log_error "AppArmor not installed (aa-status command not found)"
            errors=$((errors + 1))
        fi
    fi
    
    return $errors
}

# Backup and rollback system
create_rollback_point() {
    local checkpoint="$1"
    local timestamp
    timestamp=$(date +%s)
    local rollback_file="${BACKUP_DIR}/rollback-${checkpoint}-${timestamp}.tar.gz"
    
    log_message "ðŸ“¦ Creating rollback point: $checkpoint"
    
    # Create encrypted backup if gpg is available
    if command -v gpg >/dev/null 2>&1; then
        local encrypted_file="${rollback_file}.gpg"
        tar -czf - \
            /etc/ssh \
            /etc/ufw \
            /etc/fail2ban \
            /etc/nginx \
            /etc/postfix \
            2>/dev/null | gpg --symmetric --cipher-algo AES256 --compress-algo 1 --batch --yes --passphrase "server-backup-$(hostname)-$timestamp" > "$encrypted_file" 2>/dev/null
        
        if [ -f "$encrypted_file" ]; then
            echo "$encrypted_file" > "${BACKUP_DIR}/latest-rollback"
            log_message "âœ… Encrypted rollback point created: $checkpoint"
        fi
    else
        # Fallback to unencrypted backup
        tar -czf "$rollback_file" \
            /etc/ssh \
            /etc/ufw \
            /etc/fail2ban \
            /etc/nginx \
            /etc/postfix \
            2>/dev/null || log_message "âš ï¸ Some files missing during rollback creation"
        echo "$rollback_file" > "${BACKUP_DIR}/latest-rollback"
        log_message "âœ… Rollback point created: $checkpoint"
    fi
}

# ========= System Resource Detection =========
log_message "===== 0. Detecting system resources ====="
detect_system_resources

# Calculate optimization parameters based on detected resources
log_message "===== 0.1. Calculating optimization parameters ====="
calculate_optimization_parameters

# ========= Basic server hardening =========
log_message "===== 1. Updating system packages ====="
safe_apt_update && apt-get upgrade -y

echo "===== 2. Setting hostname ====="
if [ "$DOCKER_MODE" = "false" ]; then
    hostnamectl set-hostname "$HOSTNAME"
else
    echo "ðŸ³ Skipping hostname setup in Docker mode"
fi

echo "===== 2.1 Setting root password for emergency access ====="
if [ "$DOCKER_MODE" = "false" ]; then
    echo "Setting a secure root password for console/emergency access..."
    echo "This is important for recovery scenarios when SSH key access fails."
    echo ""
    echo "Please set a strong root password:"
    passwd root
    echo "âœ… Root password configured for emergency console access"
    echo ""
else
    echo "ðŸ³ Skipping root password setup in Docker mode"
fi

echo "===== 3. Creating non-root user ====="
if ! id "$USERNAME" &>/dev/null; then
  if [ "$DOCKER_MODE" = "true" ]; then
    # Non-interactive user creation for Docker
    useradd -m -s /bin/bash "$USERNAME"
    echo "$USERNAME:$USERNAME" | chpasswd
  else
    # Determine if we should create user with or without password
    if [ -n "$SSH_PUBLIC_KEY" ]; then
      echo "SSH public key provided - creating user without password prompt"
      useradd -m -s /bin/bash "$USERNAME"
      # Generate a random password and immediately expire it to force key-only auth
      TEMP_PASS=$(openssl rand -base64 32)
      echo "$USERNAME:$TEMP_PASS" | chpasswd
      passwd -e "$USERNAME"
    else
      echo "No SSH public key provided - user will be prompted to set password"
      adduser --gecos "" "$USERNAME"
    fi
  fi
  usermod -aG sudo "$USERNAME"
  
  # Create SSH directory for the new user
  mkdir -p /home/$USERNAME/.ssh
  chmod 700 /home/$USERNAME/.ssh
  chown $USERNAME:$USERNAME /home/$USERNAME/.ssh
  
  # Set up SSH key if provided
  if [ -n "$SSH_PUBLIC_KEY" ]; then
    echo "Setting up SSH public key for $USERNAME"
    echo "$SSH_PUBLIC_KEY" > /home/$USERNAME/.ssh/authorized_keys
    chmod 600 /home/$USERNAME/.ssh/authorized_keys
    chown $USERNAME:$USERNAME /home/$USERNAME/.ssh/authorized_keys
    echo "SSH key configured successfully"
  else
    # Try to copy existing keys as fallback
    if [ -f ~/.ssh/authorized_keys ]; then
      echo "Copying existing SSH keys from root user"
      cp ~/.ssh/authorized_keys /home/$USERNAME/.ssh/
      chmod 600 /home/$USERNAME/.ssh/authorized_keys
      chown $USERNAME:$USERNAME /home/$USERNAME/.ssh/authorized_keys
    else
      echo "No SSH keys available - password authentication will be enabled"
    fi
  fi
fi

echo "===== 4. Securing SSH ====="
if [ "$DOCKER_MODE" = "false" ]; then
    # Backup original SSH config
    cp /etc/ssh/sshd_config /etc/ssh/sshd_config.bak
    
    # Determine password authentication setting based on key availability
    if [ -n "$SSH_PUBLIC_KEY" ] || [ -f /home/$USERNAME/.ssh/authorized_keys ]; then
        PASSWORD_AUTH="no"
        echo "SSH keys are available - disabling password authentication"
    else
        PASSWORD_AUTH="yes"
        echo "No SSH keys available - enabling password authentication for initial setup"
        echo "WARNING: Remember to add SSH keys and disable password auth later!"
    fi
    
    # Configure SSH with comprehensive security hardening
    cat > /etc/ssh/sshd_config << EOF
# Comprehensive SSH Security Configuration for Debian 13

# Network and Protocol
Port $SSH_PORT
Protocol 2
AddressFamily any
ListenAddress 0.0.0.0
ListenAddress ::

# Host Keys (prefer Ed25519, fallback to RSA)
HostKey /etc/ssh/ssh_host_ed25519_key
HostKey /etc/ssh/ssh_host_rsa_key

# Authentication Security
PermitRootLogin no
PasswordAuthentication $PASSWORD_AUTH
PubkeyAuthentication yes
AuthenticationMethods publickey
AllowUsers $USERNAME

# Connection Limits and Timeouts
ClientAliveInterval 300
ClientAliveCountMax 2
LoginGraceTime 30
MaxAuthTries 2
MaxSessions 5
MaxStartups 3:30:10

# Forwarding Controls (Restrictive by Default)
AllowTcpForwarding local
PermitOpen 10.0.0.0/8:*,172.16.0.0/12:*,192.168.0.0/16:*
AllowAgentForwarding no
PermitTunnel no
GatewayPorts no
X11Forwarding no

# Modern Cryptographic Algorithms with Post-Quantum Support  
KexAlgorithms sntrup761x25519-sha512@openssh.com,curve25519-sha256,curve25519-sha256@libssh.org
Ciphers chacha20-poly1305@openssh.com,aes256-gcm@openssh.com,aes128-gcm@openssh.com
MACs hmac-sha2-512-etm@openssh.com,hmac-sha2-256-etm@openssh.com

# SFTP Subsystem (Internal with Logging)
Subsystem sftp internal-sftp -f AUTH -l INFO

# Security Features
IgnoreRhosts yes
HostbasedAuthentication no
PermitEmptyPasswords no
ChallengeResponseAuthentication no
UsePAM yes
StrictModes yes

# Feature Configuration
PrintMotd no
AcceptEnv LANG LC_*
Banner /etc/ssh/banner
EOF

    # Create SSH banner
    cat > /etc/ssh/banner << 'EOF'
**************************************************************************
*                                                                        *
*                 AUTHORIZED ACCESS ONLY                                 *
*                                                                        *
*  This system is for authorized users only. All activities may be      *
*  monitored and recorded. Unauthorized access is prohibited.           *
*                                                                        *
**************************************************************************
EOF

    chmod 644 /etc/ssh/banner
    
    # Ensure SSH host keys exist (fresh images sometimes defer generation)
    if [ ! -f /etc/ssh/ssh_host_ed25519_key ] || [ ! -f /etc/ssh/ssh_host_rsa_key ]; then
        log_message "Generating missing SSH host keys..."
        ssh-keygen -A
        log_message "âœ… SSH host keys generated"
    else
        log_message "âœ… SSH host keys already exist"
    fi
else
    echo "ðŸ³ Skipping SSH configuration in Docker mode"
fi

# Don't restart SSH yet - will do at the end to avoid disconnecting mid-setup

echo "===== 5. Setting up firewall ====="
if [ "$DOCKER_MODE" = "false" ]; then
    apt install -y ufw
    
    # Configure IPv6 support and nftables backend (Debian 13 default)
    sed -i 's/IPV6=no/IPV6=yes/' /etc/default/ufw
    
    # Ensure UFW uses nftables backend (Debian 13 default)
    # This ensures consistency with fail2ban UFW actions
    if ! grep -q "^BACKEND=nftables" /etc/default/ufw; then
        echo "BACKEND=nftables" >> /etc/default/ufw
    fi
    
    # Set default policies - deny incoming, allow outgoing (IPv4 and IPv6)
    ufw default deny incoming
    ufw default allow outgoing
    
    # Allow only necessary ports for both IPv4 and IPv6
    ufw allow $SSH_PORT/tcp comment "SSH"
    ufw allow 80/tcp comment "HTTP" 
    ufw allow 443/tcp comment "HTTPS"
    
    # Application direct ports removed for security (using Nginx proxy instead)
    # Enable the firewall non-interactively
    echo "y" | ufw enable
    # Show the status of the firewall
    ufw status verbose
else
    echo "ðŸ³ Skipping firewall setup in Docker mode"
fi

echo "===== 5.1. Configuring NTP time synchronization ====="
if [ "$DOCKER_MODE" = "false" ]; then
    # Ensure NTP synchronization is enabled (Debian 13 systemd-timesyncd)
    timedatectl set-ntp true
    
    # Verify NTP is working
    if timedatectl status | grep -q "NTP service: active"; then
        echo "âœ… NTP synchronization enabled and active"
    else
        echo "âš ï¸ NTP synchronization may not be working properly"
    fi
    
    # Show current time sync status
    timedatectl status
else
    echo "ðŸ³ Skipping NTP configuration in Docker mode (host handles time sync)"
fi

echo "===== 6. Web Server Selection ====="
echo "Choose between traditional nginx + PHP-FPM or modern NGINX Unit for better performance:"
echo ""

# Initialize web server choice
WEB_SERVER_TYPE="nginx"

echo "ðŸŒ Web Server Architecture Choice:"
echo ""
echo "ðŸ“Š Traditional nginx + PHP-FPM:"
echo "   â€¢ Widely used, battle-tested architecture"
echo "   â€¢ Separate nginx and PHP-FPM processes"
echo "   â€¢ Good performance, extensive documentation"
echo "   â€¢ Industry standard for most deployments"
echo ""
echo "ðŸš€ NGINX Unit (Modern Application Server):"
echo "   â€¢ Up to 8-10x faster response times than PHP-FPM"
echo "   â€¢ Single process handles web serving and PHP execution"
echo "   â€¢ Dynamic configuration without restarts"
echo "   â€¢ Better resource management under high load"
echo "   â€¢ Newer technology, smaller community support"
echo ""
read -p "Use NGINX Unit for better performance? (y/N): " -n 1 -r
echo
if [[ $REPLY =~ ^[Yy]$ ]]; then
    WEB_SERVER_TYPE="unit"
    echo "âœ… NGINX Unit selected - preparing for high-performance deployment"
    
    # Update environment file with web server choice
    if [ -f "/opt/polyserver/config/defaults.env" ]; then
        sed -i "s/WEB_SERVER_TYPE=nginx/WEB_SERVER_TYPE=unit/" "/opt/polyserver/config/defaults.env" 2>/dev/null || true
    fi
else
    WEB_SERVER_TYPE="nginx"
    echo "âœ… Traditional nginx + PHP-FPM selected - reliable and well-documented"
    
    # Environment file already has nginx as default, no change needed
fi

echo "===== 6.1 Security Components Configuration ====="
echo "Security components are configured via environment variables:"
echo "â€¢ INSTALL_CLAMAV=$INSTALL_CLAMAV (File scanning - HIGH resource usage)"
echo "â€¢ INSTALL_RKHUNTER=$INSTALL_RKHUNTER (Rootkit detection - LOW resource usage)"
if [ "$DOCKER_MODE" = "false" ]; then
    echo "â€¢ INSTALL_SURICATA=$INSTALL_SURICATA (Network IDS - MEDIUM resource usage)"
fi
echo ""

echo "===== 6.2 Installing core packages and web server ====="

# Core security packages (always installed)
CORE_PACKAGES="fail2ban unattended-upgrades apt-listchanges gnupg-agent logwatch apparmor apparmor-utils git awscli"

# Add optional security packages based on environment variables
OPTIONAL_PACKAGES=""
[ "$INSTALL_CLAMAV" = true ] && OPTIONAL_PACKAGES="$OPTIONAL_PACKAGES clamav clamav-daemon"
[ "$INSTALL_RKHUNTER" = true ] && OPTIONAL_PACKAGES="$OPTIONAL_PACKAGES rkhunter chkrootkit"
[ "$INSTALL_SURICATA" = true ] && OPTIONAL_PACKAGES="$OPTIONAL_PACKAGES suricata"

# Web server specific packages
if [ "$WEB_SERVER_TYPE" = "unit" ]; then
    echo "Installing NGINX Unit and PHP packages..."
    
    # Add NGINX Unit repository
    curl -1sLf 'https://packages.nginx.org/keys/nginx_signing.key' | gpg --dearmor > /usr/share/keyrings/nginx-archive-keyring.gpg
    echo "deb [signed-by=/usr/share/keyrings/nginx-archive-keyring.gpg] https://packages.nginx.org/unit/debian/ trixie unit" > /etc/apt/sources.list.d/unit.list
    
    apt-get update
    
    # Install NGINX Unit core and PHP module
    WEB_SERVER_PACKAGES="unit unit-php php8.4 php8.4-cli php8.4-fpm php8.4-mysql php8.4-xml php8.4-mbstring php8.4-curl php8.4-zip php8.4-gd php8.4-intl php8.4-bcmath php8.4-opcache php8.4-readline"
    
    echo "âœ… NGINX Unit selected - using high-performance application server"
else
    # Traditional nginx + PHP-FPM
    WEB_SERVER_PACKAGES="nginx-extras php8.4 php8.4-fpm php8.4-mysql php8.4-xml php8.4-mbstring php8.4-curl php8.4-zip php8.4-gd php8.4-intl php8.4-bcmath php8.4-opcache php8.4-readline"
    
    echo "âœ… Traditional nginx + PHP-FPM selected - using stable architecture"
fi

if [ "$DOCKER_MODE" = "true" ]; then
    # Docker-compatible package list
    apt-get install -y "$CORE_PACKAGES" "$WEB_SERVER_PACKAGES" "$OPTIONAL_PACKAGES" lm-sensors
else
    # Full package list for production servers
    apt-get install -y "$CORE_PACKAGES" "$WEB_SERVER_PACKAGES" "$OPTIONAL_PACKAGES" lm-sensors hddtemp unbound
fi

# Display installed optional security components
echo "âœ… Security package installation completed"
INSTALLED_COMPONENTS=""
[ "$INSTALL_CLAMAV" = true ] && INSTALLED_COMPONENTS="$INSTALLED_COMPONENTS clamav"
[ "$INSTALL_MALDET" = true ] && INSTALLED_COMPONENTS="$INSTALLED_COMPONENTS maldet"
[ "$INSTALL_RKHUNTER" = true ] && INSTALLED_COMPONENTS="$INSTALLED_COMPONENTS rkhunter"
[ "$INSTALL_SURICATA" = true ] && INSTALLED_COMPONENTS="$INSTALLED_COMPONENTS suricata"
echo "Installed optional security components:${INSTALLED_COMPONENTS:-none}"

# Web server specific post-installation configuration
if [ "$WEB_SERVER_TYPE" = "unit" ]; then
    echo "Configuring NGINX Unit..."
    systemctl enable unit
    systemctl start unit
    
    # Test Unit installation
    if systemctl is-active --quiet unit; then
        echo "âœ… NGINX Unit is running"
    else
        echo "âš ï¸ NGINX Unit failed to start - check logs: journalctl -u unit"
    fi
else
    echo "Configuring nginx and PHP-FPM..."
    systemctl enable nginx
    systemctl enable php8.4-fpm
    systemctl start php8.4-fpm
    
    # Test installations
    if systemctl is-active --quiet php8.4-fpm; then
        echo "âœ… PHP-FPM is running"
        
        # Update PHP-FPM configuration with calculated values
        update_php_fpm_config
        
        # Restart PHP-FPM to apply updated configuration
        systemctl restart php8.4-fpm
        if systemctl is-active --quiet php8.4-fpm; then
            echo "âœ… PHP-FPM restarted with optimized configuration"
        else
            echo "âš ï¸ PHP-FPM failed to restart after configuration update"
        fi
    else
        echo "âš ï¸ PHP-FPM failed to start - check logs: journalctl -u php8.4-fpm"
    fi
fi

# Security packages are now installed with the main package installation above

echo "===== 6.0.1 Installing CPU microcode updates ====="

# Check if running in a virtual environment
VIRT_TYPE=""
if [ -f /proc/cpuinfo ] && grep -q "hypervisor" /proc/cpuinfo; then
    VIRT_TYPE="hypervisor"
elif systemd-detect-virt &>/dev/null; then
    VIRT_TYPE=$(systemd-detect-virt)
elif [ -f /sys/hypervisor/type ]; then
    VIRT_TYPE=$(cat /sys/hypervisor/type)
fi

# Detect CPU vendor and install appropriate microcode updates
CPU_VENDOR=$(grep vendor_id /proc/cpuinfo | head -1 | awk '{print $3}')
echo "Detected CPU vendor: $CPU_VENDOR"

if [ -n "$VIRT_TYPE" ] && [ "$VIRT_TYPE" != "none" ]; then
    echo "ðŸ” Virtualization detected: $VIRT_TYPE"
    echo "âš ï¸  Note: In virtualized environments (OVH, Hetzner, AWS, etc.):"
    echo "   - Microcode updates are typically managed by the host/hypervisor"
    echo "   - VM-level microcode installation may not affect actual CPU vulnerability mitigations"
    echo "   - Contact your hosting provider for physical host microcode status"
    echo ""
    echo "Installing microcode package anyway for completeness..."
fi

if [ "$CPU_VENDOR" = "AuthenticAMD" ]; then
    echo "AMD processor detected - installing AMD microcode updates..."
    
    # Check if non-free-firmware repository is available
    if ! apt-cache search amd64-microcode | grep -q amd64-microcode; then
        echo "Adding non-free-firmware repository for AMD microcode..."
        
        # Check if we're using the new sources.list format (Debian 12+, still applicable in Debian 13)
        if [ -f /etc/apt/sources.list.d/debian.sources ]; then
            # Update existing debian.sources file to include non-free-firmware
            if ! grep -q "non-free-firmware" /etc/apt/sources.list.d/debian.sources; then
                echo "Updating debian.sources to include non-free-firmware..."
                sed -i 's/Components: main/Components: main non-free-firmware/' /etc/apt/sources.list.d/debian.sources
                apt-get update
            fi
        else
            # Add to traditional sources.list
            if ! grep -q "non-free-firmware" /etc/apt/sources.list; then
                echo "Adding non-free-firmware to sources.list..."
                sed -i 's/main$/main non-free-firmware/' /etc/apt/sources.list
                apt-get update
            fi
        fi
    fi
    
    # Install AMD microcode
    if apt-cache search amd64-microcode | grep -q amd64-microcode; then
        apt-get install -y amd64-microcode
        echo "âœ… AMD microcode installed successfully"
        echo "âš ï¸  Microcode will be active after next reboot"
    else
        echo "âš ï¸  AMD microcode package not available in repositories"
    fi
    
elif [ "$CPU_VENDOR" = "GenuineIntel" ]; then
    echo "Intel processor detected - installing Intel microcode updates..."
    apt-get install -y intel-microcode
    echo "âœ… Intel microcode installed successfully"
    echo "âš ï¸  Microcode will be active after next reboot"
    
else
    echo "Unknown or unsupported CPU vendor: $CPU_VENDOR"
    echo "Skipping microcode installation"
fi

# Update initramfs to include microcode and check for kernel updates
echo "===== 6.0.2 Updating system with microcode integration ====="

# Update initramfs to ensure microcode is loaded
echo "Updating initramfs to include microcode..."
update-initramfs -u -k all

# Check if kernel update is available and recommend it
echo "Checking for kernel updates..."
CURRENT_KERNEL=$(uname -r)
echo "Current kernel: $CURRENT_KERNEL"

# Check for available kernel updates
if apt list --upgradable 2>/dev/null | grep -q linux-image; then
    echo "âš ï¸  Kernel updates available:"
    apt list --upgradable 2>/dev/null | grep linux-image
    echo ""
    echo "ðŸ’¡ Kernel update recommendation:"
    echo "   Run: apt update && apt upgrade linux-image-*"
    echo "   Then reboot to activate microcode and kernel updates"
    KERNEL_UPDATE_NEEDED=true
else
    echo "âœ… Kernel is up to date"
    KERNEL_UPDATE_NEEDED=false
fi

# Export kernel update status for potential use by other scripts
export KERNEL_UPDATE_NEEDED

# Check for backports kernel if available (often has better hardware support)
if apt-cache search linux-image | grep -q backports; then
    echo ""
    echo "ðŸ’¡ Backports kernel available for better hardware support:"
    apt-cache search linux-image | grep backports | head -3
    echo "   Consider: apt install -t trixie-backports linux-image-amd64"
fi

# Show current CPU vulnerabilities status
echo ""
echo "Current CPU vulnerability status:"
if [ -d /sys/devices/system/cpu/vulnerabilities ]; then
    for vuln in /sys/devices/system/cpu/vulnerabilities/*; do
        vuln_name=$(basename "$vuln")
        vuln_status=$(cat "$vuln")
        printf "  %-25s %s\n" "$vuln_name:" "$vuln_status"
    done
else
    echo "  CPU vulnerability information not available"
fi

# Check if microcode is properly loaded
echo ""
echo "Microcode status:"
if dmesg | grep -i microcode | tail -5 | grep -q "updated"; then
    echo "âœ… Microcode updates detected in dmesg"
    dmesg | grep -i microcode | tail -2
else
    if [ -n "$VIRT_TYPE" ] && [ "$VIRT_TYPE" != "none" ]; then
        echo "â„¹ï¸  No microcode updates in dmesg (expected in virtualized environment)"
        echo "   Microcode management is handled by the hypervisor/host system"
    else
        echo "âš ï¸  Microcode updates not visible in dmesg (may require reboot)"
    fi
fi

# Check initramfs for microcode
if [ -f "/boot/initrd.img-$(uname -r)" ]; then
    if lsinitramfs "/boot/initrd.img-$(uname -r)" 2>/dev/null | grep -q microcode; then
        echo "âœ… Microcode files present in initramfs"
        lsinitramfs "/boot/initrd.img-$(uname -r)" 2>/dev/null | grep microcode | head -3
    else
        echo "âš ï¸  No microcode files found in initramfs"
    fi
fi
echo ""

echo "===== 6.1 Installing incident response and monitoring tools ====="
# System monitoring
apt-get install -y htop iotop sysstat atop bmon

# Network monitoring
apt-get install -y iftop nethogs tcpdump ethtool iperf3 netcat-openbsd

# Network diagnostics
apt-get install -y mtr-tiny arp-scan dnsutils net-tools traceroute whois

# File integrity
apt-get install -y debsums aide

# Configure lm-sensors with enhanced detection and logwatch integration
echo "===== 6.1.1 Configuring hardware sensors with enhanced detection ====="

# Enhanced sensor detection and configuration
echo "Running comprehensive sensor detection..."

# Run sensors-detect automatically with safe defaults
if command -v sensors-detect >/dev/null 2>&1; then
    echo "Running sensors-detect with safe automatic detection..."
    # Run sensors-detect with automatic yes to safe drivers only
    echo -e "y\ny\ny\ny\ny\nn" | sensors-detect --auto 2>/dev/null || true
    
    # Load detected modules
    if [ -f /etc/modules ]; then
        echo "Loading detected sensor modules..."
        systemctl restart systemd-modules-load 2>/dev/null || true
        # Try manual module loading for common sensors
        for module in coretemp k10temp it87 w83627ehf nct6775; do
            modprobe $module 2>/dev/null || true
        done
    fi
fi

# Re-check sensors after detection
if command -v sensors >/dev/null 2>&1; then
    # Wait for modules to initialize
    sleep 2
    
    # Check if sensors are now detected
    if sensors 2>/dev/null | grep -q "Â°C\|Â°F\|RPM\|V\|W"; then
        echo "âœ… Hardware sensors detected after module loading"
        
        # Show detected sensors
        echo "Detected sensors:"
        sensors 2>/dev/null | grep -E "Core|temp|fan|Â°C|Â°F|RPM|V|W" | head -10
        
        # Enable lm-sensors service
        systemctl enable lm-sensors 2>/dev/null || true
        systemctl start lm-sensors 2>/dev/null || true
        
        # Configure sensors for logwatch
        echo "Configuring sensors for logwatch integration..."
        mkdir -p /etc/logwatch/conf/services
        
        # Create sensors service configuration for logwatch
        cat > /etc/logwatch/conf/services/sensors.conf << 'EOF'
# Sensors monitoring for logwatch
Title = "Hardware Sensors"
LogFile = sensors
*OnlyService = sensors
*RemoveHeaders = Yes
EOF
        
        # Create sensor logging script for logwatch
        mkdir -p /var/log/sensors
        cat > /usr/local/bin/log-sensors << 'EOF'
#!/bin/bash
# Log sensor data for logwatch analysis
LOGFILE="/var/log/sensors/sensors.log"
DATE=$(date '+%Y-%m-%d %H:%M:%S')

# Ensure log directory exists
mkdir -p /var/log/sensors

# Log current sensor readings
echo "[$DATE] Sensor readings:" >> "$LOGFILE"
sensors >> "$LOGFILE" 2>/dev/null
echo "" >> "$LOGFILE"

# Check for critical temperatures and log alerts
if sensors 2>/dev/null | grep -E "CRITICAL|ALARM" | grep -v "+0.0"; then
    echo "[$DATE] CRITICAL: Sensor alerts detected!" >> "$LOGFILE"
    sensors 2>/dev/null | grep -E "CRITICAL|ALARM" >> "$LOGFILE"
    echo "" >> "$LOGFILE"
fi

# Rotate log if it gets too large (keep last 1000 lines)
if [ -f "$LOGFILE" ] && [ $(wc -l < "$LOGFILE") -gt 1000 ]; then
    tail -n 500 "$LOGFILE" > "${LOGFILE}.tmp" && mv "${LOGFILE}.tmp" "$LOGFILE"
fi
EOF
        
        chmod +x /usr/local/bin/log-sensors
        
        # Add sensor logging to cron (every 10 minutes)
        echo "*/10 * * * * root /usr/local/bin/log-sensors" >> /etc/crontab
        
        # Update logwatch configuration to include sensors
        if [ -f /etc/logwatch/conf/logwatch.conf ]; then
            # Check if sensors service already included
            if ! grep -q "sensors" /etc/logwatch/conf/logwatch.conf; then
                echo "Service = sensors" >> /etc/logwatch/conf/logwatch.conf
                echo "âœ… Sensors added to logwatch daily reports"
            fi
        fi
        
        # Create logrotate configuration for sensor logs
        cat > /etc/logrotate.d/sensors << EOF
/var/log/sensors/*.log {
    weekly
    rotate 4
    compress
    delaycompress
    missingok
    notifempty
    create 644 root root
}
EOF
        
        echo "âœ… Hardware sensors configured with logwatch integration"
        echo "   â€¢ Sensor data logged every 10 minutes"
        echo "   â€¢ Critical temperature alerts logged"
        echo "   â€¢ Included in daily logwatch reports"
        
        # Run initial sensor logging
        /usr/local/bin/log-sensors
        
    else
        echo "No hardware sensors detected even after module detection"
        echo "This is normal for virtual machines and cloud instances"
        
        # Disable sensors service and suppress warnings
        systemctl disable lm-sensors 2>/dev/null || true
        systemctl mask lm-sensors 2>/dev/null || true
        
        # Create empty sensors config to prevent startup warnings
        mkdir -p /etc/sensors.d
        cat > /etc/sensors.d/no-sensors.conf << 'EOF'
# No hardware sensors configuration
# This file prevents sensors warnings on systems without hardware monitoring
EOF
        echo "âœ… Sensors warnings suppressed for VPS/cloud environment"
        
        # Create fake sensor log for logwatch (prevents errors)
        mkdir -p /var/log/sensors
        cat > /var/log/sensors/sensors.log << EOF
# No hardware sensors available on this system
# This is normal for virtual machines and cloud instances
EOF
        
        # Still add sensors to logwatch but with a note about no sensors
        if [ -f /etc/logwatch/conf/logwatch.conf ]; then
            if ! grep -q "sensors" /etc/logwatch/conf/logwatch.conf; then
                echo "Service = sensors" >> /etc/logwatch/conf/logwatch.conf
                echo "âœ… Sensors service added to logwatch (will show 'no sensors' message)"
            fi
        fi
    fi
else
    echo "Sensors command not available - installing lm-sensors package"
    apt-get update && apt-get install -y lm-sensors
    echo "âœ… lm-sensors installed - rerun script or manually run sensors-detect"
fi

# Log monitoring
apt-get install -y logcheck logcheck-database

# Audit framework
apt-get install -y auditd audispd-plugins

# Enhanced shell environment
echo "===== 6.2 Installing enhanced shell environment ====="
apt-get install -y zsh vim git curl locales

# Configure locale to avoid character encoding issues
sed -i '/en_US.UTF-8/s/^# //g' /etc/locale.gen
locale-gen

# Install Oh My Zsh for deploy user
if id "$USERNAME" &>/dev/null; then
    echo "Installing Oh My Zsh for $USERNAME..."
    sudo -u $USERNAME sh -c "$(curl -fsSL https://raw.github.com/ohmyzsh/ohmyzsh/master/tools/install.sh)" "" --unattended
    
    # Configure Oh My Zsh with useful plugins
    sudo -u $USERNAME sed -i 's/plugins=(git)/plugins=(git docker sudo systemd colored-man-pages)/' /home/$USERNAME/.zshrc
fi

# Install Oh My Zsh for root user as well
echo "Installing Oh My Zsh for root..."
sh -c "$(curl -fsSL https://raw.github.com/ohmyzsh/ohmyzsh/master/tools/install.sh)" "" --unattended
sed -i 's/plugins=(git)/plugins=(git docker sudo systemd colored-man-pages)/' /root/.zshrc

# Configure vim globally with enhanced settings for server administration
cat > /etc/vim/vimrc.local << EOF
" PolyServer Enhanced Vim Configuration
" Optimized for server administration and configuration editing

" Basic settings
syntax on
set number
set ruler
set showcmd
set showmatch
set incsearch
set hlsearch
set ignorecase
set smartcase

" Indentation and formatting
set tabstop=4
set shiftwidth=4
set expandtab
set autoindent
set smartindent

" Interface enhancements
set laststatus=2
set wildmenu
set wildmode=longest:full,full
set scrolloff=3
set sidescrolloff=5

" File handling
set nobackup
set noswapfile
set autoread
set encoding=utf-8

" Mouse and clipboard (disabled for server use)
set mouse=
set clipboard=

" Security (disable modelines for security)
set nomodeline
set modelines=0

" Color scheme
colorscheme default

" Status line
set statusline=%F%m%r%h%w\ [FORMAT=%{&ff}]\ [TYPE=%Y]\ [POS=%l,%v][%p%%]\ %{strftime(\"%d/%m/%y\ -\ %H:%M\")}

" Useful key mappings for server configuration files
" Clear search highlighting
nnoremap <silent> <C-l> :nohlsearch<CR><C-l>

" Quick save
nnoremap <C-s> :w<CR>
inoremap <C-s> <Esc>:w<CR>a

" File type specific settings
augroup ServerConfigs
    autocmd!
    " Nginx configuration files
    autocmd BufRead,BufNewFile *.conf setlocal filetype=nginx
    autocmd BufRead,BufNewFile nginx.conf setlocal filetype=nginx
    autocmd BufRead,BufNewFile */nginx/* setlocal filetype=nginx
    
    " Shell scripts
    autocmd BufRead,BufNewFile *.sh setlocal filetype=sh
    autocmd FileType sh setlocal tabstop=2 shiftwidth=2
    
    " YAML files (Docker Compose, etc.)
    autocmd BufRead,BufNewFile *.yml,*.yaml setlocal filetype=yaml
    autocmd FileType yaml setlocal tabstop=2 shiftwidth=2
    
    " JSON files
    autocmd BufRead,BufNewFile *.json setlocal filetype=json
    autocmd FileType json setlocal tabstop=2 shiftwidth=2
    
    " Environment files
    autocmd BufRead,BufNewFile .env*,*.env setlocal filetype=sh
    
    " Log files (read-only, no line numbers for better readability)
    autocmd BufRead,BufNewFile *.log setlocal readonly nonumber nowrap
augroup END

" Highlight trailing whitespace
highlight ExtraWhitespace ctermbg=red guibg=red
match ExtraWhitespace /\s\+$/

" Show tabs and trailing spaces
set listchars=tab:>-,trail:Â·,extends:>,precedes:<
set list
EOF

# Source the vim config in the main vimrc
echo 'source /etc/vim/vimrc.local' >> /etc/vim/vimrc

# Create a vim configuration info file for reference
cat > /etc/vim/polyserver-vim-help.txt << EOF
PolyServer Vim Configuration - Quick Reference
=============================================

Key Features:
- Syntax highlighting enabled
- Line numbers and ruler
- Smart indentation (4 spaces, expanded tabs)
- Case-insensitive search with smart case
- No mouse support (server-optimized)
- No backup/swap files for cleaner filesystem
- Security hardened (modelines disabled)

File Type Support:
- Nginx configuration files (.conf, nginx.conf)
- Shell scripts (.sh) - 2-space indentation
- YAML files (.yml, .yaml) - 2-space indentation  
- JSON files (.json) - 2-space indentation
- Environment files (.env, .env.*) 
- Log files - read-only mode, no line numbers

Quick Keys:
- Ctrl+L: Clear search highlighting
- Ctrl+S: Quick save

Visual Aids:
- Trailing whitespace highlighted in red
- Tabs and spaces visible
- Status line shows file info and timestamp

To view this help: cat /etc/vim/polyserver-vim-help.txt
EOF

echo "Enhanced vim configuration installed with server administration optimizations"

# Create global aliases for all users
cat > /etc/profile.d/polyserver-aliases.sh << EOF
#!/bin/bash
alias ll="ls -la"
alias la="ls -A"
alias l="ls -CF"
alias grep="grep --color=auto"
alias fgrep="fgrep --color=auto"
alias egrep="egrep --color=auto"
EOF
chmod +x /etc/profile.d/polyserver-aliases.sh

# Create executable commands for non-interactive shells
cat > /usr/local/bin/ll << EOF
#!/bin/bash
ls -la "\$@"
EOF
chmod +x /usr/local/bin/ll

cat > /usr/local/bin/la << EOF
#!/bin/bash
ls -A "\$@"
EOF
chmod +x /usr/local/bin/la

# Add aliases to both users' shell configs
if id "$USERNAME" &>/dev/null; then
    echo 'source /etc/profile.d/polyserver-aliases.sh 2>/dev/null || true' >> /home/$USERNAME/.zshrc
fi
echo 'source /etc/profile.d/polyserver-aliases.sh 2>/dev/null || true' >> /root/.zshrc

echo "Enhanced shell environment configured with zsh, Oh My Zsh, vim enhancements, and useful aliases"

# ========= Configure Email System =========
echo "===== 6.5 Configuring Email System ====="

if [ "$SMTP_ENABLED" = "true" ]; then
    echo "SMTP configuration enabled - using external SMTP for reliable email delivery"
    echo "SMTP Server: $SMTP_SERVER:$SMTP_PORT"
    echo "From: $SMTP_FROM_EMAIL -> To: $LOGWATCH_EMAIL"
else
    echo "SMTP disabled - using local mail delivery (emails stored locally only)"
fi

# Pre-configure postfix for mail delivery
echo "postfix postfix/main_mailer_type string 'Internet Site'" | debconf-set-selections
echo "postfix postfix/mailname string $(hostname -f)" | debconf-set-selections

# Install mail system
apt-get install -y mailutils postfix

# Stop postfix for configuration
systemctl stop postfix 2>/dev/null || true

if [ "$SMTP_ENABLED" = "true" ]; then
    echo "Configuring external SMTP for reliable email delivery..."
    
    # Install SASL packages for SMTP authentication
    apt-get install -y libsasl2-modules
    
    # Configure postfix for external SMTP relay
    postconf -e "relayhost = [$SMTP_SERVER]:$SMTP_PORT"
    # Note: smtp_use_tls is deprecated, using smtp_tls_security_level instead
    postconf -e "smtp_sasl_auth_enable = yes"
    postconf -e "smtp_sasl_security_options = noanonymous"
    postconf -e "smtp_sasl_password_maps = hash:/etc/postfix/sasl_passwd"
    postconf -e "smtp_tls_security_level = encrypt"
    postconf -e "smtp_tls_note_starttls_offer = yes"
    postconf -e "smtp_tls_CAfile = /etc/ssl/certs/ca-certificates.crt"
    
    # Disable SMTPUTF8 for compatibility with Amazon SES
    postconf -e "smtputf8_enable = no"
    
    # Critical: Configure postfix to send ALL mail via SMTP relay (satellite mode)
    postconf -e "mydestination ="
    postconf -e "myorigin = \$myhostname"
    postconf -e "inet_interfaces = loopback-only"
    postconf -e "mynetworks = 127.0.0.0/8"
    postconf -e "local_transport = error:local delivery is disabled"
    postconf -e "alias_maps ="
    postconf -e "alias_database ="
    postconf -e "local_recipient_maps ="
    postconf -e "mailbox_command ="
    postconf -e "mailbox_transport ="
    postconf -e "home_mailbox ="
    postconf -e "mail_spool_directory ="
    postconf -e "virtual_alias_maps ="
    postconf -e "virtual_mailbox_maps ="
    postconf -e "transport_maps ="
    
    # FORCE all mail to go via SMTP - override any local delivery attempts
    postconf -e "default_transport = smtp:[$SMTP_SERVER]:$SMTP_PORT"
    postconf -e "fallback_transport = smtp:[$SMTP_SERVER]:$SMTP_PORT"
    
    # Configure sender rewriting to use the SMTP from address
    postconf -e "sender_canonical_maps = regexp:/etc/postfix/sender_canonical"
    postconf -e "smtp_header_checks = regexp:/etc/postfix/smtp_header_checks"
    
    # Create recipient canonical map to redirect all local recipients
    cat > /etc/postfix/recipient_canonical << EOF
# Redirect all local recipients to external email address
root@$HOSTNAME    $LOGWATCH_EMAIL
$USERNAME@$HOSTNAME $LOGWATCH_EMAIL
admin@$HOSTNAME   $LOGWATCH_EMAIL
security@$HOSTNAME $LOGWATCH_EMAIL
postmaster@$HOSTNAME $LOGWATCH_EMAIL
webmaster@$HOSTNAME $LOGWATCH_EMAIL
root@\$(hostname)    $LOGWATCH_EMAIL
$USERNAME@\$(hostname) $LOGWATCH_EMAIL
admin@\$(hostname)   $LOGWATCH_EMAIL
security@\$(hostname) $LOGWATCH_EMAIL
postmaster@\$(hostname) $LOGWATCH_EMAIL
webmaster@\$(hostname) $LOGWATCH_EMAIL
EOF
    
    # Configure recipient canonical mapping
    postconf -e "recipient_canonical_maps = hash:/etc/postfix/recipient_canonical"
    postmap /etc/postfix/recipient_canonical
    
    # Create SASL password file
    cat > /etc/postfix/sasl_passwd << EOF
[$SMTP_SERVER]:$SMTP_PORT    $SMTP_USERNAME:$SMTP_PASSWORD
EOF
    
    # Secure the password file
    chmod 600 /etc/postfix/sasl_passwd
    chown root:root /etc/postfix/sasl_passwd
    
    # Create the hash database
    postmap /etc/postfix/sasl_passwd
    
    # Create sender canonical map to rewrite all From addresses
    cat > /etc/postfix/sender_canonical << EOF
# Rewrite all sender addresses to use the SMTP from address
/.*/    $SMTP_FROM_EMAIL
EOF
    
    # Create header checks to rewrite From headers
    cat > /etc/postfix/smtp_header_checks << EOF
# Rewrite From header to use proper SMTP from address
/^From:.*/ REPLACE From: $SMTP_FROM_EMAIL
EOF
    
    # Create hash databases for maps
    postmap /etc/postfix/sender_canonical
    postmap /etc/postfix/smtp_header_checks
    
    # Create aliases to redirect all local mail to the configured email address
    cat > /etc/aliases << EOF
# All local mail redirected to external email address
root: $LOGWATCH_EMAIL
$USERNAME: $LOGWATCH_EMAIL
admin: $LOGWATCH_EMAIL
security: $LOGWATCH_EMAIL
postmaster: $LOGWATCH_EMAIL
MAILER-DAEMON: $LOGWATCH_EMAIL
webmaster: $LOGWATCH_EMAIL
EOF

    # Build alias database
    newaliases

else
    echo "Configuring local-only mail system..."
    
    # Configure postfix for local-only delivery
    postconf -e "inet_interfaces = loopback-only"
    postconf -e "mydestination = \$myhostname, localhost.\$mydomain, localhost"
    postconf -e "myorigin = \$mydomain"
    postconf -e "relayhost ="
    postconf -e "mynetworks = 127.0.0.0/8"
    postconf -e "local_transport = local:\$myhostname"
    postconf -e "default_transport = local"
    
    # Create mail directories with proper permissions
    mkdir -p /var/mail
    chmod 1777 /var/mail
    mkdir -p /var/spool/mail
    chmod 1777 /var/spool/mail
    
    # Ensure mail directory ownership
    chown root:mail /var/mail
    chown root:mail /var/spool/mail
    
    # Create local mail aliases (all external emails go to root locally)
    cat > /etc/aliases << EOF
# Local mail aliases for server
# All external email addresses are redirected to local root account
root: root
$LOGWATCH_EMAIL: root
$USERNAME: root
webmaster: root
admin: root
security: root
postmaster: root
MAILER-DAEMON: root
EOF

    # Build alias database
    newaliases
fi

# Enable and start postfix with new configuration
create_rollback_point "postfix-config"
enable_and_start_service postfix

# Check if we're in a container environment
CONTAINER_ENV=""
if [ -f /.dockerenv ] || [ -n "${CONTAINER}" ] || [ "${TESTING_MODE}" = "true" ]; then
    CONTAINER_ENV="true"
    echo "ðŸ“¦ Container environment detected - mail testing will be simplified"
fi

echo "âœ… Email system configured"

# Test mail system
echo "===== Testing mail system ====="

# Skip intensive mail testing in container environments
if [ "$CONTAINER_ENV" = "true" ]; then
    echo "ðŸ“¦ Container environment - skipping detailed mail testing"
    echo "âœ… Mail system configuration completed"
    echo "ðŸ“§ Mail functionality will be available when deployed"
elif [ "$SMTP_ENABLED" = "true" ]; then
    echo "Testing external SMTP configuration..."
    
    # Create test message with proper From header
    cat > /tmp/smtp_test_email.txt << EOF
From: $SMTP_FROM_EMAIL
To: $LOGWATCH_EMAIL
Subject: SMTP Test - PolyServer Setup Complete

This is a test email from your PolyServer setup.
If you receive this email, external SMTP is working correctly.

Server: $(hostname)
Setup completed: $(date)
SMTP Server: $SMTP_SERVER
From Address: $SMTP_FROM_EMAIL
Destination: $LOGWATCH_EMAIL

All security notifications will be sent to this email address.
EOF
    
    # Send via sendmail
    /usr/sbin/sendmail -f "$SMTP_FROM_EMAIL" "$LOGWATCH_EMAIL" < /tmp/smtp_test_email.txt
    
    echo "âœ… Test email sent to $LOGWATCH_EMAIL via external SMTP"
    echo "ðŸ“§ Check your email inbox to confirm delivery"
    
    # Check mail queue for any issues (container-safe)
    sleep 3
    if command -v mailq >/dev/null 2>&1; then
        QUEUE_STATUS=$(mailq 2>/dev/null || echo "queue check failed")
        if [[ "$QUEUE_STATUS" == "Mail queue is empty" ]]; then
            echo "âœ… Mail queue is empty - email sent successfully"
        elif [[ "$QUEUE_STATUS" == "queue check failed" ]]; then
            echo "âš ï¸ Mail queue check failed (normal in container environments)"
            echo "âœ… SMTP test email sent (queue verification skipped)"
        else
            echo "âš ï¸ Mail queue status:"
            echo "$QUEUE_STATUS" | head -n 10
        fi
    else
        echo "âœ… SMTP test email sent (mailq not available)"
    fi
    
else
    echo "Testing local mail system..."
    
    # Create test message for local delivery
    echo "Subject: Local Mail Test - PolyServer Setup

Testing local mail system during PolyServer setup...
This test confirms local mail delivery is working.
All external emails will be stored locally.
Timestamp: $(date)
Server: $(hostname)
" | /usr/sbin/sendmail "${LOGWATCH_EMAIL:-root}"
    
    echo "âœ… Test email sent to local account"
    
    # Wait for delivery
    sleep 5
    
    # Check if mail was delivered locally
    if [ -f /var/mail/root ]; then
        echo "âœ… Local mail delivery confirmed in /var/mail/root"
        echo "Mail file size: $(stat -c%s /var/mail/root 2>/dev/null | numfmt --to=iec || echo "unknown")"
    elif [ -f /var/spool/mail/root ]; then
        echo "âœ… Local mail delivery confirmed in /var/spool/mail/root"
        echo "Mail file size: $(stat -c%s /var/spool/mail/root 2>/dev/null | numfmt --to=iec || echo "unknown")"
    else
        echo "âš ï¸ Mail file not found - checking postfix status and logs"
        systemctl status postfix --no-pager -l 2>/dev/null || echo "Postfix status check failed (normal in containers)"
        echo "Checking mail queue:"
        mailq 2>/dev/null || echo "Mail queue check failed (normal in container environments)"
        echo "âœ… Local mail test completed (delivery may be delayed in containers)"
    fi
fi

# Only check postfix configuration if not in container environment  
if [ "$CONTAINER_ENV" != "true" ]; then
    # Check postfix configuration and logs
    echo ""
    echo "Postfix configuration check:"
    if [ "$SMTP_ENABLED" = "true" ]; then
        postconf relayhost 2>/dev/null || echo "postconf failed"
        postconf smtp_sasl_auth_enable 2>/dev/null || echo "postconf failed"
        postconf smtp_tls_security_level 2>/dev/null || echo "postconf failed"
    else
        postconf inet_interfaces 2>/dev/null || echo "postconf failed"
        postconf mydestination 2>/dev/null || echo "postconf failed"
        postconf local_transport 2>/dev/null || echo "postconf failed"
    fi

    echo ""
    echo "Recent postfix logs:"
    tail -n 10 /var/log/mail.log 2>/dev/null || echo "Mail log not yet available"
fi

echo ""
if [ "$SMTP_ENABLED" = "true" ]; then
    echo "ðŸ“§ Mail system configured with external SMTP for reliable delivery"
    echo "ðŸ“§ All security notifications will be sent to: $LOGWATCH_EMAIL"
else
    echo "ðŸ“§ Mail system configured for local delivery only"
    echo "ðŸ“§ All email notifications will be stored in local root mailbox"
fi

# Clean up temporary files
rm -f /tmp/smtp_test_email.txt

# Configure automatic security updates (enabled by default)
cat > /etc/apt/apt.conf.d/20auto-upgrades << EOF
APT::Periodic::Update-Package-Lists "1";
APT::Periodic::Unattended-Upgrade "1";
APT::Periodic::AutocleanInterval "7";
EOF

# Configure unattended-upgrades for security patches only
cat > /etc/apt/apt.conf.d/50unattended-upgrades << EOF
Unattended-Upgrade::Allowed-Origins {
    "\${distro_id}:\${distro_codename}-security";
};

// Automatically reboot if required (at 2 AM)
Unattended-Upgrade::Automatic-Reboot "true";
Unattended-Upgrade::Automatic-Reboot-Time "02:00";

// Send email to admin if there are problems
Unattended-Upgrade::Mail "${LOGWATCH_EMAIL:-root}";
Unattended-Upgrade::MailReport "only-on-error";

// Remove unused dependencies
Unattended-Upgrade::Remove-Unused-Dependencies "true";

// Allow package downgrade if needed for security
Unattended-Upgrade::Allow-downgrade "true";
EOF

# Configure automatic service restart without interactivity
cat > /etc/needrestart/conf.d/unattended.conf << 'EOF'
# Automatically restart services without prompting during unattended upgrades
\$nrconf{restart} = 'a';
EOF

# Configure fail2ban for SSH
if [ "$DOCKER_MODE" = "false" ]; then
    # Ensure required log files exist before fail2ban starts
    echo "Creating required log files for fail2ban..."
    touch /var/log/auth.log
    touch /var/log/fail2ban.log
    chmod 640 /var/log/auth.log
    chmod 640 /var/log/fail2ban.log
    chown root:adm /var/log/auth.log
    chown root:adm /var/log/fail2ban.log
    
    # Create a test log entry to initialize auth.log
    logger -p auth.info "Server setup: Initializing auth.log for fail2ban"
    
    cat > /etc/fail2ban/jail.local << EOF
    [DEFAULT]
    # Enable IPv6 support for modern infrastructure
    allowipv6 = yes
    # Do not ban localhost and the trusted client IP if provided
    ignoreip = 127.0.0.1/8 ::1 ${CLIENT_IP:-}

    # Use systemd backend for Debian 13 reliability
    backend = systemd

    # Use UFW/nftables for Debian 13 firewall management
    banaction = ufw
    banaction_allports = ufw
    action = %(banaction)s[blocktype=reject]

    [sshd]
    enabled = true
    port = $SSH_PORT
    filter = sshd
    logpath = /var/log/auth.log
    maxretry = 3
    bantime = 3600
    findtime = 600

    [sshd-ddos]
    enabled = true
    port = $SSH_PORT
    filter = sshd-ddos
    logpath = /var/log/auth.log
    maxretry = 2
    bantime = 3600

    [recidive]
    enabled = true
    filter = recidive
    logpath = /var/log/fail2ban.log
    action = %(banaction)s[name=recidive, port="all"]
    bantime = 86400
    findtime = 86400
    maxretry = 5
EOF

    # Create custom filter for SSH pre-auth connection floods and non-identifying clients
    cat > /etc/fail2ban/filter.d/sshd-ddos.conf << 'EOF'
    # Fail2Ban filter for SSH pre-auth connection floods and non-identifying clients
    [Definition]
    failregex = ^.*sshd\[\d+\]: Did not receive identification string from <HOST>\s*$
                ^.*sshd\[\d+\]: Connection closed by <HOST> port \d+ \[preauth\]$
                ^.*sshd\[\d+\]: Disconnected from <HOST> port \d+ \[preauth\]$
                ^.*sshd\[\d+\]: Connection reset by <HOST> port \d+ \[preauth\]$
    ignoreregex =
EOF
    
    # Test fail2ban configuration before starting
    echo "Testing fail2ban configuration..."
    if fail2ban-client -t; then
        echo "âœ… Fail2ban configuration is valid"
    else
        echo "âš ï¸ Fail2ban configuration test failed - checking for issues"
        fail2ban-client -t || true
    fi
    
    # Enable and start fail2ban with error handling
    create_rollback_point "fail2ban-config"
    
    # Stop fail2ban if it's already running to ensure clean start
    docker_systemctl stop fail2ban 2>/dev/null || true
    sleep 1
    
    if enable_and_start_service fail2ban; then
        # Test fail2ban client connection
        if [ "$DOCKER_MODE" = "false" ] && fail2ban-client status >/dev/null 2>&1; then
            log_message "âœ… Fail2ban client communication working"
            fail2ban-client status || true
        else
            log_message "âš ï¸ Fail2ban status check failed (may still be initializing)"
        fi
    else
        log_error "âŒ Failed to start fail2ban service"
        if [ "$DOCKER_MODE" = "false" ]; then
            systemctl status fail2ban --no-pager -l || true
        fi
    fi
else
    echo "ðŸ³ Skipping fail2ban configuration in Docker mode"
fi

# Configure hardware sensors
echo "===== 7. Configuring hardware monitoring ====="
if [ "$DOCKER_MODE" = "false" ]; then
    # Detect and configure sensors automatically
    yes | sensors-detect
else
    echo "ðŸ³ Skipping hardware sensor detection in Docker mode"
fi

echo "===== 8. Configuring selected security components ====="

if [ "$INSTALL_CLAMAV" = true ]; then
    echo "===== 8.1 Configuring ClamAV with resource optimization ====="
    # Optimize ClamAV for production server environment with resource awareness
    # This prevents ClamAV from consuming excessive CPU/memory that could impact applications

    if [ "$DOCKER_MODE" = "false" ]; then
    # Stop services during configuration (only in non-Docker mode)
    systemctl stop clamav-daemon clamav-freshclam 2>/dev/null || true

    # Configure ClamAV daemon with resource-conscious settings
    cat > /etc/clamav/clamd.conf << 'EOF'
# ClamAV Daemon Configuration - Optimized for Production Servers
User clamav
LocalSocket /run/clamav/clamd.ctl
FixStaleSocket true
LocalSocketGroup clamav
LocalSocketMode 666

# Resource-balanced configuration for application servers
MaxThreads 2
MaxConnectionQueueLength 10
MaxQueue 100

# Optimize scanning performance vs resources
ReadTimeout 180
CommandReadTimeout 60
SendBufTimeout 200

# File size and scanning limits - balanced for application servers
MaxScanSize 100M
MaxFileSize 25M
MaxRecursion 10
MaxFiles 10000
MaxPartitions 50
MaxIconsPE 100

# Scan behavior - comprehensive security vs performance
ScanPE true
ScanELF true
ScanOLE2 true
ScanPDF true
ScanHTML true
ScanArchive true
ArchiveBlockEncrypted false
MaxDirectoryRecursion 15

# Memory and timeout optimizations
PCREMatchLimit 10000
PCRERecMatchLimit 5000
PCREMaxFileSize 25M
MaxScanTime 120000

# Logging - standard for production
LogFile /var/log/clamav/clamav.log
LogTime true
LogClean false
LogSyslog false
LogRotate true
LogVerbose false

# Network and detection settings
SelfCheck 3600
DatabaseDirectory /var/lib/clamav
OfficialDatabaseOnly false
Foreground false
Debug false

# Production detection settings
IdleTimeout 30
ExitOnOOM true
LeaveTemporaryFiles false
DetectPUA false
CrossFilesystems true

# Heuristic settings - balanced approach
AlgorithmicDetection true
Bytecode true
BytecodeSecurity TrustSigned
BytecodeTimeout 60000

# Enhanced detection for production servers
PhishingSignatures true
PhishingAlwaysBlockSSLMismatch false
PhishingAlwaysBlockCloak false
HeuristicScanPrecedence false
StructuredDataDetection false
ScanPartialMessages false
OLE2BlockMacros false
EOF

    # Configure freshclam with reduced frequency for production servers
    cat > /etc/clamav/freshclam.conf << 'EOF'
# ClamAV Freshclam Configuration - Optimized for Production Servers
DatabaseOwner clamav

# Moderate update frequency - 4 times daily for production balance
Checks 4

# Database mirrors and sources
DatabaseMirror db.us.clamav.net
DatabaseMirror db.local.clamav.net

# Logging
UpdateLogFile /var/log/clamav/freshclam.log
LogVerbose false
LogSyslog false
LogTime true
LogRotate true

# Download behavior - balanced for production
MaxAttempts 3
ConnectTimeout 60
ReceiveTimeout 60

# Notify clamd of updates
NotifyClamd /etc/clamav/clamd.conf

# Test database before loading
TestDatabases yes

# Bytecode updates
Bytecode true
EOF

    # Create systemd resource limits for ClamAV services
    echo "Setting up systemd resource limits for ClamAV services..."

    # ClamAV daemon resource limits for production servers
    mkdir -p /etc/systemd/system/clamav-daemon.service.d
    cat > /etc/systemd/system/clamav-daemon.service.d/resource-limits.conf << 'EOF'
[Service]
# Proper memory limits for ClamAV daemon (minimum 1GB required)
CPUQuota=40%
MemoryMax=1536M
MemoryHigh=1200M

# Process priority and I/O scheduling
Nice=10
IOSchedulingClass=2
IOSchedulingPriority=4

# Smart restart behavior with longer delays
Restart=on-failure
RestartSec=60
StartLimitInterval=1200
StartLimitBurst=2

# Watchdog configuration for production workloads
WatchdogSec=300

# OOM handling - kill ClamAV rather than other services
OOMPolicy=kill
OOMScoreAdjust=100

# Security isolation
PrivateTmp=true
ProtectSystem=strict
ProtectHome=true
NoNewPrivileges=true
ReadWritePaths=/var/lib/clamav /var/log/clamav /run/clamav

# Prevent memory fragmentation issues
TasksMax=50

# OOM handling - controlled termination
OOMPolicy=kill
OOMScoreAdjust=300

# Security and resource isolation
PrivateTmp=true
ProtectSystem=strict
ProtectHome=true
NoNewPrivileges=true
ReadWritePaths=/var/lib/clamav /var/log/clamav /run/clamav
EOF

    # Freshclam resource limits for production servers
    mkdir -p /etc/systemd/system/clamav-freshclam.service.d
    cat > /etc/systemd/system/clamav-freshclam.service.d/resource-limits.conf << 'EOF'
[Service]
# Proper memory limits for virus definition updates (minimum 768MB required)
CPUQuota=20%
MemoryMax=1024M
MemoryHigh=768M

# Process priority
Nice=15
IOSchedulingClass=2

# Restart behavior
Restart=on-failure
RestartSec=120
StartLimitInterval=1800
StartLimitBurst=2

# OOM handling
OOMPolicy=kill
OOMScoreAdjust=200

# Security isolation
PrivateTmp=true
ProtectSystem=strict
ProtectHome=true
NoNewPrivileges=true
ReadWritePaths=/var/lib/clamav /var/log/clamav

# Prevent resource conflicts during updates
TasksMax=20
EOF

    # Create log directory with proper permissions
    mkdir -p /var/log/clamav
    chown clamav:clamav /var/log/clamav
    chmod 755 /var/log/clamav

    # Set up logrotate for ClamAV logs
    cat > /etc/logrotate.d/clamav << 'EOF'
/var/log/clamav/*.log {
    weekly
    rotate 12
    compress
    delaycompress
    missingok
    notifempty
    create 644 clamav clamav
    postrotate
        systemctl reload clamav-daemon > /dev/null 2>&1 || true
    endscript
}
EOF

    # Reload systemd and start services with new configurations
    systemctl daemon-reload

    echo "âœ… ClamAV configured with resource allocation for production environment"
    echo "   â€¢ CPU limited to 40% (daemon) / 20% (updater)"
    echo "   â€¢ Memory INCREASED to 1536MB (daemon) / 1024MB (updater)"
    echo "   â€¢ Update frequency: 4x daily (production balance)"
    echo "   â€¢ Optimized scan limits and timeouts"
    echo "   â€¢ Enhanced security isolation and OOM protection"
fi

# Enable and start ClamAV services
create_rollback_point "clamav-config"
enable_and_start_service clamav-freshclam
enable_and_start_service clamav-daemon

if [ "$DOCKER_MODE" = "false" ]; then
    echo ""
    echo "ðŸ“‹ ClamAV Management Commands:"
    echo "   â€¢ Check status: systemctl status clamav-daemon clamav-freshclam"
    echo "   â€¢ View logs: journalctl -u clamav-daemon -f"
    echo "   â€¢ Manual scan: clamscan -r /path/to/scan"
    echo "   â€¢ Monitor resources: systemctl show clamav-daemon --property=CPUUsageNSec,MemoryCurrent"
fi
else
    echo "â­ï¸ ClamAV antivirus not selected - skipping configuration"
fi

if [ "$INSTALL_MALDET" = true ]; then
    # Install Linux Malware Detect (maldet) - enhanced malware protection
    echo "===== 8.2 Installing Linux Malware Detect (maldet) ====="
    # Create temporary directory for installation
    mkdir -p /tmp/maldet
    cd /tmp/maldet

# Download the latest version
wget https://www.rfxn.com/downloads/maldetect-current.tar.gz

# Extract and install
tar -xzf maldetect-current.tar.gz
MALDET_DIR=$(tar -tzf maldetect-current.tar.gz | head -1 | cut -f1 -d"/")
cd "$MALDET_DIR"
./install.sh

# Configure maldet with secure settings
cat > /usr/local/maldetect/conf.maldet << EOC
# Linux Malware Detect v1.6.x
# Configuration File

# Enable Email Alerting (1 = enabled, 0 = disabled)
email_alert="1"

# Email Address in which you want to receive scan reports and alerts
# Separate multiple email addresses with a space: "user@domain.com user2@domain.com"
email_addr="${LOGWATCH_EMAIL:-root}"

# Use with ClamAV (1 = enabled, 0 = disabled)
clamav_scan="1"

# Quarantine malicious files (1 = enabled, 0 = disabled)
quarantine_hits="1"

# Clean/Delete malicious files (1 = enabled, 0 = disabled)
quarantine_clean="0"

# Clean/Delete suspicious files (1 = enabled, 0 = disabled)
quarantine_suspend_user="0"

# Minimum userid value that can be suspended
quarantine_suspend_user_minuid="500"

# Enable Email Alerting for all scan users (1 = enabled, 0 = disabled)
email_subj="[MALWARE] ${HOSTNAME}: Linux Malware Detection on \\\${domain_count} domains"

# Use path names relative to a domain for cleaner reports
email_ignore_clean="1"

# Allow clean/delete operation to use signatures with HEX string matches below this value
quar_hex_min_suspect="70"

# The default find command to use, use of 'xargs' is required
# for 'find -exec' to queue and optimize processing of find matches
find_cmd="find \\\${scan_location} -type f -not -path '/proc/*' -not -path '/sys/*' -print0 | xargs -0 -P 10 -n 100"

# The default basis for determining file system ownership of a file
# should always be the username:group of the file/directory
file_owner_lookup="1"

# Size limit on files being scanned (in KB)
max_filesize="10240"

# When using the -r scan operation to scan root directory & user paths, the max directory depth
# that will be scanned, beyond that will be ignored.
maxdepth="15"

# The maximum amount of file download attempts that will be made before giving up
url_max_dl="3"

# The curl command line that handles all remote file transfers,
# adjust timeout and max-time to meet connectivity requirements.
curl_timeout="30"
curl_max_time="60"

# The maximum number of child processes that maldet should fork to handle scan operations,
# by default we fork one scan thread per available CPU.
scan_max_process="5"

# The maximum number of process operations that maldet should fork per signature in hex scan operations,
# limit this to 2 to reduce CPU load at expense of scan speed.
scan_max_process_hex="2"

# Additional paths for daily cron scan
scan_paths="/home /opt/polyserver /var/www"

# Do not scan mounts/paths defined here
scan_ignore_paths="/proc /sys /dev"

# Total CPU usage threshold (percentage) at which scanning will be suspended until usage drops
scan_cpumax="75"

# Allow maldet to download and install updated signatures from rfxn.com
autoupdate="1"

# Daily automatic updates of malware signatures
autoupdate_signatures="1"

# Daily automatic updates of maldet
autoupdate_version="1"

# When defined, the update process will source this external file from
# rfxn.com following the update if it exists. This is used to deploy
# critical configuration settings to all installations.
autoupdate_version_hashed="1"

# Run weekly cronjob at specific day and time
cron_weekly_day="2"  # 0 = Sunday, 1 = Monday, 2 = Tuesday, etc.
cron_weekly_hour="3" # Hour in 24h format
cron_daily_hour="3"  # Hour in 24h format
EOC

# Create maldet daily scan script with notifications
cat > /etc/cron.daily/maldet-scan << 'EOF'
#!/bin/bash
# Daily maldet scan script

# Log file
LOGFILE="/var/log/maldet/daily_scan.log"

# Make sure log directory exists
mkdir -p /var/log/maldet

# Start the log
echo "Linux Malware Detect daily scan started at $(date)" > $LOGFILE

# Run scan on important directories
/usr/local/sbin/maldet --scan-all /home /opt/polyserver /var/www >> $LOGFILE 2>&1

# Finish log
echo "Linux Malware Detect daily scan completed at $(date)" >> $LOGFILE

# Check for detections
if grep -q "malware hits" $LOGFILE; then
    HITS=$(grep "malware hits" $LOGFILE | grep -o '[0-9]\+')
    if [ "$HITS" -gt 0 ]; then
        # Send email alert if malware found
        cat $LOGFILE | mail -s "âš ï¸ MALWARE WARNING: $HITS malware hits found on $(hostname)" "${LOGWATCH_EMAIL:-root}"
    fi
fi
EOF

# Make scan script executable
chmod 755 /etc/cron.daily/maldet-scan

# Force initial maldet signature update
/usr/local/sbin/maldet --update-sigs

    # Clean up
    cd /
    rm -rf /tmp/maldet
fi

# Create daily scan script
cat > /etc/cron.daily/clamscan << 'EOF'
#!/bin/bash
LOGFILE="/var/log/clamav/daily_scan.log"
DIRTOSCAN="/home /opt/polyserver /var/www"

# Create log directory if it doesn't exist
mkdir -p /var/log/clamav

# Remove old logfile
rm -f $LOGFILE

# Start scanning
echo "ClamAV daily scan started at $(date)" >> $LOGFILE
clamscan -r -i $DIRTOSCAN >> $LOGFILE
echo "ClamAV daily scan completed at $(date)" >> $LOGFILE

# Send notification if viruses were found
if grep -q "Infected files: [1-9]" $LOGFILE; then
    VIRUS_COUNT=$(grep "Infected files:" $LOGFILE | cut -d: -f2 | tr -d ' ')
    echo "WARNING - $VIRUS_COUNT VIRUS(ES) FOUND ON $(hostname)" | mail -s "VIRUS ALERT on $(hostname)" "${LOGWATCH_EMAIL:-root}"
fi
EOF
chmod 755 /etc/cron.daily/clamscan

# Configure Logcheck
echo "===== 9. Configuring Logcheck ====="
# Set logcheck to use server level
sed -i 's/^REPORTLEVEL=.*/REPORTLEVEL="server"/' /etc/logcheck/logcheck.conf

# Set logcheck email recipient (same as logwatch)
sed -i "s/^SENDMAILTO=.*/SENDMAILTO=\"${LOGWATCH_EMAIL:-root}\"/" /etc/logcheck/logcheck.conf

# Set running frequency to daily (default is hourly)
sed -i 's/^CRON_DAILY_RUN=.*/CRON_DAILY_RUN="true"/' /etc/logcheck/logcheck.conf
sed -i 's/^CRON_HOURLY_RUN=.*/CRON_HOURLY_RUN="false"/' /etc/logcheck/logcheck.conf

# Remove hourly logcheck cron job if it exists
rm -f /etc/cron.hourly/logcheck 2>/dev/null || true
rm -f /etc/cron.d/logcheck 2>/dev/null || true

# Add ignore patterns for common application server activity
log_message "Adding logcheck ignore patterns for UFW and common server activity..."
cat >> /etc/logcheck/ignore.d.server/application-server-ignore << EOF
# Application server specific ignore patterns
# Ignore normal server activity patterns that are not security issues

# Normal SSH connection patterns
^\w{3} [ :0-9]{11} [._[:alnum:]-]+ sshd\[[0-9]+\]: Connection from [.[:digit:]]+ port [0-9]+ on [.[:digit:]]+ port [0-9]+$
^\w{3} [ :0-9]{11} [._[:alnum:]-]+ sshd\[[0-9]+\]: Accepted publickey for [[:alnum:]]+ from [.[:digit:]]+ port [0-9]+ ssh2: [[:alnum:][:space:]]+$
^\w{3} [ :0-9]{11} [._[:alnum:]-]+ sshd\[[0-9]+\]: pam_unix\(sshd:session\): session opened for user [[:alnum:]]+ by \(uid=[0-9]+\)$
^\w{3} [ :0-9]{11} [._[:alnum:]-]+ sshd\[[0-9]+\]: pam_unix\(sshd:session\): session closed for user [[:alnum:]]+$

# UFW firewall blocks - support both syslog and ISO 8601 formats
^\w{3} [ :0-9]{11} [._[:alnum:]-]+ kernel: \[UFW [[:upper:]]+\].*$
^[0-9]{4}-[0-9]{2}-[0-9]{2}T[0-9]{2}:[0-9]{2}:[0-9]{2}\.[0-9]+[+-][0-9]{4} [._[:alnum:]-]+ kernel: \[[0-9.]+\] \[UFW [[:upper:]]+\].*$

# Normal cron activity
^\w{3} [ :0-9]{11} [._[:alnum:]-]+ \/USR\/SBIN\/CRON\[[0-9]+\]: \([[:alnum:]]+\) CMD \(.*\)$
^\w{3} [ :0-9]{11} [._[:alnum:]-]+ cron\[[0-9]+\]: \([[:alnum:]]+\) CMD \(.*\)$

# Normal systemd activity
^\w{3} [ :0-9]{11} [._[:alnum:]-]+ systemd\[[0-9]+\]: .*\.service: Succeeded\.$
^\w{3} [ :0-9]{11} [._[:alnum:]-]+ systemd\[[0-9]+\]: Started .*\.$

# Normal postfix activity (for notifications) - support both formats
^\w{3} [ :0-9]{11} [._[:alnum:]-]+ postfix/smtp\[[0-9]+\]: [A-F0-9]+: to=<.*>, relay=.*$
^\w{3} [ :0-9]{11} [._[:alnum:]-]+ postfix/cleanup\[[0-9]+\]: [A-F0-9]+: message-id=<.*>$
^\w{3} [ :0-9]{11} [._[:alnum:]-]+ postfix/qmgr\[[0-9]+\]: [A-F0-9]+: from=<.*>, size=[0-9]+, nrcpt=[0-9]+.*$
^\w{3} [ :0-9]{11} [._[:alnum:]-]+ postfix\/.*\[[0-9]+\]: [A-F0-9]+: .*$
^[0-9]{4}-[0-9]{2}-[0-9]{2}T[0-9]{2}:[0-9]{2}:[0-9]{2}\.[0-9]+[+-][0-9]{4} [._[:alnum:]-]+ postfix\/.*\[[0-9]+\]: [A-F0-9]+: .*$

# Suricata normal operations and restarts (if enabled)
^[0-9]{4}-[0-9]{2}-[0-9]{2}T[0-9]{2}:[0-9]{2}:[0-9]{2}\.[0-9]+[+-][0-9]{4} [._[:alnum:]-]+ suricata\[[0-9]+\]: [0-9]{1,2}\/[0-9]{1,2}\/[0-9]{4} -- [0-9]{2}:[0-9]{2}:[0-9]{2} - <.*> - .*$
^[0-9]{4}-[0-9]{2}-[0-9]{2}T[0-9]{2}:[0-9]{2}:[0-9]{2}\.[0-9]+[+-][0-9]{4} [._[:alnum:]-]+ systemd\[[0-9]+\]: suricata\.service: .*$
^[0-9]{4}-[0-9]{2}-[0-9]{2}T[0-9]{2}:[0-9]{2}:[0-9]{2}\.[0-9]+[+-][0-9]{4} [._[:alnum:]-]+ suricatasc\[[0-9]+\]: Unable to connect to socket .*$
^[0-9]{4}-[0-9]{2}-[0-9]{2}T[0-9]{2}:[0-9]{2}:[0-9]{2}\.[0-9]+[+-][0-9]{4} [._[:alnum:]-]+ kernel: \[[0-9.]+\] device ens[0-9]+ (entered|left) promiscuous mode$

# Normal security tool operations
^[0-9]{4}-[0-9]{2}-[0-9]{2}T[0-9]{2}:[0-9]{2}:[0-9]{2}\.[0-9]+[+-][0-9]{4} [._[:alnum:]-]+ chkrootkit-daily\[[0-9]+\]: sending alert to root: .*$
^[0-9]{4}-[0-9]{2}-[0-9]{2}T[0-9]{2}:[0-9]{2}:[0-9]{2}\.[0-9]+[+-][0-9]{4} [._[:alnum:]-]+ maldet: .*$
^[0-9]{4}-[0-9]{2}-[0-9]{2}T[0-9]{2}:[0-9]{2}:[0-9]{2}\.[0-9]+[+-][0-9]{4} [._[:alnum:]-]+ root: (Security configuration backup completed|Suricata rules updated successfully): .*$

# SSH connection attempts and failures (expected on internet-facing servers)
^[0-9]{4}-[0-9]{2}-[0-9]{2}T[0-9]{2}:[0-9]{2}:[0-9]{2}\.[0-9]+[+-][0-9]{4} [._[:alnum:]-]+ sshd\[[0-9]+\]: (error: |Unable to negotiate with|Connection closed by|banner exchange:).*$

# Kernel packet filtering messages
^[0-9]{4}-[0-9]{2}-[0-9]{2}T[0-9]{2}:[0-9]{2}:[0-9]{2}\.[0-9]+[+-][0-9]{4} [._[:alnum:]-]+ kernel: \[[0-9.]+\] af_packet: .*$

# Normal PHP-FPM activity (if using PHP)
^\w{3} [ :0-9]{11} [._[:alnum:]-]+ php-fpm\[[0-9]+\]: .*pool [[:alnum:]]+.*$

# Normal nginx activity
^\w{3} [ :0-9]{11} [._[:alnum:]-]+ nginx\[[0-9]+\]: .*$

# Normal Docker activity (if using Docker)
^\w{3} [ :0-9]{11} [._[:alnum:]-]+ dockerd\[[0-9]+\]: .*$
^\w{3} [ :0-9]{11} [._[:alnum:]-]+ containerd\[[0-9]+\]: .*$

EOF

log_message "âœ… Logcheck configured with application server ignore patterns"

# Configure and initialize AIDE (Advanced Intrusion Detection Environment)
if [ "$DOCKER_MODE" = "false" ]; then
    echo "Configuring AIDE for file integrity monitoring..."
    
    # Configure AIDE to run properly with mail functionality
    cat > /etc/default/aide << 'EOF'
# Configuration for AIDE
# Run AIDE checks as root to enable mail functionality
AIDE_USER="root"

# Mail configuration
MAILTO="root"
MAILSUBJECT="AIDE integrity check for $HOSTNAME"

# Quiet mode - don't output unless there are changes
QUIETREPORTS="yes"

# Skip the database check if the database doesn't exist yet
COPYNEWDB="no"
EOF

    # Create custom AIDE check script that handles mail properly
    cat > /usr/local/bin/aide-check << 'EOF'
#!/bin/bash
# Custom AIDE check script with proper mail handling

# Log file for AIDE output
AIDE_LOG="/var/log/aide/aide-check.log"
mkdir -p /var/log/aide

# Run AIDE check and capture output
echo "AIDE integrity check started at $(date)" > $AIDE_LOG
echo "=====================================" >> $AIDE_LOG

# Run AIDE check with proper error handling
if aide --config=/etc/aide/aide.conf --check 2>&1 | tee -a $AIDE_LOG; then
    # AIDE completed successfully
    echo "AIDE check completed at $(date)" >> $AIDE_LOG
    
    # Check if there were any changes detected
    if grep -q "found differences" $AIDE_LOG || grep -q "File.*changed" $AIDE_LOG; then
        # Changes detected - send alert email
        cat $AIDE_LOG | mail -s "âš ï¸ AIDE ALERT: File integrity changes detected on $HOSTNAME" root
    else
        # No changes - log success
        echo "No integrity violations detected" >> $AIDE_LOG
    fi
else
    # AIDE failed
    echo "AIDE check failed at $(date)" >> $AIDE_LOG
    echo "AIDE integrity check failed on $HOSTNAME" | mail -s "ðŸš¨ AIDE ERROR: Check failed on $HOSTNAME" root
    exit 1
fi

# Rotate old logs
find /var/log/aide -name "aide-check.log.*" -mtime +30 -delete
if [ -f $AIDE_LOG ] && [ $(stat -c%s $AIDE_LOG) -gt 10485760 ]; then
    # Rotate if log is larger than 10MB
    mv $AIDE_LOG ${AIDE_LOG}.$(date +%Y%m%d)
    gzip ${AIDE_LOG}.$(date +%Y%m%d)
fi
EOF

    chmod 755 /usr/local/bin/aide-check

    # Override the default AIDE systemd service to use our custom script
    mkdir -p /etc/systemd/system/dailyaidecheck.service.d
    cat > /etc/systemd/system/dailyaidecheck.service.d/override.conf << 'EOF'
[Service]
# Override to use our custom AIDE check script
ExecStart=
ExecStart=/usr/local/bin/aide-check

# Ensure proper user and environment
User=root
Group=root

# Resource limits to prevent AIDE from overwhelming system
CPUQuota=25%
MemoryMax=512M
Nice=15
IOSchedulingClass=3

# Proper logging
StandardOutput=journal
StandardError=journal
EOF

    systemctl daemon-reload

    echo "Initializing AIDE database - this will take some time..."
    nice -n 19 aideinit
    
    echo "âœ… AIDE configured with proper mail functionality"
else
    echo "ðŸ³ Skipping AIDE initialization in Docker mode"
fi

# Configure Audit Framework (auditd)
echo "===== 10.1 Configuring Audit Framework ====="
# Configure audit daemon
cat > /etc/audit/auditd.conf << EOF
#
# This file controls the configuration of the audit daemon
#

local_events = yes
write_logs = yes
log_file = /var/log/audit/audit.log
log_group = adm
log_format = ENRICHED
flush = INCREMENTAL_ASYNC
freq = 50
max_log_file = 8
num_logs = 5
priority_boost = 4
name_format = HOSTNAME
##name = mydomain
max_log_file_action = ROTATE
space_left = 75
space_left_action = SYSLOG
verify_email = yes
action_mail_acct = ${LOGWATCH_EMAIL:-root}
admin_space_left = 50
admin_space_left_action = SUSPEND
disk_full_action = SUSPEND
disk_error_action = SUSPEND
use_libwrap = yes
##tcp_listen_port = 60
tcp_listen_queue = 5
tcp_max_per_addr = 1
##tcp_client_ports = 1024-65535
tcp_client_max_idle = 0
enable_krb5 = no
krb5_principal = auditd
##krb5_key_file = /etc/audit/audit.key
distribute_network = no
EOF

# Configure audit rules
cat > /etc/audit/rules.d/audit.rules << 'EOF'
## auditd rules for enhanced security monitoring

## First rule - delete all
-D

## Increase the buffers to survive stress events
## Adjust buffer size based on system activity
-b 8192

## This determines how long to wait in burst of events
--backlog_wait_time 0

## Set failure mode to syslog
-f 1

# DNS lookup monitoring
-w /etc/resolv.conf -p r -k dns_lookup
-a always,exit -F arch=b64 -S connect -F a1=0x2 -F key=dns_lookup
-a always,exit -F arch=b64 -S connect -F a1=0xA -F key=dns_lookup
-a always,exit -F arch=b64 -S sendto -F a1=0x2 -F key=dns_lookup
-a always,exit -F arch=b64 -S sendto -F a1=0xA -F key=dns_lookup
-a always,exit -F arch=b64 -S execve -F exe=/usr/bin/dig -F key=dns_lookup
-a always,exit -F arch=b64 -S execve -F exe=/usr/bin/nslookup -F key=dns_lookup
-a always,exit -F arch=b64 -S execve -F exe=/usr/bin/getent -F key=dns_lookup

## File System monitoring
-w /etc/fstab -p wa -k filesystem_modifications
-w /etc/group -p wa -k user_group_modifications
-w /etc/shadow -p wa -k password_modifications
-w /etc/security/opasswd -p wa -k password_modifications
-w /etc/sudoers -p wa -k sudoers_modifications
-w /etc/sudoers.d -p wa -k sudoers_modifications

## Login monitoring
-w /var/log/faillog -p wa -k login_failures
-w /var/log/lastlog -p wa -k login_activity
-w /var/run/faillock -p wa -k login_failures

## Process and system activity
-w /sbin/insmod -p x -k module_insertion
-w /sbin/rmmod -p x -k module_removal
-w /sbin/modprobe -p x -k module_insertion
-a always,exit -F arch=b64 -S mount -k mount_operations
-a always,exit -F arch=b32 -S mount -k mount_operations

## System startup scripts
-w /etc/init.d -p wa -k init_modifications
-w /etc/systemd -p wa -k systemd_modifications

## SSH configuration
-w /etc/ssh/sshd_config -p wa -k sshd_config_modifications
-w /etc/ssh/sshd_config.d -p wa -k sshd_config_modifications

## Network configuration
-w /etc/hosts -p wa -k hosts_file_modifications
-w /etc/network/interfaces -p wa -k network_modifications

## Web server (nginx)
-w /etc/nginx/nginx.conf -p wa -k nginx_config
-w /etc/nginx/conf.d -p wa -k nginx_config

## Docker configuration monitoring
-w /etc/docker/daemon.json -p wa -k docker_config
-w /etc/docker -p wa -k docker_config

## Application directories monitoring
-w /opt/polyserver/config -p wa -k application_config_changes
-w /opt/polyserver/scripts -p x -k application_script_execution

## Critical command executions
-a always,exit -F path=/usr/bin/curl -F perm=x -F key=data_exfiltration
-a always,exit -F path=/usr/bin/wget -F perm=x -F key=data_exfiltration
-a always,exit -F path=/usr/bin/base64 -F perm=x -F key=data_exfiltration
-a always,exit -F path=/bin/nc -F perm=x -F key=data_exfiltration
-a always,exit -F path=/bin/netcat -F perm=x -F key=data_exfiltration
-a always,exit -F path=/usr/bin/ssh -F perm=x -F key=outbound_ssh
-a always,exit -F path=/usr/bin/scp -F perm=x -F key=data_exfiltration
# -a always,exit -F path=/usr/bin/sftp -F perm=x -F key=data_exfiltration  # SFTP disabled

## AppArmor (Debian's default MAC system)
-w /etc/apparmor -p wa -k apparmor_modifications
-w /etc/apparmor.d -p wa -k apparmor_modifications

## Cron jobs
-w /etc/cron.allow -p wa -k cron_modifications
-w /etc/cron.deny -p wa -k cron_modifications
-w /etc/cron.d -p wa -k cron_modifications
-w /etc/cron.daily -p wa -k cron_modifications
-w /etc/cron.hourly -p wa -k cron_modifications
-w /etc/cron.monthly -p wa -k cron_modifications
-w /etc/cron.weekly -p wa -k cron_modifications
-w /etc/crontab -p wa -k cron_modifications

## Security tools configuration
-w /usr/local/maldetect/conf.maldet -p wa -k security_tool_config
-w /etc/rkhunter.conf -p wa -k security_tool_config
-w /etc/default/clamav-daemon -p wa -k security_tool_config
-w /etc/clamav/clamd.conf -p wa -k security_tool_config

# User modifications monitoring
-w /etc/passwd -p wa -k user_modify

# Time change monitoring
-a always,exit -F arch=b64 -S clock_settime -F key=changetime
-a always,exit -F arch=b32 -S clock_settime -F key=changetime

## Monitor Docker socket for access
-w /var/run/docker.sock -p rwa -k docker_socket_access

## Monitor for privilege escalation
-a always,exit -F arch=b64 -S setuid -S setgid -F exit=0 -k privilege_escalation
-a always,exit -F arch=b32 -S setuid -S setgid -F exit=0 -k privilege_escalation

## Detect unauthorized attempts to access restricted directories
-a always,exit -F dir=/root -F perm=r -F auid>=1000 -F key=unauthorized_access
-a always,exit -F dir=/etc/ssl/private -F perm=r -F auid>=1000 -F key=unauthorized_access

## Detect changes to backup scripts
-w /mnt/backup/backups -p wa -k backup_changes

## File integrity for binaries (limited to critical ones to reduce noise)
-w /usr/bin/sudo -p wa -k binary_modifications
-w /usr/bin/docker -p wa -k binary_modifications
-w /usr/bin/ssh -p wa -k binary_modifications
-w /usr/bin/nginx -p wa -k binary_modifications
-w /usr/bin/maldet -p wa -k binary_modifications

## Detect attempts to alter logs
-w /var/log -p wa -k log_tampering

## Make the configuration immutable until next reboot (uncomment if needed)
## WARNING: You will need to reboot to make changes after enabling this option
#-e 2
EOF

# Create daily audit report script
cat > /etc/cron.daily/audit-report << 'EOF'
#!/bin/bash
# Daily audit report script

# Set variables
DATE=$(date +%Y-%m-%d)
REPORT_DIR="/var/log/audit/reports"
LOG_FILE="/var/log/audit/audit.log"
MAIL_RECIPIENT="${LOGWATCH_EMAIL:-root}"
HOSTNAME=$(hostname)

# Create report directory if it doesn't exist
mkdir -p $REPORT_DIR

# Generate report filename
REPORT_FILE="${REPORT_DIR}/audit-report-${DATE}.txt"

# Start report
echo "===============================================================" > $REPORT_FILE
echo "Audit Report for $HOSTNAME on $DATE" >> $REPORT_FILE
echo "===============================================================" >> $REPORT_FILE
echo "" >> $REPORT_FILE

# System Summary
echo "SYSTEM SUMMARY" >> $REPORT_FILE
echo "===============" >> $REPORT_FILE
uname -a >> $REPORT_FILE
echo "" >> $REPORT_FILE
echo "Uptime: $(uptime)" >> $REPORT_FILE
echo "" >> $REPORT_FILE

# General Summary Report
echo "GENERAL SUMMARY" >> $REPORT_FILE
echo "===============" >> $REPORT_FILE
ausearch --start today --end now | aureport --summary -i >> $REPORT_FILE
echo "" >> $REPORT_FILE

# Authentication Report
echo "AUTHENTICATION EVENTS" >> $REPORT_FILE
echo "====================" >> $REPORT_FILE
ausearch --start today --end now | aureport --auth --summary -i >> $REPORT_FILE
echo "" >> $REPORT_FILE

# User Modification Events
echo "USER MODIFICATION EVENTS" >> $REPORT_FILE
echo "=======================" >> $REPORT_FILE
ausearch -k user_modify --start today --end now -i >> $REPORT_FILE
echo "" >> $REPORT_FILE

# Executable Summary
echo "EXECUTABLE SUMMARY" >> $REPORT_FILE
echo "=================" >> $REPORT_FILE
ausearch --start today --end now | aureport --executable --summary -i >> $REPORT_FILE
echo "" >> $REPORT_FILE

# Suspicious Command Executions
echo "SUSPICIOUS COMMAND EXECUTIONS" >> $REPORT_FILE
echo "============================" >> $REPORT_FILE
ausearch -k data_exfiltration --start today --end now -i >> $REPORT_FILE
echo "" >> $REPORT_FILE

# File Modification Events
echo "CONFIG FILE MODIFICATION EVENTS" >> $REPORT_FILE
echo "=============================" >> $REPORT_FILE
ausearch -k sshd_config_modifications --start today --end now -i >> $REPORT_FILE
ausearch -k nginx_config --start today --end now -i >> $REPORT_FILE
ausearch -k docker_config --start today --end now -i >> $REPORT_FILE
ausearch -k application_config_changes --start today --end now -i >> $REPORT_FILE
ausearch -k security_tool_config --start today --end now -i >> $REPORT_FILE
echo "" >> $REPORT_FILE

# Privilege Escalation
echo "PRIVILEGE ESCALATION EVENTS" >> $REPORT_FILE
echo "=========================" >> $REPORT_FILE
ausearch -k privilege_escalation --start today --end now -i >> $REPORT_FILE
echo "" >> $REPORT_FILE

# Unauthorized Access Attempts
echo "UNAUTHORIZED ACCESS ATTEMPTS" >> $REPORT_FILE
echo "==========================" >> $REPORT_FILE
ausearch -k unauthorized_access --start today --end now -i >> $REPORT_FILE
echo "" >> $REPORT_FILE

# Binary Modifications
echo "BINARY MODIFICATION EVENTS" >> $REPORT_FILE
echo "=========================" >> $REPORT_FILE
ausearch -k binary_modifications --start today --end now -i >> $REPORT_FILE
echo "" >> $REPORT_FILE

# Docker Socket Access
echo "DOCKER SOCKET ACCESS" >> $REPORT_FILE
echo "===================" >> $REPORT_FILE
ausearch -k docker_socket_access --start today --end now -i >> $REPORT_FILE
echo "" >> $REPORT_FILE

# Audit System Status
echo "AUDIT SYSTEM STATUS" >> $REPORT_FILE
echo "==================" >> $REPORT_FILE
auditctl -s >> $REPORT_FILE
echo "" >> $REPORT_FILE
auditctl -l >> $REPORT_FILE
echo "" >> $REPORT_FILE

# Check for empty report (only headings) and add note if so
if [ $(grep -v "^$\|^=\|^[A-Z]" $REPORT_FILE | wc -l) -eq 0 ]; then
    echo "No significant audit events recorded for this period." >> $REPORT_FILE
fi

# Email report if there are significant events
if grep -q "type=\|command=\|success=\|.*=yes\|modified\|executed" $REPORT_FILE; then
    cat $REPORT_FILE | mail -s "Audit Report for $HOSTNAME - $DATE" $MAIL_RECIPIENT
fi

# Cleanup old reports (keep 30 days)
find $REPORT_DIR -name "audit-report-*.txt" -mtime +30 -delete

exit 0
EOF

chmod 750 /etc/cron.daily/audit-report

# Configure auditd systemd resource limits
echo "===== 9.1.1 Configuring Auditd Resource Management ====="
mkdir -p /etc/systemd/system/auditd.service.d
cat > /etc/systemd/system/auditd.service.d/resource-limits.conf << 'EOF'
[Service]
# Resource limits to prevent auditd from overwhelming system
CPUQuota=20%
MemoryMax=256M
MemoryHigh=200M
Nice=0
IOSchedulingClass=1
IOSchedulingPriority=4
OOMPolicy=continue
OOMScoreAdjust=-100

# Security and isolation (limited for auditd requirements)
NoNewPrivileges=true
ProtectHome=true
ReadWritePaths=/var/log/audit /etc/audit

# Restart policy for audit reliability
Restart=always
RestartSec=60
TimeoutStartSec=60
TimeoutStopSec=30

# Watchdog configuration
WatchdogSec=120
NotifyAccess=main
EOF

systemctl daemon-reload

# Enable and start auditd
docker_systemctl enable auditd
docker_systemctl restart auditd

# Initial audit test
if [ "$DOCKER_MODE" = "false" ]; then
    echo "Testing audit system..."
    auditctl -l
else
    echo "ðŸ³ Skipping audit system test in Docker mode"
fi

# Create audit log rotation configuration
cat > /etc/logrotate.d/auditd << EOF
/var/log/audit/audit.log {
    rotate 10
    weekly
    size 50M
    compress
    delaycompress
    missingok
    notifempty
    postrotate
        docker_systemctl reload auditd > /dev/null 2>&1 || true
    endscript
}
EOF

# Configure ModSecurity WAF
echo "===== 10.2 Configuring ModSecurity Web Application Firewall ====="
if [ "$DOCKER_MODE" = "false" ]; then
    # Install libmodsecurity3 for Debian
    apt-get install -y libmodsecurity3 libmodsecurity-dev

    # Enable ModSecurity in Nginx
    mkdir -p /etc/nginx/modsec
    cat > /etc/nginx/modsec/main.conf << EOF
# Include the recommended configuration
Include /etc/nginx/modsec/modsecurity.conf

# Include OWASP Core Rule Set (CRS)
Include /etc/nginx/modsec/owasp-crs/crs-setup.conf
Include /etc/nginx/modsec/owasp-crs/rules/*.conf
EOF

    # Download OWASP CRS
    mkdir -p /etc/nginx/modsec/owasp-crs
    rm -rf /etc/nginx/modsec/owasp-crs
    git clone https://github.com/coreruleset/coreruleset.git /etc/nginx/modsec/owasp-crs
    cp /etc/nginx/modsec/owasp-crs/crs-setup.conf.example /etc/nginx/modsec/owasp-crs/crs-setup.conf

    # Create application-agnostic ModSecurity configuration
    cat > /etc/nginx/modsec/modsecurity.conf << EOF
# ModSecurity configuration for PolyServer applications

# -- Rule engine initialization ----------------------------------------------
SecRuleEngine On

# -- Request body handling ---------------------------------------------------
SecRequestBodyAccess On
SecRequestBodyLimit 13107200
SecRequestBodyNoFilesLimit 131072
SecRequestBodyInMemoryLimit 131072

# Buffer response bodies
SecResponseBodyAccess On
SecResponseBodyMimeType text/plain text/html text/xml application/json
SecResponseBodyLimit 1048576

# -- Filesystem configuration ------------------------------------------------
SecTmpDir /tmp/
SecDataDir /tmp/

# -- Audit log configuration -------------------------------------------------
SecAuditEngine RelevantOnly
SecAuditLogRelevantStatus "^(?:5|4(?!04))"
SecAuditLogParts ABIJDEFHZ
SecAuditLogType Serial
SecAuditLog /var/log/nginx/modsec_audit.log

# -- Debug log configuration -------------------------------------------------
SecDebugLog /var/log/nginx/modsec_debug.log
SecDebugLogLevel 1

# -- Application specific exceptions ----------------------------------------
# Add custom rules here for your specific applications
# Examples:
# SecRule REQUEST_URI "@beginsWith /api/" "id:1000,phase:1,pass,nolog,ctl:ruleRemoveById=942100"
# SecRule REQUEST_URI "@beginsWith /admin/" "id:1001,phase:1,pass,nolog,ctl:ruleRemoveById=942100"
EOF

    # Configure Nginx to use ModSecurity
    cat > /etc/nginx/conf.d/modsecurity.conf << EOF
modsecurity on;
modsecurity_rules_file /etc/nginx/modsec/main.conf;
EOF
else
    echo "ðŸ³ Skipping ModSecurity configuration in Docker mode (module not available)"
fi

# Install comprehensive nginx security configuration
echo "===== 10.2.1 Installing Nginx Security Configuration ====="

# Create security configuration for blocking common attacks
cat > /etc/nginx/conf.d/security.conf << 'EOF'
# Nginx Security Configuration for PolyServer Applications
# This file contains security rules to block common attacks and sensitive file access

# Hide nginx version information
server_tokens off;

# Block access to sensitive files and directories
location ~ /\. {
    # Block access to hidden files (.git, .env, .htaccess, etc.)
    access_log off;
    log_not_found off;
    deny all;
}

location ~ ^/(\.well-known/acme-challenge/)(.*)$ {
    # Allow Let's Encrypt ACME challenge (exception to hidden files rule)
    allow all;
}

# Block access to common sensitive files
location ~* \.(env|git|gitignore|gitmodules|htaccess|htpasswd|ini|log|sh|sql|conf|config|bak|backup|swp|tmp)$ {
    access_log off;
    log_not_found off;
    deny all;
}

# Block access to README and documentation files
location ~* ^/(readme|README|changelog|CHANGELOG|license|LICENSE|install|INSTALL|upgrade|UPGRADE|todo|TODO).*$ {
    access_log off;
    log_not_found off;
    deny all;
}

# Block access to common admin paths (application-agnostic protection)
location ~* ^/(admin|administrator|wp-admin|wp-login|wp-config|wp-content|wp-includes|wp-json|xmlrpc|phpmyadmin|pma|mysql|adminer|cpanel|plesk|webmail|roundcube|squirrelmail)(.*)$ {
    access_log off;
    log_not_found off;
    return 444; # Close connection without response
}

# Block access to common CMS and framework paths
location ~* ^/(drupal|joomla|wordpress|magento|prestashop|opencart|typo3|concrete5|modx|craft|laravel|symfony|codeigniter|cakephp|zend|yii)(.*)$ {
    access_log off;
    log_not_found off;
    return 444;
}

# Block access to common development/testing paths
location ~* ^/(test|tests|testing|dev|development|staging|demo|backup|backups|old|new|temp|tmp|cache|logs|vendor|node_modules|bower_components)(.*)$ {
    access_log off;
    log_not_found off;
    return 444;
}

# Block access to common exploit paths
location ~* ^/(shell|webshell|c99|c100|r57|r99|backdoor|hack|hacked|exploit|virus|trojan|worm|bot|zombie|scanner|scan|probe|brute|force|attack)(.*)$ {
    access_log off;
    log_not_found off;
    return 444;
}

# Block requests for non-existent scripts that are commonly probed
location ~* \.(asp|aspx|jsp|cgi|pl|py|rb|php|php3|php4|php5|phtml|shtml)$ {
    access_log off;
    log_not_found off;
    return 444;
}

# Block common vulnerability scanners and bad user agents
if ($http_user_agent ~* (nikto|sqlmap|fimap|nessus|openvas|nmap|masscan|zmap|zap|burp|netsparker|acunetix|appscan|webscarab|w3af|skipfish|wapiti|whatweb|gobuster|dirb|dirbuster|ffuf|feroxbuster|nuclei|httpx|subfinder)) {
    access_log off;
    return 444;
}

# Block empty user agents and common bot patterns
if ($http_user_agent ~ ^$) {
    access_log off;
    return 444;
}

# Block suspicious referrers
if ($http_referer ~* (babes|click|diamond|forsale|girl|jewelry|love|nudit|organic|poker|porn|sex|teen|video|webcam|zippo)) {
    access_log off;
    return 444;
}

# Block requests with suspicious query strings
if ($args ~* (\.\./|<script|GLOBALS|globals|javascript:|vbscript:|onload|onerror|onclick)) {
    access_log off;
    return 444;
}

# Block SQL injection attempts in query strings
if ($args ~* (union|select|insert|delete|update|drop|create|alter|exec|execute|script|javascript|vbscript)) {
    access_log off;
    return 444;
}
EOF

# Create proxy parameters file for reusable proxy settings
cat > /etc/nginx/conf.d/proxy_params << 'EOF'
# Common proxy parameters for applications
# This file contains reusable proxy settings

# Timeout settings
proxy_connect_timeout 90s;
proxy_send_timeout 240s;
proxy_read_timeout 240s;

# Use HTTP/1.1 for proxying
proxy_http_version 1.1;

# Enable WebSockets support
proxy_set_header Upgrade $http_upgrade;
proxy_set_header Connection "upgrade";

# Pass important headers for proper operation
proxy_set_header Host $http_host;
proxy_set_header X-Real-IP $remote_addr;
proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
proxy_set_header X-Forwarded-Proto $scheme;
proxy_set_header X-Forwarded-Host $http_host;
proxy_set_header X-Forwarded-Port $server_port;

# Performance optimizations
proxy_buffering off;
proxy_request_buffering off;
proxy_cache_bypass $http_upgrade;
proxy_redirect off;

# Security settings
proxy_hide_header X-Powered-By;
proxy_hide_header Server;
EOF

# Set proper permissions
chmod 644 /etc/nginx/conf.d/security.conf
chmod 644 /etc/nginx/conf.d/proxy_params

echo "Nginx security configuration installed"

# Configure AppArmor for applications
echo "===== 10.3 Setting up AppArmor for applications ====="
echo "AppArmor profile templates are available in /etc/apparmor.d/"
echo "Customize application-specific profiles as needed for your deployments"

# Configure Suricata IDS
echo "===== 10.4 Setting up Suricata Network IDS ====="
if [ "$DOCKER_MODE" = "false" ]; then
    # Configure network interface
    INTERFACE=$(ip -o -4 route show to default | awk '{print $5}')

    # Interactive service configuration for Suricata monitoring
    echo "ðŸ“‹ Configuring Suricata network variables based on services..."
    echo "This helps Suricata know which services to monitor and reduces false positives."
    echo ""
    
    # Service detection and configuration
    # shellcheck disable=SC2016
    HTTP_SERVERS='$HOME_NET'
    # shellcheck disable=SC2016
    SQL_SERVERS='$HOME_NET'
    # shellcheck disable=SC2016
    DNS_SERVERS='$HOME_NET'
    # shellcheck disable=SC2016
    MAIL_SERVERS='$HOME_NET'
    # shellcheck disable=SC2016
    FTP_SERVERS='$HOME_NET'
    
    if [ "$TESTING_MODE" != "true" ]; then
        echo "Will you be running web services (nginx, apache, etc.) on this server? [Y/n]"
        read -r web_services
        if [[ $web_services =~ ^[Nn]$ ]]; then
            HTTP_SERVERS="any"
            echo "  ðŸ“Œ HTTP monitoring set to external traffic only"
        else
            echo "  ðŸ“Œ HTTP monitoring enabled for this server"
        fi
        
        echo ""
        echo "Will you be running database services (MySQL, PostgreSQL, etc.) on this server? [Y/n]"
        read -r db_services
        if [[ $db_services =~ ^[Nn]$ ]]; then
            SQL_SERVERS="any"
            echo "  ðŸ“Œ Database monitoring set to external traffic only"
        else
            echo "  ðŸ“Œ Database monitoring enabled for this server"
        fi
        
        echo ""
        echo "Will you be running DNS services on this server? [y/N]"
        read -r dns_services
        if [[ $dns_services =~ ^[Yy]$ ]]; then
            echo "  ðŸ“Œ DNS monitoring enabled for this server"
        else
            DNS_SERVERS="any"
            echo "  ðŸ“Œ DNS monitoring set to external traffic only"
        fi
        
        echo ""
        echo "Will you be running mail services on this server? [y/N]"
        read -r mail_services
        if [[ $mail_services =~ ^[Yy]$ ]]; then
            echo "  ðŸ“Œ Mail monitoring enabled for this server"
        else
            MAIL_SERVERS="any"
            echo "  ðŸ“Œ Mail monitoring set to external traffic only"
        fi
        
        echo ""
        echo "Will you be running FTP services on this server? [y/N]"
        read -r ftp_services
        if [[ $ftp_services =~ ^[Yy]$ ]]; then
            echo "  ðŸ“Œ FTP monitoring enabled for this server"
        else
            FTP_SERVERS="any"
            echo "  ðŸ“Œ FTP monitoring set to external traffic only"
        fi
    else
        echo "  ðŸ“Œ Testing mode: Using default service configurations"
    fi
    
    echo ""
    echo "âœ… Service configuration complete. Generating Suricata config..."

    # Basic Suricata configuration 
    cat > /etc/suricata/suricata.yaml << EOF
%YAML 1.1
---
# Suricata configuration for PolyServer applications
vars:
  address-groups:
    HOME_NET: "[192.168.0.0/16,10.0.0.0/8,172.16.0.0/12]"
    EXTERNAL_NET: "!$HOME_NET"
    HTTP_SERVERS: "$HTTP_SERVERS"
    SQL_SERVERS: "$SQL_SERVERS"
    DNS_SERVERS: "$DNS_SERVERS"
    MAIL_SERVERS: "$MAIL_SERVERS"
    FTP_SERVERS: "$FTP_SERVERS"
    
  port-groups:
    HTTP_PORTS: "80"
    HTTPS_PORTS: "443"
    SSH_PORTS: "22"
    DNS_PORTS: "53"
    DB_PORTS: "3306,5432,1521,1433,27017"
    MAIL_PORTS: "25,465,587,993,995"
    FTP_PORTS: "21,990"
    
default-rule-path: /etc/suricata/rules
rule-files:
  - suricata.rules
  - application-custom.rules

af-packet:
  - interface: $INTERFACE
    cluster-id: 99
    cluster-type: cluster_flow
    defrag: yes
    use-mmap: yes
    tpacket-v3: yes
    
# Enable basic alerts
detect-engine:
  profile: medium
  sgh-mpm-context: auto
  inspection-recursion-limit: 3000

# App layer protocol configuration
app-layer:
  protocols:
    # Essential protocols for production applications
    http:
      enabled: yes
    tls:
      enabled: yes
    ssh:
      enabled: yes
    dns:
      enabled: yes
    smtp:
      enabled: yes
    ftp:
      enabled: yes
    http2:
      enabled: yes
    
    # Database and enterprise protocols (might be needed)
    smb:
      enabled: yes
    nfs:
      enabled: yes
    
    # Disable industrial/IoT protocols not needed for web applications
    dcerpc:
      enabled: no
    modbus:
      enabled: no
    enip:
      enabled: no
    dnp3:
      enabled: no
    ntp:
      enabled: no
    tftp:
      enabled: no
    ikev2:
      enabled: no
    krb5:
      enabled: no
    dhcp:
      enabled: no
    snmp:
      enabled: no
    sip:
      enabled: no
    rfb:
      enabled: no
    mqtt:
      enabled: no
    rdp:
      enabled: no
  
# Log configuration
outputs:
  - fast:
      enabled: yes
      filename: fast.log
      
  - eve-log:
      enabled: yes
      filetype: regular
      filename: eve.json
      types:
        - alert
        - http
        - dns
        - tls
        - flow
EOF

# Create custom rules template for applications
cat > /etc/suricata/rules/application-custom.rules << EOF
# Custom application-specific rules
# Add your application-specific Suricata rules here

# Example: Alert on potential SQL injection attempts
# alert http \$EXTERNAL_NET any -> \$HOME_NET any (msg:"APP SQL Injection Attempt"; flow:established,to_server; http.uri; content:"/api/"; nocase; pcre:"/(\%27)|(\')|(\-\-)|(%23)|(#)/i"; classtype:web-application-attack; sid:3000001; rev:1;)

# Example: Alert on brute force attempts 
# alert http \$EXTERNAL_NET any -> \$HOME_NET any (msg:"APP Authentication Brute Force Attempt"; flow:established,to_server; http.uri; content:"/login"; threshold:type threshold, track by_src, count 5, seconds 60; classtype:attempted-admin; sid:3000002; rev:1;)
EOF

# Set up Suricata log rotation
cat > /etc/logrotate.d/suricata << 'EOF'
/var/log/suricata/*.log /var/log/suricata/*.json {
    daily
    size 100M
    rotate 7
    compress
    delaycompress
    missingok
    notifempty
    create 0640 root adm
    postrotate
        /bin/kill -USR2 $(cat /var/run/suricata.pid 2>/dev/null) 2>/dev/null || systemctl reload suricata 2>/dev/null || true
    endscript
}
EOF

# Install Trivy for container scanning
curl -sfL https://raw.githubusercontent.com/aquasecurity/trivy/main/contrib/install.sh | sh -s -- -b /usr/local/bin

# Create directory for security logs
mkdir -p /var/log/security/trivy

# Create cron job for daily container scanning
cat > /etc/cron.daily/trivy-scan << 'EOF'
#!/bin/bash
# Daily container vulnerability scanning

REPORT_DIR="/var/log/security/trivy"
DATE=$(date +%Y-%m-%d)
MAIL_RECIPIENT="${LOGWATCH_EMAIL:-root}"
HOSTNAME=$(hostname)
TRIVYLOG="${REPORT_DIR}/trivy-${DATE}.log"

# Create report directory if it doesn't exist
mkdir -p $REPORT_DIR

# Update Trivy vulnerability database
/usr/local/bin/trivy image --download-db-only > /dev/null 2>&1

# Start log file
echo "===== Container Vulnerability Scan Report: $DATE =====" > $TRIVYLOG

# Scan running containers
CONTAINERS=$(docker ps --format "{{.Image}}")
for IMAGE in $CONTAINERS; do
    echo "Scanning image: $IMAGE" >> $TRIVYLOG
    /usr/local/bin/trivy image --no-progress --severity HIGH,CRITICAL $IMAGE >> $TRIVYLOG
    echo "-----------------------------------------" >> $TRIVYLOG
done

# Email report if vulnerabilities found
if grep -q "CRITICAL\|HIGH" $TRIVYLOG; then
    cat $TRIVYLOG | mail -s "âš ï¸ CONTAINER VULNERABILITIES: Found on $HOSTNAME" $MAIL_RECIPIENT
fi

# Cleanup old reports
find $REPORT_DIR -name "trivy-*.log" -mtime +30 -delete
EOF

chmod 755 /etc/cron.daily/trivy-scan

    # Configure Suricata systemd resource limits
    echo "===== 10.4.1 Configuring Suricata Resource Management ====="
    mkdir -p /etc/systemd/system/suricata.service.d
    cat > /etc/systemd/system/suricata.service.d/resource-limits.conf << EOF
[Service]
# Override ExecStart to specify the correct network interface
ExecStart=
ExecStart=/usr/bin/suricata -D --af-packet=$INTERFACE -c /etc/suricata/suricata.yaml --pidfile /run/suricata.pid

# Resource limits to prevent Suricata from overwhelming system
CPUQuota=50%
MemoryMax=1G
MemoryHigh=800M
Nice=5
IOSchedulingClass=2
IOSchedulingPriority=4
OOMPolicy=kill
OOMScoreAdjust=200

# Security and isolation (minimal for IDS functionality)
PrivateTmp=false
NoNewPrivileges=false
ProtectHome=false
ProtectSystem=false

# Restart policy for network IDS reliability
Restart=always
RestartSec=60
TimeoutStartSec=120
TimeoutStopSec=30

# Watchdog configuration
WatchdogSec=300
NotifyAccess=main
EOF

    systemctl daemon-reload

    # Enable and start Suricata
    systemctl enable suricata
    systemctl start suricata
else
    echo "ðŸ³ Skipping Suricata configuration in Docker mode"
fi

# Configure Logwatch
echo "===== 10. Configuring Logwatch ====="

# Configure rsyslog with traditional timestamp format for logwatch compatibility
if ! grep -q "RSYSLOG_TraditionalFileFormat" /etc/rsyslog.conf; then
    cp /etc/rsyslog.conf /etc/rsyslog.conf.backup
    # shellcheck disable=SC2016
    sed -i '1i$ActionFileDefaultTemplate RSYSLOG_TraditionalFileFormat' /etc/rsyslog.conf
    systemctl restart rsyslog
    echo "âœ… Configured rsyslog to use traditional timestamp format"
fi

mkdir -p /var/cache/logwatch

# Create Logwatch configuration
cat > /etc/logwatch/conf/logwatch.conf << EOF
# Logwatch Configuration
Output = mail
MailTo = ${LOGWATCH_EMAIL:-root}
Format = html
Range = yesterday
Detail = High
Show_Empty_Sections = yes

# Disable the default Service = All to avoid conflicts
Service =

# Use specific services instead of All to avoid configuration conflicts
Service = zz-sys         # System Configuration
Service = sshd           # SSH login attempts and success/fail
Service = secure         # PAM messages, login denials
Service = sudo           # Use of sudo, privilege escalations
Service = audit          # If auditd is active
Service = fail2ban       # Banned IPs (if you're using it)
Service = pam_unix       # Pluggable authentication messages
Service = cron           # Scheduled job activity
Service = dpkg           # Package installs/removals (Debian/Ubuntu)
Service = systemd        # System boot/service issues
Service = kernel         # Kernel messages (OOM, panics, etc.)
Service = postfix        # Mail logs (if you use local mail for cron/system)
Service = sendmail       # Might be triggered by postfix wrapper
Service = iptables       # Firewall logs (if you log dropped packets)
Service = zz-lm_sensors  # Hardware Sensors
Service = zz-network     # Network Interface
Service = zz-disk_space  # Disk usage overview
Service = clamav         # Virus scan results
Service = clam-update    # Virus scan updates
EOF

# Create enhanced postfix/sendmail service configuration for detailed reporting
mkdir -p /etc/logwatch/conf/services
mkdir -p /etc/logwatch/conf/logfiles

# Create journalctl-based service configurations for systemd services
cat > /etc/logwatch/conf/services/postfix.conf << EOF
# Enhanced Postfix reporting for servers using journalctl
Title = "Mail System (Postfix/Sendmail)"
Logfile =
Logfile = none
*JournalCtl = "--unit='postfix' --unit='postfix@-'"
*RemoveHeaders = Yes
Detail = High
EOF

# Create custom sendmail/postfix logwatch script for server-specific analysis
mkdir -p /etc/logwatch/scripts/services
cat > /etc/logwatch/scripts/services/postfix << 'EOF'
#!/usr/bin/perl
# Enhanced Postfix/Sendmail analysis for servers
# Focuses on security-relevant email events

use strict;
use warnings;

my %sent_count = ();
my %received_count = ();
my %rejected_count = ();
my %bounced_count = ();
my %smtp_stats = ();
my %security_events = ();
my %relay_attempts = ();
my @critical_events = ();

while (my $line = <STDIN>) {
    chomp $line;
    
    # Skip lines that don't contain postfix/sendmail
    next unless $line =~ /(postfix|sendmail)/;
    
    # Extract timestamp
    my ($timestamp) = $line =~ /^(\w+\s+\d+\s+\d+:\d+:\d+)/;
    
    # Count sent messages
    if ($line =~ /status=sent/) {
        $sent_count{total}++;
        if ($line =~ /relay=([^,\s]+)/) {
            $sent_count{$1}++;
        }
    }
    
    # Count received messages
    elsif ($line =~ /status=deferred|status=bounced/) {
        $bounced_count{total}++;
        if ($line =~ /(Connection refused|timeout|Host not found)/i) {
            $bounced_count{$1}++;
        }
    }
    
    # Track SMTP security events
    elsif ($line =~ /(SASL|TLS|SSL)/) {
        if ($line =~ /SASL.*authentication failed/i) {
            $security_events{"SASL Authentication Failed"}++;
            push @critical_events, "$timestamp: SASL auth failure";
        }
        elsif ($line =~ /(TLS|SSL).*established/i) {
            $smtp_stats{"TLS Connections"}++;
        }
        elsif ($line =~ /Anonymous TLS connection established/i) {
            $smtp_stats{"Anonymous TLS"}++;
        }
    }
    
    # Track relay attempts (security concern)
    elsif ($line =~ /Relay access denied/i) {
        $security_events{"Unauthorized Relay Attempts"}++;
        if ($line =~ /from=<([^>]*)>.*to=<([^>]*)>/) {
            push @critical_events, "$timestamp: Relay attempt from $1 to $2";
        }
    }
    
    # Track connection rejections
    elsif ($line =~ /(reject|blocked|denied)/i) {
        $rejected_count{total}++;
        if ($line =~ /Client host rejected/i) {
            $rejected_count{"Host Rejection"}++;
        }
        elsif ($line =~ /Sender address rejected/i) {
            $rejected_count{"Sender Rejection"}++;
        }
    }
    
    # Track postfix warnings and errors
    elsif ($line =~ /(warning|error|fatal)/i) {
        if ($line =~ /warning.*SASL/i) {
            $security_events{"SASL Warnings"}++;
        }
        elsif ($line =~ /error.*timeout/i) {
            $smtp_stats{"Timeout Errors"}++;
        }
    }
    
    # Track queue statistics
    elsif ($line =~ /postfix\/qmgr.*removed/) {
        $smtp_stats{"Messages Processed"}++;
    }
}

# Generate report
print "\n";
print "=" x 60 . "\n";
print "SERVER MAIL SYSTEM REPORT\n";
print "=" x 60 . "\n\n";

# Mail delivery statistics
if (keys %sent_count || keys %bounced_count) {
    print "ðŸ“§ MAIL DELIVERY STATISTICS:\n";
    print "-" x 30 . "\n";
    
    if ($sent_count{total}) {
        print "âœ… Successfully sent: $sent_count{total} messages\n";
        foreach my $relay (sort keys %sent_count) {
            next if $relay eq 'total';
            print "   â†’ via $relay: $sent_count{$relay}\n";
        }
    }
    
    if ($bounced_count{total}) {
        print "âš ï¸  Bounced/Deferred: $bounced_count{total} messages\n";
        foreach my $reason (sort keys %bounced_count) {
            next if $reason eq 'total';
            print "   â†’ $reason: $bounced_count{$reason}\n";
        }
    }
    
    if ($rejected_count{total}) {
        print "ðŸš« Rejected: $rejected_count{total} messages\n";
        foreach my $reason (sort keys %rejected_count) {
            next if $reason eq 'total';
            print "   â†’ $reason: $rejected_count{$reason}\n";
        }
    }
    print "\n";
}

# SMTP/TLS statistics
if (keys %smtp_stats) {
    print "ðŸ” SMTP/TLS STATISTICS:\n";
    print "-" x 25 . "\n";
    foreach my $stat (sort keys %smtp_stats) {
        print "â€¢ $stat: $smtp_stats{$stat}\n";
    }
    print "\n";
}

# Security events (important for servers)
if (keys %security_events) {
    print "ðŸš¨ SECURITY EVENTS:\n";
    print "-" x 20 . "\n";
    foreach my $event (sort keys %security_events) {
        my $count = $security_events{$event};
        my $indicator = $count > 5 ? "âš ï¸ " : "â€¢ ";
        print "$indicator$event: $count\n";
    }
    print "\n";
}

# Critical events detail
if (@critical_events) {
    print "ðŸ” CRITICAL EVENT DETAILS:\n";
    print "-" x 28 . "\n";
    foreach my $event (@critical_events) {
        print "â€¢ $event\n";
    }
    print "\n";
}

# Recommendations for servers
if ($security_events{"Unauthorized Relay Attempts"} > 0) {
    print "âš ï¸  SECURITY RECOMMENDATIONS:\n";
    print "-" x 32 . "\n";
    print "â€¢ Review relay restrictions in postfix configuration\n";
    print "â€¢ Consider implementing stricter sender verification\n";
    print "â€¢ Monitor source IPs for relay attempts\n\n";
}

if (!$smtp_stats{"TLS Connections"} && $sent_count{total}) {
    print "âš ï¸  TLS RECOMMENDATIONS:\n";
    print "-" x 23 . "\n";
    print "â€¢ Consider enforcing TLS for all SMTP connections\n";
    print "â€¢ Review SMTP authentication security\n\n";
}

print "ðŸ“‹ For detailed logs, check: /var/log/mail.log\n";
print "ðŸ”§ Mail queue status: mailq\n";
print "ðŸ“Š Postfix configuration: postconf -n\n\n";
EOF

chmod +x /etc/logwatch/scripts/services/postfix

# Create logwatch cron job - use only cron.d for precise timing
# Remove any existing daily cron to prevent duplicates
rm -f /etc/cron.daily/00logwatch

# Configure logwatch to run once daily at 6:00 AM
cat > /etc/cron.d/logwatch << EOF
# Daily logwatch execution for server
# Run at 6:00 AM daily to analyze previous day's logs
0 6 * * * root /usr/sbin/logwatch --output mail --format html --range yesterday --detail high
EOF

# Create custom service for lm_sensors
mkdir -p /etc/logwatch/scripts/services
cat > /etc/logwatch/scripts/services/zz-lm_sensors << 'EOF'
#!/bin/bash
echo "Hardware Sensor Information:"
echo ""
sensors | grep -v "Adapter:" | grep -v "^$" | sed -e 's/^/   /'
echo ""
echo "Disk Temperature:"
echo ""
hddtemp /dev/sd? 2>/dev/null | sed -e 's/^/   /' || echo "   No disk temperature data available"
EOF
chmod 755 /etc/logwatch/scripts/services/zz-lm_sensors

# Create service definition
mkdir -p /etc/logwatch/conf/services
cat > /etc/logwatch/conf/services/zz-lm_sensors.conf << EOF
# Logwatch configuration file for lm_sensors

Title = "Hardware Sensors"
EOF

# Configure RKHunter
echo "===== 10. Configuring RKHunter ====="
if [ "$DOCKER_MODE" = "false" ]; then
    # Update rkhunter database
    rkhunter --update

    # Set up RKHunter properties
    cat > /etc/rkhunter.conf.local << EOF
# RKHunter configuration overrides

# Update database on a daily basis
UPDATE_MIRRORS=1
MIRRORS_MODE=0
UPDATE_MIRRORS=1
WEB_CMD="DISABLED"

# Mail options - same email as logwatch
MAIL-ON-WARNING=${LOGWATCH_EMAIL:-root}
COPY_LOG_ON_ERROR=1

# Scan options
SCAN_DEV_DIR=1
SCAN_WORLD_WRITABLE=1
ALLOW_SSH_ROOT_USER=no
XINETD_ALLOWED_SVC=
DISABLE_CHECK_PORTS=0

# Allow certain whitelisted files
#ALLOWHIDDENDIR=/dev/.udev
#ALLOWHIDDENFILE=/dev/.blkid.tab
EOF

# Create RKHunter scan script
cat > /etc/cron.daily/rkhunter-scan << 'EOF'
#!/bin/bash
# Run a daily RKHunter scan

# Log file
LOGFILE="/var/log/rkhunter/daily_scan.log"

# Create log directory if it doesn't exist
mkdir -p /var/log/rkhunter

# Clear previous log
echo "RKHunter daily scan started at $(date)" > $LOGFILE

# Run the scan
rkhunter --check --skip-keypress --report-warnings-only >> $LOGFILE 2>&1

# Add completion time
echo "RKHunter daily scan completed at $(date)" >> $LOGFILE

# Check for warnings and alert if found
if grep -q "Warning:" $LOGFILE; then
    WARNING_COUNT=$(grep -c "Warning:" $LOGFILE)
    ADMIN_EMAIL=$(grep "^MAIL-ON-WARNING=" /etc/rkhunter.conf.local | cut -d= -f2)
    # If no email is set, use root
    if [ -z "$ADMIN_EMAIL" ]; then
        ADMIN_EMAIL="root"
    fi
    
    # Send email alert
    cat $LOGFILE | mail -s "âš ï¸ ROOTKIT WARNING: ${WARNING_COUNT} suspicious items found on $(hostname)" "$ADMIN_EMAIL"
fi
EOF
chmod 755 /etc/cron.daily/rkhunter-scan

    # Run initial scan to establish baseline
    echo "Running initial RKHunter scan to create baseline..."
    rkhunter --propupd
    rkhunter --check --skip-keypress --report-warnings-only
else
    echo "ðŸ³ Skipping RKHunter configuration in Docker mode"
fi

# Configure chkrootkit daily scan
cat > /etc/cron.daily/chkrootkit-scan << 'EOF'
#!/bin/bash
# Run a daily chkrootkit scan

# Log file
LOGFILE="/var/log/chkrootkit/daily_scan.log"

# Create log directory if it doesn't exist
mkdir -p /var/log/chkrootkit

# Clear previous log
echo "chkrootkit daily scan started at $(date)" > $LOGFILE

# Run the scan
chkrootkit -q >> $LOGFILE 2>&1

# Add completion time
echo "chkrootkit daily scan completed at $(date)" >> $LOGFILE

# Check for warnings and alert if found (chkrootkit outputs "INFECTED" when it finds something)
if grep -q "INFECTED" $LOGFILE; then
    ADMIN_EMAIL=$(grep "^MAIL-ON-WARNING=" /etc/rkhunter.conf.local | cut -d= -f2)
    # If no email is set, use root
    if [ -z "$ADMIN_EMAIL" ]; then
        ADMIN_EMAIL="root"
    fi
    
    # Send email alert
    cat $LOGFILE | mail -s "âš ï¸ ROOTKIT WARNING: Possible rootkit found on $(hostname)" "$ADMIN_EMAIL"
fi
EOF
chmod 755 /etc/cron.daily/chkrootkit-scan

# ========= Block Storage Setup =========
echo "===== 7. Setting up block storage for backups ====="
if [ -e "$BLOCK_DEVICE" ]; then
  mkdir -p $BACKUP_MOUNT
  
  # Check if the device is already formatted
  if ! blkid $BLOCK_DEVICE &>/dev/null; then
    echo "Formatting block storage device"
    mkfs.ext4 $BLOCK_DEVICE
  fi
  
  # Add to fstab for auto-mounting
  if ! grep -q "$BACKUP_MOUNT" /etc/fstab; then
    echo "$BLOCK_DEVICE $BACKUP_MOUNT ext4 defaults,noatime 0 2" >> /etc/fstab
  fi
  
  # Mount the device
  mount $BACKUP_MOUNT || true
  
  # Create backup directories
  mkdir -p $BACKUP_MOUNT/backups
  chmod 750 $BACKUP_MOUNT/backups
fi

# ========= Docker Installation =========
# Check if we need Docker (deployment mode is "docker" or just always install for flexibility)
if [ "$DEPLOYMENT_MODE" = "docker" ] || [ "$DOCKER_MODE" = "false" ]; then
    echo "===== 8. Installing Docker and Docker Compose ====="
    echo "Installing Docker for deployment mode: $DEPLOYMENT_MODE"
    
    apt-get install -y apt-transport-https ca-certificates curl software-properties-common gnupg lsb-release

    # Add Docker repository for Debian
    curl -fsSL https://download.docker.com/linux/debian/gpg | gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg
    echo "deb [arch=amd64 signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/debian $(lsb_release -cs) stable" | tee /etc/apt/sources.list.d/docker.list > /dev/null
    apt-get update
    apt-get install -y docker-ce docker-ce-cli containerd.io docker-compose-plugin

    # Start Docker
    docker_systemctl enable docker
    docker_systemctl start docker

    # Add user to Docker group
    usermod -aG docker $USERNAME

    # Docker security hardening
    cat > /etc/docker/daemon.json << EOF
{
  "log-driver": "json-file",
  "log-opts": {
    "max-size": "10m",
    "max-file": "3"
  },
  "live-restore": true,
  "userland-proxy": false,
  "no-new-privileges": true,
  "icc": false
}
EOF

    docker_systemctl restart docker
    
    if [ "$DEPLOYMENT_MODE" = "docker" ]; then
        echo "Docker mode: Container orchestration ready for applications"
        
        # Create Docker networks for applications
        docker network create polyserver-network 2>/dev/null || echo "Network polyserver-network already exists"
        
        # Create directories for Docker-managed volumes
        mkdir -p /opt/polyserver/docker/{volumes,compose}
        chown -R $USERNAME:$USERNAME /opt/polyserver/docker
    fi
else
    echo "ðŸ³ Skipping Docker installation (testing mode)"
fi

# ========= Install Netdata Monitoring =========
echo "===== 8.1 Installing Netdata monitoring ====="
if [ "$DOCKER_MODE" = "false" ] && [ "$NETDATA_ENABLED" = "true" ]; then
    echo "Installing Netdata monitoring agent..."
    
    # Download and run the official installer
    echo "Downloading Netdata installer..."
    if curl -o /tmp/netdata-kickstart.sh https://get.netdata.cloud/kickstart.sh; then
        echo "Running Netdata installation..."
        
        # Check if claim token is provided via template variables
        NETDATA_CLAIM_TOKEN="{{NETDATA_CLAIM_TOKEN}}"
        NETDATA_CLAIM_ROOMS="{{NETDATA_CLAIM_ROOMS}}"
        
        if [ -n "$NETDATA_CLAIM_TOKEN" ] && [ "$NETDATA_CLAIM_TOKEN" != "{{NETDATA_CLAIM_TOKEN}}" ]; then
            echo "Installing with Netdata Cloud integration (from configuration)..."
            sh /tmp/netdata-kickstart.sh --stable-channel --disable-telemetry --claim-token "$NETDATA_CLAIM_TOKEN" --claim-rooms "$NETDATA_CLAIM_ROOMS"
        else
            echo "Installing without Netdata Cloud (local monitoring only)..."
            sh /tmp/netdata-kickstart.sh --stable-channel --disable-telemetry --dont-wait
        fi
        
        # Clean up installer
        rm -f /tmp/netdata-kickstart.sh
    else
        echo "âš ï¸ Failed to download Netdata installer, trying fallback method..."
        
        # Fallback: install via package manager
        if command -v apt-get >/dev/null 2>&1; then
            apt-get update
            apt-get install -y netdata
        else
            echo "âŒ Failed to install Netdata - please install manually"
            echo "   Visit: https://learn.netdata.cloud/docs/installing/one-line-installer-for-all-linux-systems"
            NETDATA_ENABLED="false"
        fi
    fi
    
    # Check if Netdata was successfully installed
    if ! command -v netdata >/dev/null 2>&1 && ! systemctl is-active --quiet netdata; then
        echo "âŒ Netdata installation verification failed"
        NETDATA_ENABLED="false"
    fi
fi

if [ "$DOCKER_MODE" = "false" ] && [ "$NETDATA_ENABLED" = "true" ] && [ "$NETDATA_ENABLED" != "false" ]; then
    # Configure Netdata for secure server monitoring
    echo "Configuring Netdata for secure server monitoring..."
    
    # Create minimal security-focused configuration
    cat > /etc/netdata/netdata.conf << 'EOF'
[global]
    # SECURITY: Bind to localhost only (access via SSH tunnel or Nginx proxy)
    bind socket to IP = 127.0.0.1
    default port = 19999
    
    # Performance optimized for server
    page cache size = 32
    dbengine multihost disk space = 128
    
[web]
    # No authentication needed since localhost-only
    web files owner = root
    web files group = netdata
    
EOF

    # Enable and start Netdata
    docker_systemctl enable netdata
    docker_systemctl restart netdata

    # Wait for Netdata to start
    sleep 3

    # Optional Netdata Cloud Integration (show instructions if not configured)
    NETDATA_CLAIM_TOKEN="{{NETDATA_CLAIM_TOKEN}}"
    NETDATA_CLAIM_ROOMS="{{NETDATA_CLAIM_ROOMS}}"
    
    if [ -z "$NETDATA_CLAIM_TOKEN" ] || [ "$NETDATA_CLAIM_TOKEN" = "{{NETDATA_CLAIM_TOKEN}}" ]; then
        echo ""
        echo "ðŸ“Š NETDATA CLOUD INTEGRATION (Optional)"
        echo "======================================"
        echo "To add this server to Netdata Cloud for centralized monitoring:"
        echo ""
        echo "1. Sign up/login at: https://app.netdata.cloud"
        echo "2. Create a new space or select existing space"
        echo "3. Go to 'Connect Nodes' and copy your claim token"
        echo "4. Run the following command on this server:"
        echo ""
        echo "   sudo /opt/netdata/bin/netdata-claim.sh \\"
        echo "     -token=YOUR_CLAIM_TOKEN \\"
        echo "     -rooms=YOUR_ROOM_ID \\"
        echo "     -url=https://app.netdata.cloud"
        echo ""
        echo "5. Your server will appear in Netdata Cloud within 1-2 minutes"
        echo ""
        echo "ðŸ“ To set up automatic claiming, add these to your .env file:"
        echo "   NETDATA_CLAIM_TOKEN=your_claim_token"
        echo "   NETDATA_CLAIM_ROOMS=your_room_id"
        echo ""
    else
        echo "âœ… Netdata Cloud integration configured from template variables"
        echo "   â€¢ Server should appear in your Netdata Cloud dashboard within a few minutes"
        echo "   â€¢ Login at: https://app.netdata.cloud"
    fi

    # Create Netdata log rotation
    cat > /etc/logrotate.d/netdata << 'EOF'
/var/log/netdata/*.log {
    daily
    rotate 14
    missingok
    notifempty
    compress
    delaycompress
    postrotate
        systemctl reload netdata > /dev/null 2>&1 || true
    endscript
}
EOF

    # Create access script for easy local access
    cat > /usr/local/bin/netdata-access << 'EOF'
#!/bin/bash
# Quick access to local Netdata dashboard
echo "ðŸŒ Opening Netdata dashboard..."
echo "   Local URL: http://127.0.0.1:19999"
echo "   SSH Tunnel: ssh -L 19999:127.0.0.1:19999 user@server"
echo "   Netdata Cloud: https://app.netdata.cloud"
EOF
    chmod +x /usr/local/bin/netdata-access

    echo "âœ… Netdata monitoring installed and configured"
    echo "   â€¢ Local access: http://127.0.0.1:19999 (via SSH tunnel)"
    echo "   â€¢ Quick access command: netdata-access"
elif [ "$DOCKER_MODE" = "false" ] && [ "$NETDATA_ENABLED" != "true" ]; then
    echo "ðŸ“Š Netdata monitoring disabled (NETDATA_ENABLED=false)"
    echo "   To enable: Set NETDATA_ENABLED=true in your configuration"
else
    echo "ðŸ³ Skipping Netdata configuration in Docker mode"
fi

# ========= Setup Directories =========
echo "===== 9. Setting up PolyServer directories ====="
mkdir -p /opt/polyserver/{data,backups,config,scripts}
chown -R $USERNAME:$USERNAME /opt/polyserver
chmod -R 750 /opt/polyserver

# ========= Setup Unbound DNS Cache =========
echo "===== 10. Setting up Unbound DNS cache ====="
if [ "$DOCKER_MODE" = "false" ]; then
    # Enable and start Unbound service
    docker_systemctl enable unbound
    docker_systemctl start unbound

    # Configure DHCP client to preserve DNS settings
    cat > /etc/dhcp/dhclient.conf << EOF
# dhclient.conf - Configuration for DHCP client
# This configuration preserves the DNS settings across DHCP renewals

# Don't override the nameserver with the one provided by DHCP
supersede domain-name-servers 127.0.0.1;

# Request basic network configuration from DHCP server
request subnet-mask, broadcast-address, time-offset, routers,
        domain-name, domain-name-servers, domain-name-search,
        host-name, netbios-name-servers, netbios-scope, interface-mtu,
        ntp-servers;

# Timeout settings
timeout 60;
retry 60;
reboot 10;
select-timeout 5;
initial-interval 2;
EOF

# Update resolv.conf for dual-stack DNS
cat > /etc/resolv.conf << 'EOF'
nameserver 127.0.0.1
nameserver ::1
options edns0 trust-ad
EOF

# Configure system to use our DNS resolver (Debian networking)
# Debian uses traditional /etc/network/interfaces or systemd-resolved
# Make resolv.conf immutable to prevent DHCP from overwriting it
chattr +i /etc/resolv.conf

# Configure systemd-resolved to use our local DNS
if systemctl is-active --quiet systemd-resolved; then
  mkdir -p /etc/systemd/resolved.conf.d
  cat > /etc/systemd/resolved.conf.d/local-dns.conf << EOF
[Resolve]
DNS=127.0.0.1
FallbackDNS=8.8.8.8 1.1.1.1
DNSSEC=yes
DNSOverTLS=opportunistic
Cache=yes
EOF
  systemctl restart systemd-resolved
fi

# Configure Unbound (use template-generated configuration)
echo "Using generated Unbound configuration from template system..."
# Note: Unbound configuration is handled by the template system
# The configuration file is generated from templates/unbound/local.conf.template
# and placed in /etc/unbound/unbound.conf.d/local.conf during deployment

    # Fix AppArmor for Unbound - grant net_admin capability
    echo "Configuring AppArmor for Unbound..."
    mkdir -p /etc/apparmor.d/local
    cat > /etc/apparmor.d/local/usr.sbin.unbound << 'EOF'
# Site-specific additions and overrides for usr.sbin.unbound
# Grant net_admin capability for Unbound network configuration
capability net_admin,
EOF

    # Reload AppArmor profile
    if command -v apparmor_parser >/dev/null 2>&1 && [ -f /etc/apparmor.d/usr.sbin.unbound ]; then
        apparmor_parser -r /etc/apparmor.d/usr.sbin.unbound 2>/dev/null || true
        echo "âœ… AppArmor profile updated for Unbound"
    fi

    # Disable unbound-resolvconf service (not needed and causes errors)
    echo "Disabling unbound-resolvconf service..."
    systemctl stop unbound-resolvconf.service 2>/dev/null || true
    systemctl disable unbound-resolvconf.service 2>/dev/null || true
    systemctl mask unbound-resolvconf.service 2>/dev/null || true
    echo "âœ… Unbound-resolvconf service disabled"

    # Restart Unbound service to apply changes
    docker_systemctl restart unbound

    # Create log file with proper permissions
    touch /var/log/unbound.log
    chmod 640 /var/log/unbound.log
    chown unbound:adm /var/log/unbound.log

    # Add log rotation configuration
    cat > /etc/logrotate.d/unbound << EOF
/var/log/unbound.log {
    weekly
    rotate 12
    compress
    delaycompress
    missingok
    notifempty
    create 640 unbound adm
    postrotate
        service unbound restart > /dev/null
    endscript
}
EOF

    # Test DNS resolution
    echo "Testing DNS resolution through Unbound..."
    dig @127.0.0.1 google.com | grep -A2 "ANSWER SECTION"
else
    echo "ðŸ³ Skipping Unbound DNS cache setup in Docker mode"
fi

# ========= Configure comprehensive log rotation =========
echo "===== 10.5 Setting up comprehensive log rotation ====="

# Nginx log rotation (includes ModSecurity logs)
cat > /etc/logrotate.d/nginx << 'EOF'
/var/log/nginx/*.log {
    daily
    rotate 30
    compress
    delaycompress
    missingok
    notifempty
    create 0640 www-data adm
    sharedscripts
    prerotate
        if [ -d /etc/logrotate.d/httpd-prerotate ]; then \
            run-parts /etc/logrotate.d/httpd-prerotate; \
        fi \
    endprerotate
    postrotate
        systemctl reload nginx > /dev/null 2>&1 || true
    endscript
}

# ModSecurity audit logs (separate rotation for large files)
/var/log/nginx/modsec_audit.log /var/log/nginx/modsec_debug.log {
    daily
    rotate 14
    size 100M
    compress
    delaycompress
    missingok
    notifempty
    create 0640 www-data adm
    copytruncate
}
EOF

# Security scan logs rotation
cat > /etc/logrotate.d/security-scans << 'EOF'
# ClamAV scan logs
/var/log/clamav/daily_scan.log {
    weekly
    rotate 12
    compress
    delaycompress
    missingok
    notifempty
    create 0644 root root
}

# Malware detection logs
/var/log/maldet/daily_scan.log {
    weekly
    rotate 12
    compress
    delaycompress
    missingok
    notifempty
    create 0644 root root
}

# RKHunter scan logs
/var/log/rkhunter/daily_scan.log {
    weekly
    rotate 12
    compress
    delaycompress
    missingok
    notifempty
    create 0644 root root
}

# chkrootkit scan logs
/var/log/chkrootkit/daily_scan.log {
    weekly
    rotate 12
    compress
    delaycompress
    missingok
    notifempty
    create 0644 root root
}
EOF

# Container security logs rotation
cat > /etc/logrotate.d/container-security << 'EOF'
# Trivy container vulnerability scan logs
/var/log/security/trivy/*.log {
    weekly
    rotate 8
    compress
    delaycompress
    missingok
    notifempty
    create 0644 root root
}

# Docker logs (if using json-file driver)
/var/lib/docker/containers/*/*.log {
    daily
    rotate 7
    size 100M
    compress
    delaycompress
    missingok
    notifempty
    copytruncate
}
EOF

# PolyServer application logs rotation
cat > /etc/logrotate.d/polyserver << 'EOF'
# PolyServer application logs
/opt/polyserver/logs/*.log {
    daily
    rotate 30
    compress
    delaycompress
    missingok
    notifempty
    create 0644 deploy deploy
    copytruncate
}

# PolyServer backup logs
/opt/polyserver/backups/*.log {
    weekly
    rotate 12
    compress
    delaycompress
    missingok
    notifempty
    create 0644 deploy deploy
}

# DSGVO/GDPR logs
/var/log/dsgvo/*.log {
    monthly
    rotate 24
    compress
    delaycompress
    missingok
    notifempty
    create 0644 root root
}

# Security incident logs
/var/log/security/incidents/*.log {
    monthly
    rotate 36
    compress
    delaycompress
    missingok
    notifempty
    create 0600 root root
}
EOF

# Fail2ban log rotation (enhance default)
cat > /etc/logrotate.d/fail2ban << 'EOF'
/var/log/fail2ban.log {
    weekly
    rotate 12
    compress
    delaycompress
    missingok
    notifempty
    create 0644 root root
    postrotate
        systemctl reload fail2ban > /dev/null 2>&1 || true
    endscript
}
EOF

# UFW firewall log rotation
cat > /etc/logrotate.d/ufw << 'EOF'
/var/log/ufw.log {
    daily
    rotate 30
    compress
    delaycompress
    missingok
    notifempty
    create 0640 root adm
}
EOF

# Logwatch logs rotation
cat > /etc/logrotate.d/logwatch << 'EOF'
/var/log/logwatch/*.log {
    monthly
    rotate 12
    compress
    delaycompress
    missingok
    notifempty
    create 0644 root root
}
EOF

echo "Comprehensive log rotation configured for all PolyServer components"

# Enhanced application-specific log rotation (avoiding system conflicts)
# Only configure logs that are not managed by default system logrotate

# Sudo activity logs (extend default retention for security monitoring)
cat > /etc/logrotate.d/polyserver-sudo << 'EOF'
# Sudo activity logs (important for privilege escalation monitoring)
/var/log/sudo.log {
    daily
    rotate 90
    compress
    delaycompress
    missingok
    notifempty
    create 0640 root adm
    postrotate
        systemctl reload rsyslog > /dev/null 2>&1 || true
    endscript
}
EOF

# AIDE logs (application-specific)
cat > /etc/logrotate.d/polyserver-aide << 'EOF'
# AIDE integrity check logs
/var/log/aide/aide-check.log {
    weekly
    rotate 12
    compress
    delaycompress
    missingok
    notifempty
    create 0640 root root
}
EOF

# Configure comprehensive rsyslog log rotation
cat > /etc/logrotate.d/rsyslog << 'EOF'
/var/log/syslog
/var/log/mail.log
/var/log/mail.err
/var/log/mail.info
/var/log/mail.warn
/var/log/kern.log
/var/log/auth.log
/var/log/user.log
/var/log/daemon.log
/var/log/debug
/var/log/messages
{
    rotate 7
    daily
    missingok
    notifempty
    delaycompress
    compress
    postrotate
        invoke-rc.d rsyslog rotate > /dev/null 2>&1 || true
    endscript
}
EOF

echo "âœ… Comprehensive log rotation configured (including rsyslog system logs)"

# ========= Additional security hardening =========
echo "===== 11. Additional security hardening ====="

echo "===== 11.1 Setting up system resource limits (ulimits) ====="
# Prevent resource exhaustion attacks with sensible limits
cat > /etc/security/limits.d/server.conf << EOF
# Server Resource Limits
# Prevent resource exhaustion attacks and improve system stability

# Limits for all users
* soft nofile 4096
* hard nofile 8192
* soft nproc 1024
* hard nproc 2048
* soft core 0
* hard core 0
* soft memlock 64
* hard memlock 64

# Deploy user limits
{{USERNAME}} soft nofile 2048
{{USERNAME}} hard nofile 4096
{{USERNAME}} soft nproc 512
{{USERNAME}} hard nproc 1024
{{USERNAME}} soft maxlogins 10
{{USERNAME}} hard maxlogins 20

# Root user (for system processes)
root soft nofile 8192
root hard nofile 16384
root soft nproc 4096
root hard nproc 8192

# Service accounts
www-data soft nofile 2048
www-data hard nofile 4096
www-data soft nproc 512
www-data hard nproc 1024
EOF

echo "âœ… System resource limits configured to prevent resource exhaustion attacks"

echo "===== 11.2 Adding systemd journal rate limiting ====="
# Prevent log flooding that could fill disk space
mkdir -p /etc/systemd/journald.conf.d
cat > /etc/systemd/journald.conf.d/99-server-limits.conf << EOF
# Server Journal Configuration
# Prevent disk space exhaustion from excessive logging

[Journal]
# Limit journal size to prevent disk full
SystemMaxUse=1G
SystemKeepFree=2G
SystemMaxFileSize=100M
RuntimeMaxUse=200M
RuntimeKeepFree=1G
RuntimeMaxFileSize=20M

# Rate limiting to prevent log flooding
RateLimitIntervalSec=30s
RateLimitBurst=1000

# Compress logs to save space
Compress=yes

# Forward to syslog (rsyslog) for processing
ForwardToSyslog=yes
ForwardToConsole=no
EOF

docker_systemctl restart systemd-journald
echo "âœ… Systemd journal rate limiting configured"

echo "===== 11.3 Adding kernel security parameters ====="
# Set secure kernel parameters including auto-reboot on panic
cat > /etc/sysctl.d/99-server-security.conf << EOF
# Server Security Kernel Parameters

# Network security
net.ipv4.ip_forward = 0
net.ipv4.conf.all.send_redirects = 0
net.ipv4.conf.default.send_redirects = 0
net.ipv4.conf.all.accept_redirects = 0
net.ipv4.conf.default.accept_redirects = 0
net.ipv4.conf.all.accept_source_route = 0
net.ipv4.conf.default.accept_source_route = 0
net.ipv4.conf.all.log_martians = 1
net.ipv4.conf.default.log_martians = 1
net.ipv4.conf.all.rp_filter = 1
net.ipv4.conf.default.rp_filter = 1
net.ipv4.icmp_echo_ignore_broadcasts = 1
net.ipv4.icmp_ignore_bogus_error_responses = 1
net.ipv4.tcp_syncookies = 1

# IPv6 security configuration (keep enabled for modern infrastructure)
net.ipv6.conf.all.accept_ra = 0
net.ipv6.conf.default.accept_ra = 0
net.ipv6.conf.all.accept_redirects = 0
net.ipv6.conf.default.accept_redirects = 0
net.ipv6.conf.all.forwarding = 0

# Process security
kernel.dmesg_restrict = 1
kernel.kptr_restrict = 2
kernel.yama.ptrace_scope = 1

# File system security
fs.suid_dumpable = 0
fs.protected_hardlinks = 1
fs.protected_symlinks = 1

# Debian 13 Trixie security enhancements
# Control Flow Integrity (CFI) hardening - available on supported hardware
# Note: These features are automatically enabled by the kernel on supported CPUs
# Intel CET (Control-flow Enforcement Technology) - amd64
# ARM PAC (Pointer Authentication) and BTI (Branch Target Identification) - arm64
# No explicit kernel parameters needed as they're enabled at compile time

# Additional memory protection
vm.mmap_rnd_bits = 32
vm.mmap_rnd_compat_bits = 16

# Automatic reboot after kernel panic (headless environment)
kernel.panic = 10
kernel.panic_on_oops = 1
EOF

# Apply kernel parameters
if [ "$DOCKER_MODE" = "false" ]; then
    sysctl -p /etc/sysctl.d/99-server-security.conf
    echo "âœ… Kernel security parameters and panic auto-reboot configured"
else
    echo "ðŸ³ Docker mode: skipping sysctl parameter application (not permitted in containers)"
fi

echo "===== 12.1. Configuring /tmp hardening with systemd mount ====="
if [ "$DOCKER_MODE" = "false" ]; then
    # Create systemd mount unit for secure /tmp
    cat > /etc/systemd/system/tmp.mount << 'EOF'
[Unit]
Description=Temporary Directory (/tmp)
Conflicts=umount.target
Before=local-fs.target umount.target
After=swap.target

[Mount]
What=tmpfs
Where=/tmp
Type=tmpfs
Options=mode=1777,strictatime,noexec,nosuid,nodev,size=512M

[Install]
WantedBy=multi-user.target
EOF

    # Enable and start the secure /tmp mount
    systemctl daemon-reload
    systemctl enable tmp.mount
    
    # Only start if /tmp is not already mounted or has different options
    if ! systemctl is-active --quiet tmp.mount; then
        echo "âš ï¸ Enabling secure /tmp mount (will take effect on next reboot)"
        echo "Current /tmp will be preserved until reboot"
    else
        echo "âœ… Secure /tmp mount already active"
    fi
    
    systemctl status tmp.mount --no-pager -l || true
    echo "âœ… /tmp hardening configured with systemd mount unit"
else
    echo "ðŸ³ Skipping /tmp hardening in Docker mode"
fi

echo "===== 11.4 Blacklisting unused filesystem modules ====="
# Disable unused filesystems that could be security risks
cat > /etc/modprobe.d/blacklist-filesystems.conf << EOF
# Blacklist unused filesystems for security

# Legacy/rare filesystems
blacklist cramfs
blacklist freevxfs
blacklist jffs2
blacklist hfs
blacklist hfsplus
blacklist squashfs
blacklist udf

# FireWire - rarely needed on servers
blacklist firewire-core
blacklist firewire-ohci
blacklist firewire-sbp2

# Bluetooth - not needed on servers
blacklist bluetooth
blacklist btusb
blacklist rfcomm
blacklist bnep

# Wireless - typically not needed on servers
blacklist cfg80211
blacklist mac80211
EOF

echo "âœ… Unused filesystem modules blacklisted for security"

echo "===== 11.5 Creating systemd timer services for reliable security monitoring ====="
# Create systemd timers to ensure critical security scans run even if cron missed

# Malware detection service
cat > /etc/systemd/system/maldet-scan.service << 'EOF'
[Unit]
Description=Linux Malware Detect Daily Scan
After=network.target

[Service]
Type=oneshot
ExecStart=/etc/cron.daily/maldet-scan
User=root
StandardOutput=journal
StandardError=journal
TimeoutSec=7200
EOF

# Malware detection timer (runs daily, catches up missed runs)
cat > /etc/systemd/system/maldet-scan.timer << 'EOF'
[Unit]
Description=Run malware detection daily
Requires=maldet-scan.service

[Timer]
OnCalendar=daily
RandomizedDelaySec=30min
Persistent=yes
AccuracySec=1min

[Install]
WantedBy=timers.target
EOF

# ClamAV scan service
cat > /etc/systemd/system/clamscan.service << 'EOF'
[Unit]
Description=ClamAV Daily Virus Scan
After=network.target

[Service]
Type=oneshot
ExecStart=/etc/cron.daily/clamscan
User=root
StandardOutput=journal
StandardError=journal
TimeoutSec=7200
EOF

# ClamAV scan timer (runs daily, catches up missed runs)
cat > /etc/systemd/system/clamscan.timer << 'EOF'
[Unit]
Description=Run ClamAV scan daily
Requires=clamscan.service

[Timer]
OnCalendar=daily
RandomizedDelaySec=45min
Persistent=yes
AccuracySec=1min

[Install]
WantedBy=timers.target
EOF

# Trivy container scan service (if Docker mode)
if [ "$DEPLOYMENT_MODE" = "docker" ]; then
cat > /etc/systemd/system/trivy-scan.service << 'EOF'
[Unit]
Description=Trivy Container Security Scan
After=network.target docker.service
Requires=docker.service

[Service]
Type=oneshot
ExecStart=/etc/cron.daily/trivy-scan
User=root
StandardOutput=journal
StandardError=journal
TimeoutSec=3600
EOF

cat > /etc/systemd/system/trivy-scan.timer << 'EOF'
[Unit]
Description=Run Trivy container scan daily
Requires=trivy-scan.service

[Timer]
OnCalendar=daily
RandomizedDelaySec=60min
Persistent=yes
AccuracySec=1min

[Install]
WantedBy=timers.target
EOF
fi

# Rootkit scan service
cat > /etc/systemd/system/rkhunter-scan.service << 'EOF'
[Unit]
Description=RKHunter Rootkit Scan
After=network.target

[Service]
Type=oneshot
ExecStart=/etc/cron.daily/rkhunter-scan
User=root
StandardOutput=journal
StandardError=journal
TimeoutSec=1800
EOF

# Rootkit scan timer (runs daily, catches up missed runs)
cat > /etc/systemd/system/rkhunter-scan.timer << 'EOF'
[Unit]
Description=Run rootkit scan daily
Requires=rkhunter-scan.service

[Timer]
OnCalendar=daily
RandomizedDelaySec=90min
Persistent=yes
AccuracySec=1min

[Install]
WantedBy=timers.target
EOF

# Enable and start the timer services
systemctl daemon-reload
systemctl enable maldet-scan.timer
systemctl enable clamscan.timer
systemctl enable rkhunter-scan.timer

if [ "$DEPLOYMENT_MODE" = "docker" ]; then
    systemctl enable trivy-scan.timer
    systemctl start trivy-scan.timer
fi

systemctl start maldet-scan.timer
systemctl start clamscan.timer
systemctl start rkhunter-scan.timer

echo "âœ… Systemd timer services created and enabled for security scans"
echo "   â€¢ maldet-scan.timer - daily malware detection (with randomized delay)"
echo "   â€¢ clamscan.timer - daily antivirus scan (with randomized delay)"
echo "   â€¢ rkhunter-scan.timer - daily rootkit scan (with randomized delay)"
if [ "$DEPLOYMENT_MODE" = "docker" ]; then
    echo "   â€¢ trivy-scan.timer - daily container vulnerability scan"
fi
echo "   â€¢ All timers use Persistent=yes to run missed executions on boot"
echo "   â€¢ Randomized delays prevent all scans running simultaneously"

# Verify timers are active
echo ""
echo "Security scan timer status:"
systemctl list-timers maldet-scan.timer clamscan.timer rkhunter-scan.timer --no-pager || true

# ========= Now restart SSH with new configuration =========
echo "===== 12. Restarting SSH to apply security settings ====="
docker_systemctl restart sshd

# Verify SSH is running only on target port and clean up port 22
if ss -tnlp | grep -q ":$SSH_PORT.*sshd"; then
  sed -i '/^Port 22$/d' /etc/ssh/sshd_config
  docker_systemctl reload ssh
  ufw delete allow 22/tcp || true
  echo "âœ… SSH now running only on port $SSH_PORT"
fi

echo "===== 13. Optional DSGVO/GDPR Compliance Setup ====="
echo "Setting up DSGVO/GDPR compliance framework..."

# Copy DSGVO setup script to the scripts directory first
mkdir -p /opt/polyserver/scripts
if [ -f "/opt/polyserver/scripts/setup-dsgvo.sh" ]; then
    DSGVO_SETUP_SCRIPT="/opt/polyserver/scripts/setup-dsgvo.sh"
else
    # Look for the script in the current directory structure
    CURRENT_DIR=$(dirname "${BASH_SOURCE[0]}")
    if [ -f "$CURRENT_DIR/setup-dsgvo.sh" ]; then
        cp "$CURRENT_DIR/setup-dsgvo.sh" "/opt/polyserver/scripts/"
        DSGVO_SETUP_SCRIPT="/opt/polyserver/scripts/setup-dsgvo.sh"
        chmod +x "$DSGVO_SETUP_SCRIPT"
    fi
fi

if [ -f "$DSGVO_SETUP_SCRIPT" ]; then
    echo "Running DSGVO compliance setup..."
    # Run non-interactively by providing default answers
    echo "y" | bash "$DSGVO_SETUP_SCRIPT" || echo "DSGVO setup completed with warnings"
else
    echo "DSGVO setup script not found. You can run it later manually."
    echo "Make sure to install DSGVO compliance files before running compliance checks."
fi

echo "===== 14. Advanced Security Hardening ====="
echo "Implementing comprehensive security enhancements..."

# APT Package Pinning for critical security packages
echo "Setting up APT package pinning for critical security packages..."
cat > /etc/apt/preferences.d/security-packages << 'EOF'
# Pin critical security packages to prevent accidental downgrades
Package: openssh-server openssh-client
Pin: version *
Pin-Priority: 1001

Package: fail2ban
Pin: version *
Pin-Priority: 1001

Package: ufw
Pin: version *
Pin-Priority: 1001

Package: auditd
Pin: version *
Pin-Priority: 1001

Package: sudo
Pin: version *
Pin-Priority: 1001

Package: clamav clamav-daemon clamav-freshclam
Pin: version *
Pin-Priority: 1001

Package: rkhunter chkrootkit
Pin: version *
Pin-Priority: 1001
EOF

# Full Disk Encryption Detection
echo "Checking for Full Disk Encryption (LUKS)..."
if lsblk -f | grep -q crypto_LUKS; then
    echo "âœ… Full disk encryption (LUKS) detected and active"
    echo "LUKS_ENCRYPTION=enabled" >> /etc/security-status.conf
else
    echo "âš ï¸ No LUKS encryption detected - consider enabling FDE for enhanced security"
    echo "LUKS_ENCRYPTION=disabled" >> /etc/security-status.conf
fi

# IPv6 Security (belt and suspenders approach)
echo "Implementing IPv6 security hardening..."
if command -v ufw >/dev/null 2>&1; then
    # Additional IPv6 rules as extra protection
    ufw --force enable
    # Block all IPv6 by default (additional layer beyond sysctl)
    ip6tables -P INPUT DROP 2>/dev/null || true
    ip6tables -P FORWARD DROP 2>/dev/null || true
    ip6tables -P OUTPUT DROP 2>/dev/null || true
    echo "âœ… IPv6 traffic blocked via ip6tables (additional protection)"
fi

# Filesystem Mount Options Security Audit
echo "Auditing filesystem mount options for security compliance..."
MOUNT_AUDIT_LOG="/var/log/security/mount-audit.log"
mkdir -p "$(dirname "$MOUNT_AUDIT_LOG")"

{
    echo "=== Filesystem Mount Security Audit - $(date) ==="
    echo "Checking critical mount points for security options..."
    
    # Check /tmp mount options
    if mount | grep -E '^[^ ]+ on /tmp ' | grep -E '(noexec|nodev|nosuid)'; then
        echo "âœ… /tmp has security mount options"
    else
        echo "âš ï¸ /tmp missing security options (noexec,nodev,nosuid recommended)"
    fi
    
    # Check /var/tmp mount options  
    if mount | grep -E '^[^ ]+ on /var/tmp ' | grep -E '(noexec|nodev|nosuid)'; then
        echo "âœ… /var/tmp has security mount options"
    else
        echo "âš ï¸ /var/tmp missing security options (noexec,nodev,nosuid recommended)"
    fi
    
    # Check /home mount options
    if mount | grep -E '^[^ ]+ on /home ' | grep -E 'nodev'; then
        echo "âœ… /home has nodev option"
    else
        echo "âš ï¸ /home missing nodev option"
    fi
    
    # Check for world-writable mount points
    echo ""
    echo "Checking for potentially dangerous mount options..."
    mount | grep -E '(exec|dev|suid)' | grep -v -E '(noexec|nodev|nosuid)' || echo "No dangerous mount options found"
    
    echo ""
} >> "$MOUNT_AUDIT_LOG"

cat "$MOUNT_AUDIT_LOG"

# Service Whitelist Audit
echo "Performing service whitelist security audit..."
SERVICE_AUDIT_LOG="/var/log/security/service-audit.log"

# Define allowed services (extend as needed for your applications)
ALLOWED_SERVICES="
ssh|sshd
systemd-
NetworkManager
cron|crond
rsyslog
dbus
getty
user@
session-
auditd
fail2ban
ufw
docker
containerd
nginx
netdata
unbound
clamav
freshclam
maldet
rkhunter
"

{
    echo "=== Service Whitelist Audit - $(date) ==="
    echo "Checking running services against security whitelist..."
    
    # Get all running services
    RUNNING_SERVICES=$(systemctl list-units --type=service --state=running --no-legend | awk '{print $1}' | sed 's/\.service$//')
    
    echo "Currently running services:"
    echo "$RUNNING_SERVICES"
    echo ""
    
    echo "Services not in whitelist (review for security):"
    for service in $RUNNING_SERVICES; do
        if ! echo "$ALLOWED_SERVICES" | grep -qE "^${service}"; then
            # Check if it matches any pattern in the whitelist
            WHITELISTED=false
            while read -r pattern; do
                if [[ "$service" =~ $pattern ]]; then
                    WHITELISTED=true
                    break
                fi
            done <<< "$ALLOWED_SERVICES" 2>/dev/null
            
            if [ "$WHITELISTED" = "false" ]; then
                echo "âš ï¸ $service - verify this service is necessary"
            fi
        fi
    done
    
    echo ""
} >> "$SERVICE_AUDIT_LOG"

cat "$SERVICE_AUDIT_LOG"

# Enhanced Persistence Detection System
echo "Setting up enhanced persistence detection monitoring..."
BASELINE_DIR="/var/lib/security/baselines"
mkdir -p "$BASELINE_DIR"

# Create persistence monitoring script
cat > /usr/local/bin/check-persistence-locations.sh << 'EOF'
#!/bin/bash
# Enhanced Persistence Detection System
# Monitors common persistence locations for unauthorized changes

BASELINE_DIR="/var/lib/security/baselines"
LOG_FILE="/var/log/security/persistence-detection.log"
MAIL_RECIPIENT="{{LOGWATCH_EMAIL}}"

# Logging function
log_message() {
    echo "$(date '+%Y-%m-%d %H:%M:%S') - $1" | tee -a "$LOG_FILE"
}

# Check a specific location for changes
check_persistence_location() {
    local location="$1"
    local name="$2"
    local baseline_file="$BASELINE_DIR/${name}.baseline"
    local current_file="/tmp/${name}.current"
    
    if [ -d "$location" ] || [ -f "$location" ]; then
        find "$location" -type f -exec stat -c "%n %Y %s" {} \; 2>/dev/null | sort > "$current_file"
        
        if [ -f "$baseline_file" ]; then
            if ! diff -q "$baseline_file" "$current_file" >/dev/null 2>&1; then
                log_message "ALERT: Changes detected in $name ($location)"
                diff "$baseline_file" "$current_file" | head -20 >> "$LOG_FILE"
                echo "PERSISTENCE ALERT: Changes detected in $name on $(hostname)" | \
                    mail -s "SECURITY ALERT: Persistence Detection" "$MAIL_RECIPIENT" 2>/dev/null || true
            fi
        else
            # First run - create baseline
            cp "$current_file" "$baseline_file"
            log_message "Created baseline for $name ($location)"
        fi
        rm -f "$current_file"
    fi
}

# Monitor autostart locations
log_message "Starting persistence detection scan..."

# System-wide autostart locations
check_persistence_location "/etc/init.d" "init_scripts"
check_persistence_location "/etc/systemd/system" "systemd_system"
check_persistence_location "/etc/systemd/user" "systemd_user"
check_persistence_location "/etc/cron.d" "cron_d"
check_persistence_location "/etc/cron.daily" "cron_daily"
check_persistence_location "/etc/cron.hourly" "cron_hourly"
check_persistence_location "/etc/cron.weekly" "cron_weekly"
check_persistence_location "/etc/cron.monthly" "cron_monthly"
check_persistence_location "/etc/rc.local" "rc_local"
check_persistence_location "/etc/profile.d" "profile_d"
check_persistence_location "/etc/bash.bashrc" "bash_bashrc"

# User autostart locations (for existing users)
for user_home in /home/*; do
    if [ -d "$user_home" ]; then
        username=$(basename "$user_home")
        check_persistence_location "$user_home/.bashrc" "bashrc_$username"
        check_persistence_location "$user_home/.profile" "profile_$username"
        check_persistence_location "$user_home/.config/autostart" "autostart_$username"
        check_persistence_location "$user_home/.config/systemd/user" "systemd_user_$username"
    fi
done

# Check for new SUID/SGID binaries
find /usr /bin /sbin /opt -type f \( -perm -4000 -o -perm -2000 \) 2>/dev/null | sort > "/tmp/suid_sgid.current"
if [ -f "$BASELINE_DIR/suid_sgid.baseline" ]; then
    if ! diff -q "$BASELINE_DIR/suid_sgid.baseline" "/tmp/suid_sgid.current" >/dev/null 2>&1; then
        log_message "ALERT: SUID/SGID binary changes detected"
        diff "$BASELINE_DIR/suid_sgid.baseline" "/tmp/suid_sgid.current" | head -20 >> "$LOG_FILE"
        echo "SUID/SGID ALERT: Binary permission changes detected on $(hostname)" | \
            mail -s "SECURITY ALERT: SUID/SGID Changes" "$MAIL_RECIPIENT" 2>/dev/null || true
    fi
else
    cp "/tmp/suid_sgid.current" "$BASELINE_DIR/suid_sgid.baseline"
    log_message "Created SUID/SGID baseline"
fi
rm -f "/tmp/suid_sgid.current"

log_message "Persistence detection scan completed"
EOF

chmod +x /usr/local/bin/check-persistence-locations.sh

# Run initial baseline creation
echo "Creating initial security baselines..."
/usr/local/bin/check-persistence-locations.sh

# Add to cron for regular monitoring
cat > /etc/cron.d/persistence-detection << 'EOF'
# Enhanced Persistence Detection - runs every 4 hours
0 */4 * * * root /usr/local/bin/check-persistence-locations.sh >/dev/null 2>&1
EOF

# Create log rotation for security logs
cat > /etc/logrotate.d/security-monitoring << 'EOF'
/var/log/security/*.log {
    rotate 12
    monthly
    compress
    delaycompress
    missingok
    notifempty
    create 640 root root
}
EOF

# Final security status summary
echo "Creating security status summary..."
cat > /etc/security-status.conf << EOF
# PolyServer Security Status Configuration
HARDENING_LEVEL=enhanced
APT_PINNING=enabled
PERSISTENCE_MONITORING=enabled
SERVICE_AUDIT=enabled
MOUNT_AUDIT=enabled
SECURITY_BASELINE_DATE=$(date +%Y-%m-%d)
EOF

echo "âœ… Advanced security hardening completed!"
echo ""
echo "Security enhancements implemented:"
echo "   â€¢ APT package pinning for critical security packages"
echo "   â€¢ Full disk encryption detection and status logging"  
echo "   â€¢ IPv6 security hardening (belt and suspenders approach)"
echo "   â€¢ Filesystem mount option security audit"
echo "   â€¢ Service whitelist audit against security baseline"
echo "   â€¢ Enhanced persistence detection monitoring"
echo "   â€¢ SUID/SGID binary monitoring"
echo "   â€¢ Automated security baseline creation and monitoring"
echo ""
echo "Security logs location: /var/log/security/"
echo "Security baselines: /var/lib/security/baselines/"
echo "Security status: /etc/security-status.conf"

echo "===== 15. Advanced Security Refinements ====="

# AppArmor Profile Enforcement Verification
echo "Verifying AppArmor profile enforcement..."
if command -v aa-status >/dev/null 2>&1; then
    echo "Current AppArmor status:"
    aa-status
    
    # Check if profiles are in enforce mode
    PROFILES_COMPLAIN=$(aa-status --complain 2>/dev/null | wc -l)
    PROFILES_ENFORCE=$(aa-status --enforce 2>/dev/null | wc -l)
    
    if [ "$PROFILES_COMPLAIN" -gt 0 ]; then
        echo "âš ï¸ $PROFILES_COMPLAIN AppArmor profiles in complain mode - consider enforcing:"
        aa-status --complain 2>/dev/null || true
        echo "   To enforce: sudo aa-enforce /etc/apparmor.d/<profile>"
    fi
    
    if [ "$PROFILES_ENFORCE" -gt 0 ]; then
        echo "âœ… $PROFILES_ENFORCE AppArmor profiles in enforce mode"
    fi
    
    # Create custom SSH profile for enhanced protection
    cat > /etc/apparmor.d/usr.sbin.sshd << 'EOF'
#include <tunables/global>

/usr/sbin/sshd {
  #include <abstractions/authentication>
  #include <abstractions/base>
  #include <abstractions/consoles>
  #include <abstractions/nameservice>
  #include <abstractions/wutmp>

  capability sys_chroot,
  capability sys_resource,
  capability chown,
  capability fowner,
  capability kill,
  capability setgid,
  capability setuid,
  capability audit_write,
  capability dac_override,
  capability dac_read_search,
  capability sys_tty_config,

  /dev/log w,
  /dev/null rw,
  /dev/ptmx rw,
  /dev/pts/* rw,
  /dev/tty rw,
  /dev/urandom r,

  /etc/default/locale r,
  /etc/environment r,
  /etc/group r,
  /etc/hosts.allow r,
  /etc/hosts.deny r,
  /etc/ld.so.cache r,
  /etc/localtime r,
  /etc/motd r,
  /etc/passwd r,
  /etc/security/** r,
  /etc/shadow r,
  /etc/ssh/** r,

  # Allow access to user authorized_keys files
  /home/*/.ssh/authorized_keys r,
  /home/*/.ssh/authorized_keys2 r,

  /proc/*/fd/ r,
  /proc/*/mounts r,
  /proc/*/stat r,
  /proc/sys/crypto/fips_enabled r,

  /run/sshd.pid w,
  /run/systemd/sessions/* rw,
  /run/utmp rw,

  /usr/bin/** PUx,
  /bin/** PUx,
  /usr/sbin/sshd mr,

  /var/log/auth.log w,
  /var/log/btmp w,
  /var/log/lastlog rw,
  /var/log/wtmp rw,

  # Site-specific additions and overrides. See local/README for details.
  #include <local/usr.sbin.sshd>
}
EOF

    # Create nginx AppArmor profile for web servers
    if [ "$DEPLOYMENT_MODE" != "docker" ]; then
        cat > /etc/apparmor.d/usr.sbin.nginx << 'EOF'
#include <tunables/global>

/usr/sbin/nginx {
  #include <abstractions/base>
  #include <abstractions/nameservice>

  capability dac_override,
  capability setgid,
  capability setuid,

  /etc/nginx/** r,
  /etc/ssl/certs/ r,
  /etc/ssl/certs/** r,
  /etc/ssl/private/ r,
  /etc/ssl/private/** r,

  /proc/*/auxv r,
  /proc/sys/kernel/ngroups_max r,

  /run/nginx.pid rw,
  /var/log/nginx/** w,
  /var/www/** r,

  /usr/sbin/nginx mr,
  /usr/share/nginx/** r,

  # Site-specific additions and overrides. See local/README for details.
  #include <local/usr.sbin.nginx>
}
EOF
        apparmor_parser -r /etc/apparmor.d/usr.sbin.nginx 2>/dev/null || echo "Nginx AppArmor profile created"
        echo "âœ… Nginx AppArmor profile created"
    fi
    
    # Load and enforce the SSH profile
    # Create the local include directory and file to prevent parser errors
    mkdir -p /etc/apparmor.d/local
    touch /etc/apparmor.d/local/usr.sbin.sshd
    
    # Add a comment to the local file
    cat > /etc/apparmor.d/local/usr.sbin.sshd << 'EOF'
# Site-specific additions and overrides for /usr/sbin/sshd
# This file can be used to add additional rules specific to this system
# Format: standard AppArmor rules
EOF
    
    apparmor_parser -r /etc/apparmor.d/usr.sbin.sshd 2>/dev/null || echo "AppArmor SSH profile created (will be active after sshd restart)"
    echo "âœ… AppArmor SSH profile created and loaded"
else
    echo "âš ï¸ AppArmor not available or not installed"
fi

# Optional Resource Guardian System
echo ""
read -p "Install Resource Guardian system for proactive resource management? (y/N): " -n 1 -r
echo
if [[ $REPLY =~ ^[Yy]$ ]]; then
    echo "===== 15.1 Setting up Resource Guardian System ====="
    echo "Installing Resource Guardian for proactive resource management..."
    
    cat > /usr/local/bin/resource-guardian << 'EOF'
#!/bin/bash
# Resource Guardian - Proactive Resource Management for Production Server
# Monitors and manages resource usage to prevent service failures

LOGFILE="/var/log/resource-guardian.log"
TIMESTAMP=$(date '+%Y-%m-%d %H:%M:%S')

# Configuration - More conservative for production servers
HIGH_CPU_THRESHOLD=85       # Higher threshold for production
SUSTAINED_CPU_TIME=600      # 10 minutes (longer grace period)
HIGH_MEMORY_THRESHOLD=90    # High memory warning threshold
CRITICAL_MEMORY_THRESHOLD=95 # Emergency memory threshold

# Critical processes that should never be killed
CRITICAL_PROCESSES="systemd|sshd|networkd|dbus|fail2ban|auditd|rsyslog|nginx|docker|containerd"

# Logging function
log_message() {
    echo "[$TIMESTAMP] $*" >> "$LOGFILE"
}

# Function to check CPU usage
check_cpu_usage() {
    # Find processes using high CPU for sustained periods
    ps aux --sort=-%cpu | awk 'NR>1 {print $2, $3, $10, $11}' | head -10 | while read -r pid cpu_percent time_col command; do
        if ! echo "$command" | grep -qE "$CRITICAL_PROCESSES"; then
            if (( $(echo "$cpu_percent > $HIGH_CPU_THRESHOLD" | bc -l) )); then
                # Convert time to seconds for comparison
                time_seconds=$(echo "$time_col" | awk -F: '{
                    if (NF == 3) print ($1 * 3600) + ($2 * 60) + $3
                    else if (NF == 2) print ($1 * 60) + $2
                    else print $1
                }' | cut -d. -f1)
                
                # Only terminate if sustained high usage (production safety)
                if [ "$time_seconds" -gt "$SUSTAINED_CPU_TIME" ]; then
                    log_message "ACTION: Terminating high-CPU process: PID=$pid CMD=$command CPU=${cpu_percent}% TIME=${time_col}"
                    
                    # Send warning email first (production safety)
                    echo "Resource Guardian will terminate high-CPU process on server $(hostname):
                    
Process: $command
PID: $pid  
CPU Usage: ${cpu_percent}%
Runtime: $time_col
Action: Process will be terminated in 2 minutes to protect system stability

To prevent automatic termination: kill $pid or systemctl stop [service]" | mail -s "PRODUCTION WARNING: Resource Guardian Action Pending" root
                    
                    # Wait 2 minutes before termination (production safety)
                    sleep 120
                    
                    # Check if process still exists and is still high CPU
                    if ps -p "$pid" > /dev/null 2>&1; then
                        current_cpu=$(ps -p "$pid" -o %cpu --no-headers 2>/dev/null | tr -d ' ')
                        if (( $(echo "$current_cpu > $HIGH_CPU_THRESHOLD" | bc -l) )); then
                            kill -TERM "$pid" 2>/dev/null
                            sleep 10
                            kill -KILL "$pid" 2>/dev/null
                            
                            echo "Resource Guardian terminated high-CPU process on server $(hostname):
                            
Process: $command
PID: $pid
CPU Usage: ${cpu_percent}%
Runtime: $time_col
Action: Process terminated to protect system stability" | mail -s "PRODUCTION: Resource Guardian Action Taken" root
                        fi
                    fi
                fi
            fi
        fi
    done
}

# Function to check memory usage
check_memory_usage() {
    memory_usage=$(free | grep Mem | awk '{printf "%.1f", ($3/$2)*100}')
    
    if (( $(echo "$memory_usage > $CRITICAL_MEMORY_THRESHOLD" | bc -l) )); then
        log_message "CRITICAL: Memory usage at ${memory_usage}% - emergency cleanup"
        
        # Emergency: kill highest memory non-critical processes
        ps aux --sort=-%mem | awk 'NR>1 {print $2, $4, $11}' | head -5 | while read -r pid mem_percent command; do
            if ! echo "$command" | grep -qE "$CRITICAL_PROCESSES"; then
                if (( $(echo "$mem_percent > 15" | bc -l) )); then
                    log_message "EMERGENCY: Killing high-memory process: PID=$pid CMD=$command MEM=${mem_percent}%"
                    kill -TERM "$pid" 2>/dev/null
                    
                    echo "EMERGENCY: Resource Guardian terminated high-memory process on server $(hostname):
                    
Process: $command
PID: $pid
Memory Usage: ${mem_percent}%
System Memory: ${memory_usage}%
Action: Emergency termination to prevent system crash" | mail -s "PRODUCTION EMERGENCY: Resource Guardian Memory Action" root
                fi
            fi
        done
        
    elif (( $(echo "$memory_usage > $HIGH_MEMORY_THRESHOLD" | bc -l) )); then
        log_message "WARNING: Memory usage at ${memory_usage}% - monitoring closely"
        echo "WARNING: High memory usage (${memory_usage}%) detected on server $(hostname). Resource Guardian is monitoring the situation." | mail -s "PRODUCTION WARNING: High Memory Usage" root
    fi
}

# Function to check system load
check_system_load() {
    load_avg=$(uptime | awk -F'load average:' '{print $2}' | awk '{print $1}' | sed 's/,//')
    cpu_count=$(nproc)
    load_ratio=$(echo "scale=2; $load_avg / $cpu_count" | bc)
    
    # Alert if load average > 2x CPU count (production threshold)
    if (( $(echo "$load_ratio > 2.0" | bc -l) )); then
        log_message "ALERT: High system load - Load: $load_avg, CPUs: $cpu_count, Ratio: $load_ratio"
        echo "HIGH LOAD ALERT: Server $(hostname) experiencing high system load.

Load Average: $load_avg
CPU Count: $cpu_count  
Load Ratio: $load_ratio per CPU

Resource Guardian is monitoring the situation." | mail -s "PRODUCTION ALERT: High System Load" root
    fi
}

# Main execution
log_message "Resource Guardian scan started"

# Check if bc is available (required for floating point calculations)
if ! command -v bc >/dev/null 2>&1; then
    log_message "ERROR: bc calculator not found - installing..."
    apt-get update && apt-get install -y bc
fi

# Run checks
check_cpu_usage
check_memory_usage  
check_system_load

log_message "Resource Guardian scan completed"

# Log rotation for resource guardian logs
if [ $(stat -c%s "$LOGFILE" 2>/dev/null || echo 0) -gt 10485760 ]; then  # 10MB
    mv "$LOGFILE" "${LOGFILE}.old"
    touch "$LOGFILE"
    chmod 644 "$LOGFILE"
    log_message "Resource Guardian log rotated"
fi
EOF

    chmod +x /usr/local/bin/resource-guardian
    
    # Install required dependency
    if ! command -v bc >/dev/null 2>&1; then
        echo "Installing bc calculator for Resource Guardian..."
        apt-get update && apt-get install -y bc
    fi
    
    # Create systemd service for Resource Guardian
    cat > /etc/systemd/system/resource-guardian.service << 'EOF'
[Unit]
Description=Resource Guardian - Proactive Resource Management
After=network.target

[Service]
Type=oneshot
ExecStart=/usr/local/bin/resource-guardian
User=root
StandardOutput=journal
StandardError=journal
EOF
    
    # Create systemd timer for Resource Guardian (runs every 5 minutes for production)
    cat > /etc/systemd/system/resource-guardian.timer << 'EOF'
[Unit]
Description=Run Resource Guardian every 5 minutes
Requires=resource-guardian.service

[Timer]
OnBootSec=5min
OnUnitActiveSec=5min
AccuracySec=1min

[Install]
WantedBy=timers.target
EOF
    
    # Enable and start Resource Guardian
    systemctl daemon-reload
    systemctl enable resource-guardian.timer
    systemctl start resource-guardian.timer
    
    echo "âœ… Resource Guardian system installed and configured"
    echo "   â€¢ Monitors CPU usage every 5 minutes (production-safe interval)"
    echo "   â€¢ CPU threshold: 85% for 10+ minutes (with 2-minute warning)"
    echo "   â€¢ Memory warning: 90%, Critical: 95%"
    echo "   â€¢ Protects critical services: SSH, systemd, fail2ban, nginx, docker, etc."
    echo "   â€¢ Logs all actions to /var/log/resource-guardian.log"
    echo "   â€¢ Sends email alerts for all actions taken"
    echo ""
else
    echo "Skipping Resource Guardian installation"
fi

# Optional Advanced Monitoring Tools
echo ""
read -p "Install advanced server monitoring commands (serverstatus, logmon, servermail)? (y/N): " -n 1 -r
echo
MONITORING_TOOLS_REPLY=$REPLY
if [[ $MONITORING_TOOLS_REPLY =~ ^[Yy]$ ]]; then
    echo "===== 15.2 Setting up Advanced Monitoring Tools ====="
    echo "Installing advanced monitoring commands for server management..."
    
    # Create serverstatus command (adapted from bastionstat)
    cat > /usr/local/bin/serverstatus << 'EOF'
#!/bin/bash
# Server Status Command - Comprehensive server health check
# Can be run by any user

echo "=== Server Status Report ==="
echo "Hostname: $(hostname -f)"
echo "Date: $(date)"
echo ""

echo "=== System Information ==="
echo "Uptime: $(uptime -p)"
echo "Load Average: $(uptime | awk -F'load average:' '{print $2}')"
echo "CPU Cores: $(nproc)"
echo ""

echo "=== Memory Usage ==="
free -h
echo ""

echo "=== Disk Usage ==="
df -h / /var /tmp 2>/dev/null | grep -v tmpfs
echo ""

echo "=== Network Connections ==="
echo "Active connections: $(netstat -ant 2>/dev/null | grep ESTABLISHED | wc -l)"
echo "Listening services:"
ss -tlnp | head -10
echo ""

echo "=== Active Users ==="
who -u
echo ""

echo "=== System Services Status ==="
for service in ssh nginx fail2ban suricata clamav-daemon auditd postfix; do
    if systemctl list-units --type=service | grep -q "^  $service.service"; then
        status=$(systemctl is-active $service 2>/dev/null)
        if [ "$status" = "active" ]; then
            echo "âœ… $service: $status"
        else
            echo "âŒ $service: $status"
        fi
    fi
done
echo ""

echo "=== Recent Security Events ==="
echo "Recent SSH logins:"
last -n 5 2>/dev/null | head -5
echo ""

if [ -f /var/log/auth.log ]; then
    echo "Recent authentication events:"
    grep "$(date '+%b %d')" /var/log/auth.log 2>/dev/null | grep -E "(Accepted|Failed)" | tail -5
fi

echo ""
echo "=== System Resource Alerts ==="
# Check for high load
load_avg=$(uptime | awk -F'load average:' '{print $2}' | awk '{print $1}' | sed 's/,//')
cpu_count=$(nproc)
if [ $(echo "$load_avg > $cpu_count * 2" | bc -l) -eq 1 ] 2>/dev/null; then
    echo "âš ï¸ High system load detected: $load_avg (CPUs: $cpu_count)"
fi

# Check disk space
df -h / | awk 'NR==2 {gsub(/%/, "", $5); if ($5 > 85) print "âš ï¸ Root filesystem usage high: " $5"%"}'
df -h /var | awk 'NR==2 {gsub(/%/, "", $5); if ($5 > 85) print "âš ï¸ /var filesystem usage high: " $5"%"}' 2>/dev/null

# Check memory usage
mem_usage=$(free | grep Mem | awk '{printf "%.0f", ($3/$2)*100}')
if [ "$mem_usage" -gt 90 ]; then
    echo "âš ï¸ High memory usage: ${mem_usage}%"
fi

echo ""
echo "=== Mail System Status ==="
if [ -f /var/mail/root ] || [ -f /var/spool/mail/root ]; then
    mail_count=$(wc -l < /var/mail/root 2>/dev/null || echo "0")
    echo "ðŸ“§ Local mail: $mail_count messages for root"
else
    echo "ðŸ“­ Local mail: No mail file found"
fi
systemctl is-active --quiet postfix && echo "âœ… Mail system (Postfix): Active" || echo "âŒ Mail system (Postfix): Inactive"
EOF
    
    chmod +x /usr/local/bin/serverstatus
    
    # Create logmon command (adapted from sshmon)
    cat > /usr/local/bin/logmon << 'EOF'
#!/bin/bash
# Log Monitor - Real-time log monitoring
# Usage: logmon [auth|security|system|nginx|all]

LOG_TYPE=${1:-auth}

echo "=== Server Log Monitor ==="
echo "Monitoring: $LOG_TYPE logs"
echo "Press Ctrl+C to stop monitoring"
echo ""

case $LOG_TYPE in
    auth)
        echo "Monitoring authentication logs..."
        sudo tail -f /var/log/auth.log | grep --line-buffered -E "(ssh|sudo|su|login)"
        ;;
    security)
        echo "Monitoring security logs (fail2ban, suricata, audit)..."
        sudo tail -f /var/log/fail2ban.log /var/log/suricata/fast.log /var/log/audit/audit.log 2>/dev/null | grep --line-buffered -v "INFO"
        ;;
    system)
        echo "Monitoring system logs..."
        sudo journalctl -f -u ssh -u nginx -u fail2ban -u suricata -u clamav-daemon
        ;;
    nginx)
        echo "Monitoring nginx access and error logs..."
        sudo tail -f /var/log/nginx/access.log /var/log/nginx/error.log 2>/dev/null
        ;;
    all|*)
        echo "Monitoring all system logs..."
        sudo journalctl -f
        ;;
esac
EOF
    
    chmod +x /usr/local/bin/logmon
    
    # Create servermail command (adapted from bastionmail)
    cat > /usr/local/bin/servermail << 'EOF'
#!/bin/bash
# Server Mail Reader - Read local system mail

echo "=== Server Mail Reader ==="
if [ -f /var/mail/root ]; then
    echo "ðŸ“§ Reading local mail for root:"
    echo ""
    tail -50 /var/mail/root
elif [ -f /var/spool/mail/root ]; then
    echo "ðŸ“§ Reading local mail for root:"
    echo ""
    tail -50 /var/spool/mail/root
else
    echo "ðŸ“­ No local mail found for root"
    echo ""
    echo "Mail files checked:"
    echo "  - /var/mail/root"
    echo "  - /var/spool/mail/root"
fi
EOF
    
    chmod +x /usr/local/bin/servermail
    
    echo "âœ… Advanced monitoring tools installed:"
    echo "   â€¢ serverstatus - Comprehensive server health and status report"
    echo "   â€¢ logmon [type] - Real-time log monitoring (auth|security|system|nginx|all)"
    echo "   â€¢ servermail - Read local system mail and notifications"
    echo "   â€¢ All users can run serverstatus and servermail"
    echo "   â€¢ logmon requires sudo for log access"
    echo ""
else
    echo "Skipping advanced monitoring tools installation"
fi

# Unattended Reboot Warning System
echo "Configuring unattended reboot warning system..."
cat > /etc/apt/apt.conf.d/51unattended-upgrades-server << 'EOF'
// Enhanced server configuration for unattended upgrades
Unattended-Upgrade::Automatic-Reboot "true";
Unattended-Upgrade::Automatic-Reboot-WithUsers "false";
Unattended-Upgrade::Automatic-Reboot-Time "04:00";

// Warning system before reboot
Unattended-Upgrade::SyslogEnable "true";
Unattended-Upgrade::SyslogFacility "daemon";
EOF

# Create pre-reboot warning script
cat > /usr/local/bin/unattended-reboot-warning.sh << 'EOF'
#!/bin/bash
# Pre-reboot warning for unattended upgrades

# Check if reboot is required
if [ -f /var/run/reboot-required ]; then
    # Send wall message to all logged in users
    echo "SYSTEM NOTICE: Unattended upgrade requires reboot. System will reboot at 04:00 AM." | wall
    
    # Log to syslog
    logger -p daemon.warning "Server scheduled for automatic reboot due to unattended upgrade"
    
    # Send email notification
    echo "Server $(hostname) is scheduled for automatic reboot at 04:00 AM due to security updates requiring reboot." | \
        mail -s "SERVER NOTICE: Scheduled Reboot Tonight" {{LOGWATCH_EMAIL}}
fi
EOF

chmod +x /usr/local/bin/unattended-reboot-warning.sh

# Add to daily cron to warn users
echo "0 20 * * * root /usr/local/bin/unattended-reboot-warning.sh" >> /etc/crontab

echo "âœ… Unattended reboot warning system configured"

# Suricata Rules Maintenance
echo "Setting up Suricata rules maintenance..."
if command -v suricata-update >/dev/null 2>&1; then
    # Configure suricata-update
    suricata-update update-sources
    suricata-update enable-source et/open
    suricata-update enable-source oisf/trafficid
    
    # Create weekly rules update job
    cat > /etc/cron.weekly/suricata-update << 'EOF'
#!/bin/bash
# Weekly Suricata rules update

# Update rule sources
/usr/bin/suricata-update update-sources

# Update rules
/usr/bin/suricata-update

# Test configuration
if suricata -T -c /etc/suricata/suricata.yaml; then
    # Restart Suricata if config is valid
    systemctl reload suricata || systemctl restart suricata
    logger -p daemon.info "Suricata rules updated successfully"
else
    # Notify of configuration error
    echo "Suricata configuration test failed after rules update on $(hostname)" | \
        mail -s "SERVER ERROR: Suricata Rules Update Failed" {{LOGWATCH_EMAIL}}
    logger -p daemon.error "Suricata rules update failed - configuration test error"
fi
EOF
    
    chmod +x /etc/cron.weekly/suricata-update
    echo "âœ… Suricata rules auto-update configured"
else
    echo "âš ï¸ suricata-update not available - install with: apt install suricata-update"
fi

# Note: SSH cryptographic configuration handled in main SSH config section above

# Systemd Watchdog for Critical Services
echo "Configuring systemd watchdog for critical services..."

# Enhanced fail2ban service with watchdog and resource management
mkdir -p /etc/systemd/system/fail2ban.service.d
cat > /etc/systemd/system/fail2ban.service.d/watchdog.conf << 'EOF'
[Service]
WatchdogSec=60
Restart=on-failure
RestartSec=30
StartLimitInterval=600
StartLimitBurst=2

# Resource management and priority
OOMScoreAdjust=-100
Nice=-5
EOF

# Enhanced Suricata service with watchdog and resource management
mkdir -p /etc/systemd/system/suricata.service.d
cat > /etc/systemd/system/suricata.service.d/watchdog.conf << 'EOF'
[Service]
WatchdogSec=120
Restart=on-failure
RestartSec=30
StartLimitInterval=1200
StartLimitBurst=2

# Resource management - lower priority than critical access services
Nice=5
OOMScoreAdjust=100
EOF

# SSH service watchdog with enhanced security hardening
mkdir -p /etc/systemd/system/ssh.service.d
cat > /etc/systemd/system/ssh.service.d/watchdog.conf << 'EOF'
[Service]
WatchdogSec=30
Restart=on-failure
RestartSec=5
StartLimitInterval=300
StartLimitBurst=5

# Highest priority and OOM protection for SSH access
OOMScoreAdjust=-300
Nice=-8

# NO filesystem protection on SSH service - allows normal system administration
# ProtectSystem causes read-only filesystem issues that break apt, installations, and system management
# Security is provided by network isolation, firewalls, and access controls instead
EOF

# Nginx service watchdog with resource management (if not Docker mode)
if [ "$DEPLOYMENT_MODE" != "docker" ]; then
    mkdir -p /etc/systemd/system/nginx.service.d
    cat > /etc/systemd/system/nginx.service.d/watchdog.conf << 'EOF'
[Service]
WatchdogSec=30
Restart=on-failure
RestartSec=5
StartLimitInterval=300
StartLimitBurst=5

# Resource management for web server
Nice=0
OOMScoreAdjust=50

# Security hardening for web server
PrivateTmp=yes
ReadWritePaths=/var/log/nginx /var/cache/nginx /run
EOF
fi

systemctl daemon-reload
echo "âœ… Enhanced systemd watchdog and resource management configured for critical services"
echo "   â€¢ SSH: Highest priority (OOM -300, Nice -8) with security hardening"
echo "   â€¢ fail2ban: High priority (OOM -100, Nice -5) for security protection"
echo "   â€¢ Suricata: Medium priority (OOM +100, Nice +5) for network monitoring"
if [ "$DEPLOYMENT_MODE" != "docker" ]; then
echo "   â€¢ Nginx: Standard priority (OOM +50, Nice 0) with security hardening"
fi

# Daily Security Configuration Backup
echo "Setting up daily security configuration backup..."
cat > /etc/cron.daily/security-config-backup << 'EOF'
#!/bin/bash
# Daily backup of critical security configurations

BACKUP_DIR="/var/backups/security-configs"
DATE=$(date +%Y%m%d)
BACKUP_FILE="$BACKUP_DIR/security-config-$DATE.tar.gz"

# Create backup directory
mkdir -p "$BACKUP_DIR"

# Create comprehensive backup
tar -czf "$BACKUP_FILE" \
    /etc/fail2ban \
    /etc/suricata \
    /etc/ssh \
    /etc/audit \
    /etc/ufw \
    /etc/apparmor.d \
    /etc/nginx \
    /etc/cron.d \
    /etc/cron.daily \
    /etc/cron.hourly \
    /etc/cron.weekly \
    /etc/systemd/system \
    /var/lib/security/baselines \
    /etc/security-status.conf \
    /etc/logrotate.d \
    2>/dev/null

# Verify backup
if [ -f "$BACKUP_FILE" ]; then
    # Check backup integrity
    if tar -tzf "$BACKUP_FILE" >/dev/null 2>&1; then
        logger -p daemon.info "Security configuration backup completed: $BACKUP_FILE"
        
        # Keep only last 30 days of backups
        find "$BACKUP_DIR" -name "security-config-*.tar.gz" -mtime +30 -delete
        
        # Report backup size
        BACKUP_SIZE=$(du -h "$BACKUP_FILE" | cut -f1)
        echo "Security configuration backup completed: $BACKUP_SIZE ($BACKUP_FILE)" >> /var/log/backup.log
    else
        logger -p daemon.error "Security configuration backup corrupted: $BACKUP_FILE"
        echo "BACKUP ERROR: Security configuration backup corrupted on $(hostname)" | \
            mail -s "SERVER ERROR: Backup Failure" {{LOGWATCH_EMAIL}}
    fi
else
    logger -p daemon.error "Security configuration backup failed"
    echo "BACKUP ERROR: Security configuration backup failed on $(hostname)" | \
        mail -s "SERVER ERROR: Backup Failure" {{LOGWATCH_EMAIL}}
fi

# Quick integrity check of critical configs
for config in /etc/ssh/sshd_config /etc/suricata/suricata.yaml /etc/fail2ban/jail.local /etc/nginx/nginx.conf; do
    if [ -f "$config" ]; then
        case "$config" in
            */sshd_config)
                sshd -t 2>/dev/null || echo "WARNING: SSH config validation failed" >> /var/log/backup.log
                ;;
            */suricata.yaml)
                suricata -T -c "$config" >/dev/null 2>&1 || echo "WARNING: Suricata config validation failed" >> /var/log/backup.log
                ;;
            */jail.local)
                fail2ban-client -t >/dev/null 2>&1 || echo "WARNING: Fail2ban config validation failed" >> /var/log/backup.log
                ;;
            */nginx.conf)
                nginx -t >/dev/null 2>&1 || echo "WARNING: Nginx config validation failed" >> /var/log/backup.log
                ;;
        esac
    fi
done
EOF

chmod +x /etc/cron.daily/security-config-backup

# Run initial backup
echo "Creating initial security configuration backup..."
/etc/cron.daily/security-config-backup

echo "âœ… Daily security configuration backup system configured"
echo ""
echo "Advanced security refinements completed:"
echo "   â€¢ AppArmor profile enforcement verification and custom profiles (SSH + Nginx)"
if [[ ${REPLY:-} =~ ^[Yy]$ ]]; then
echo "   â€¢ Resource Guardian system for proactive resource management (optional)"
fi
if [[ ${MONITORING_TOOLS_REPLY:-} =~ ^[Yy]$ ]]; then
echo "   â€¢ Advanced monitoring commands: serverstatus, logmon, servermail (optional)"
fi
echo "   â€¢ Unattended reboot warning system (wall messages + email alerts)"
echo "   â€¢ Suricata rules maintenance with weekly auto-updates"
echo "   â€¢ Enhanced OpenSSH HMAC tuning (SHA-1 completely disabled)"
echo "   â€¢ Enhanced systemd resource management with priority scheduling and security hardening"
echo "   â€¢ Daily automated backup of all security configurations"
if [ "$NETDATA_ENABLED" = "true" ]; then
    echo "   â€¢ Netdata monitoring with optional Cloud integration"
fi
echo ""
echo "Configuration backup location: /var/backups/security-configs/"
echo "Backup retention: 30 days"

echo "===== 16. Optional Application Components ====="
echo "Choose which application components to install for your server:"
echo ""

# Optional component installation section
INSTALL_COMPONENTS=""

# Docker (Enhanced Installation)
if [ "$DEPLOYMENT_MODE" != "docker" ]; then
    echo ""
    read -p "Install/Configure Docker with security optimizations? (y/N): " -n 1 -r
    echo
    if [[ $REPLY =~ ^[Yy]$ ]]; then
        INSTALL_COMPONENTS="$INSTALL_COMPONENTS docker"
    fi
fi

# Web Servers
echo ""
echo "=== Web Server Options ==="
read -p "Install Nginx Unit (modern application server)? (y/N): " -n 1 -r
echo
if [[ $REPLY =~ ^[Yy]$ ]]; then
    INSTALL_COMPONENTS="$INSTALL_COMPONENTS nginx-unit"
fi

# PHP Stack
echo ""
echo "=== PHP Development Stack ==="
read -p "Install PHP 8.4 with php-fpm and common extensions? (y/N): " -n 1 -r
echo
if [[ $REPLY =~ ^[Yy]$ ]]; then
    INSTALL_COMPONENTS="$INSTALL_COMPONENTS php"
    read -p "Include PHP development tools (Composer, Xdebug)? (y/N): " -n 1 -r
    echo
    if [[ $REPLY =~ ^[Yy]$ ]]; then
        INSTALL_COMPONENTS="$INSTALL_COMPONENTS php-dev"
    fi
fi

# Database Systems
echo ""
echo "=== Database Systems ==="
read -p "Install MariaDB with secure configuration? (y/N): " -n 1 -r
echo
if [[ $REPLY =~ ^[Yy]$ ]]; then
    INSTALL_COMPONENTS="$INSTALL_COMPONENTS mariadb"
fi

read -p "Install PostgreSQL with secure configuration? (y/N): " -n 1 -r
echo
if [[ $REPLY =~ ^[Yy]$ ]]; then
    INSTALL_COMPONENTS="$INSTALL_COMPONENTS postgresql"
fi

# Node.js Stack
echo ""
echo "=== Node.js Development Stack ==="
read -p "Install Node.js with PM2 process manager? (y/N): " -n 1 -r
echo
if [[ $REPLY =~ ^[Yy]$ ]]; then
    INSTALL_COMPONENTS="$INSTALL_COMPONENTS nodejs"
    read -p "Include development tools (Yarn, TypeScript)? (y/N): " -n 1 -r
    echo
    if [[ $REPLY =~ ^[Yy]$ ]]; then
        INSTALL_COMPONENTS="$INSTALL_COMPONENTS nodejs-dev"
    fi
fi

# Caching and Additional Services
echo ""
echo "=== Caching and Additional Services ==="
read -p "Install Redis with secure configuration? (y/N): " -n 1 -r
echo
if [[ $REPLY =~ ^[Yy]$ ]]; then
    INSTALL_COMPONENTS="$INSTALL_COMPONENTS redis"
fi

read -p "Install Git with optimized configuration? (y/N): " -n 1 -r
echo
if [[ $REPLY =~ ^[Yy]$ ]]; then
    INSTALL_COMPONENTS="$INSTALL_COMPONENTS git"
fi

# Display selected components
if [ -n "$INSTALL_COMPONENTS" ]; then
    echo ""
    echo "Selected components: $INSTALL_COMPONENTS"
    echo ""
    read -p "Proceed with installation? (y/N): " -n 1 -r
    echo
    if [[ $REPLY =~ ^[Yy]$ ]]; then
        echo "===== 16.1 Installing Selected Components ====="
        # Component installation will be implemented next
        for component in $INSTALL_COMPONENTS; do
            echo "Installing $component..."
            case $component in
                docker)
                    echo "===== 16.1.1 Installing Docker with Security Optimizations ====="
                    echo "Using Docker CE from docker.com (more current than official Debian docker.io package)"
                    
                    # Remove any existing Docker packages
                    apt-get remove -y docker docker-engine docker.io containerd runc 2>/dev/null || true
                    
                    # Install Docker prerequisites
                    apt-get update
                    apt-get install -y ca-certificates curl software-properties-common
                    
                    # Add Docker's official GPG key
                    install -m 0755 -d /etc/apt/keyrings
                    curl -fsSL https://download.docker.com/linux/debian/gpg | gpg --dearmor -o /etc/apt/keyrings/docker.gpg
                    chmod a+r /etc/apt/keyrings/docker.gpg
                    
                    # Add Docker repository
                    echo "deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/debian $(lsb_release -cs) stable" | tee /etc/apt/sources.list.d/docker.list > /dev/null
                    
                    apt-get update
                    apt-get install -y docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin
                    
                    # Create secure Docker daemon configuration
                    mkdir -p /etc/docker
                    cat > /etc/docker/daemon.json << 'DOCKER_EOF'
{
    "log-driver": "journald",
    "log-opts": {
        "max-size": "100m",
        "max-file": "3"
    },
    "storage-driver": "overlay2",
    "userland-proxy": false,
    "no-new-privileges": true,
    "live-restore": true,
    "default-ulimits": {
        "nofile": {
            "hard": 100000,
            "soft": 100000
        },
        "memlock": {
            "hard": -1,
            "soft": -1
        }
    },
    "security-opts": ["no-new-privileges:true"],
    "icc": false,
    "default-address-pools": [
        {
            "base": "172.30.0.0/16",
            "size": 24
        }
    ]
}
DOCKER_EOF
                    
                    # Create secure Docker service drop-in
                    mkdir -p /etc/systemd/system/docker.service.d
                    cat > /etc/systemd/system/docker.service.d/security.conf << 'DOCKER_EOF'
[Service]
# Security hardening
NoNewPrivileges=true
ProtectKernelTunables=true
ProtectKernelModules=true
ProtectControlGroups=true
RestrictRealtime=true
RestrictSUIDSGID=true
MemoryDenyWriteExecute=true
RestrictNamespaces=true

# Resource limits
LimitNOFILE=1048576
LimitNPROC=1048576

# OOM handling
OOMScoreAdjust=100
DOCKER_EOF
                    
                    # Add user to docker group if not already there
                    if ! groups {{USERNAME}} | grep -q docker; then
                        usermod -aG docker {{USERNAME}}
                        echo "Added {{USERNAME}} to docker group"
                    fi
                    
                    # Enable and start Docker
                    systemctl daemon-reload
                    systemctl enable docker
                    systemctl restart docker
                    
                    # Wait for Docker to be ready
                    sleep 5
                    
                    # Test Docker installation
                    if docker version >/dev/null 2>&1; then
                        echo "âœ… Docker installed and configured with security optimizations"
                        docker version | head -20
                    else
                        echo "âŒ Docker installation failed"
                    fi
                    ;;
                nginx-unit)
                    echo "===== 16.1.2 Installing Nginx Unit ====="
                    
                    # Add Nginx Unit repository
                    curl -fsSL https://nginx.org/keys/nginx_signing.key | gpg --dearmor -o /etc/apt/keyrings/nginx-unit.gpg
                    echo "deb [signed-by=/etc/apt/keyrings/nginx-unit.gpg] https://packages.nginx.org/unit/debian/ $(lsb_release -cs) unit" > /etc/apt/sources.list.d/unit.list
                    echo "deb-src [signed-by=/etc/apt/keyrings/nginx-unit.gpg] https://packages.nginx.org/unit/debian/ $(lsb_release -cs) unit" >> /etc/apt/sources.list.d/unit.list
                    
                    apt-get update
                    
                    # Install Nginx Unit and modules
                    apt-get install -y unit unit-dev unit-php unit-python3.11 unit-go unit-jsc unit-perl
                    
                    # Create initial Nginx Unit configuration
                    mkdir -p /etc/unit
                    cat > /etc/unit/initial-config.json << 'UNIT_EOF'
{
    "settings": {
        "http": {
            "header_read_timeout": 30,
            "body_read_timeout": 30,
            "send_timeout": 30,
            "idle_timeout": 180,
            "max_body_size": 8388608,
            "static": {
                "mime_types": {
                    "text/plain": [
                        ".log",
                        ".md",
                        ".txt"
                    ],
                    "application/javascript": [
                        ".js"
                    ],
                    "text/css": [
                        ".css"
                    ],
                    "text/html": [
                        ".html",
                        ".htm"
                    ]
                }
            }
        }
    },
    "listeners": {
        "127.0.0.1:8080": {
            "pass": "routes"
        }
    },
    "routes": [
        {
            "match": {
                "uri": "/status"
            },
            "action": {
                "return": 200
            }
        }
    ]
}
UNIT_EOF
                    
                    # Create systemd override for Unit with security hardening
                    mkdir -p /etc/systemd/system/unit.service.d
                    cat > /etc/systemd/system/unit.service.d/security.conf << 'UNIT_EOF'
[Service]
# Security hardening
NoNewPrivileges=true
PrivateTmp=true
ProtectSystem=strict
ProtectHome=true
ReadWritePaths=/var/lib/unit /var/log/unit /run/unit
RestrictRealtime=true
RestrictSUIDSGID=true

# Resource management
Nice=0
OOMScoreAdjust=50
LimitNOFILE=65536
LimitNPROC=4096

# Restart policy
Restart=on-failure
RestartSec=5
StartLimitBurst=3
StartLimitInterval=300
UNIT_EOF
                    
                    # Enable and start Nginx Unit
                    systemctl daemon-reload
                    systemctl enable unit
                    systemctl start unit
                    
                    # Wait for Unit to be ready
                    sleep 3
                    
                    # Apply initial configuration
                    curl -X PUT --data-binary @/etc/unit/initial-config.json --unix-socket /var/run/unit/control.sock http://localhost/config/ 2>/dev/null || true
                    
                    # Test Nginx Unit installation
                    if systemctl is-active --quiet unit; then
                        echo "âœ… Nginx Unit installed and configured"
                        echo "   â€¢ Control socket: /var/run/unit/control.sock"
                        echo "   â€¢ Status endpoint: http://127.0.0.1:8080/status"
                        echo "   â€¢ Configuration: curl --unix-socket /var/run/unit/control.sock http://localhost/config/"
                    else
                        echo "âŒ Nginx Unit installation failed"
                    fi
                    ;;
                php)
                    echo "===== 16.1.3 Installing PHP 8.4 with php-fpm ====="
                    echo "Using official Debian 13 repositories (PHP 8.4 is default)"
                    
                    apt-get update
                    
                    # Install PHP 8.4 and essential extensions from official Debian repositories
                    apt-get install -y \
                        php8.4-fpm \
                        php8.4-cli \
                        php8.4-common \
                        php8.4-curl \
                        php8.4-gd \
                        php8.4-intl \
                        php8.4-mbstring \
                        php8.4-mysql \
                        php8.4-opcache \
                        php8.4-pgsql \
                        php8.4-redis \
                        php8.4-sqlite3 \
                        php8.4-xml \
                        php8.4-zip \
                        php8.4-bcmath \
                        php8.4-bz2 \
                        php8.4-imagick \
                        php8.4-imap \
                        php8.4-soap \
                        php8.4-ssh2 \
                        php8.4-uuid \
                        php8.4-yaml
                    
                    # Configure PHP-FPM pool with security optimizations
                    cat > /etc/php/8.4/fpm/pool.d/security.conf << 'PHP_EOF'
[security]
user = {{USERNAME}}
group = {{USERNAME}}
listen = /run/php/php8.4-fpm-security.sock
listen.owner = www-data
listen.group = www-data
listen.mode = 0660

; Process management
pm = dynamic
pm.max_children = 20
pm.start_servers = 2
pm.min_spare_servers = 1
pm.max_spare_servers = 3
pm.max_requests = 1000

; Security settings
php_admin_value[disable_functions] = exec,passthru,shell_exec,system,proc_open,popen,curl_exec,curl_multi_exec,parse_ini_file,show_source
php_admin_value[open_basedir] = /var/www:/tmp:/var/lib/php/sessions:/dev/urandom
php_admin_value[allow_url_fopen] = Off
php_admin_value[allow_url_include] = Off
php_admin_value[expose_php] = Off
php_admin_value[log_errors] = On
php_admin_value[error_log] = /var/log/php8.4-fpm-security.log

; Resource limits
php_admin_value[memory_limit] = 256M
php_admin_value[max_execution_time] = 60
php_admin_value[max_input_time] = 60
php_admin_value[post_max_size] = 32M
php_admin_value[upload_max_filesize] = 32M
php_admin_value[max_file_uploads] = 20

; Session security
php_admin_value[session.cookie_httponly] = On
php_admin_value[session.cookie_secure] = On
php_admin_value[session.use_strict_mode] = On
php_admin_value[session.cookie_samesite] = Strict
php_admin_value[session.save_path] = /var/lib/php/sessions
PHP_EOF
                    
                    # Create production-ready PHP configuration
                    cat > /etc/php/8.4/fpm/conf.d/99-security.ini << 'PHP_EOF'
; Security enhancements
expose_php = Off
allow_url_fopen = Off
allow_url_include = Off
display_errors = Off
display_startup_errors = Off
log_errors = On
error_reporting = E_ALL & ~E_DEPRECATED & ~E_STRICT

; Resource limits
memory_limit = 256M
max_execution_time = 60
max_input_time = 60
post_max_size = 32M
upload_max_filesize = 32M
max_file_uploads = 20

; OPcache optimization
opcache.enable = 1
opcache.enable_cli = 0
opcache.memory_consumption = 128
opcache.interned_strings_buffer = 8
opcache.max_accelerated_files = 4000
opcache.revalidate_freq = 2
opcache.fast_shutdown = 1
opcache.validate_timestamps = 1

; Session security
session.cookie_httponly = On
session.cookie_secure = On
session.use_strict_mode = On
session.cookie_samesite = "Strict"
session.gc_maxlifetime = 1440
session.gc_probability = 1
session.gc_divisor = 1000
PHP_EOF
                    
                    # Create systemd override for php-fpm with security hardening
                    mkdir -p /etc/systemd/system/php8.4-fpm.service.d
                    cat > /etc/systemd/system/php8.4-fpm.service.d/security.conf << 'PHP_EOF'
[Service]
# Security hardening
NoNewPrivileges=true
PrivateTmp=true
ProtectSystem=strict
ProtectHome=true
ReadWritePaths=/var/www /var/log /var/lib/php /run/php /tmp
RestrictRealtime=true
RestrictSUIDSGID=true

# Resource management
Nice=0
OOMScoreAdjust=50
LimitNOFILE=65536
LimitNPROC=1024

# Restart policy
Restart=on-failure
RestartSec=5
StartLimitBurst=3
StartLimitInterval=300
PHP_EOF
                    
                    # Enable and start PHP-FPM
                    systemctl daemon-reload
                    systemctl enable php8.4-fpm
                    systemctl restart php8.4-fpm
                    
                    # Create web directory and set permissions
                    mkdir -p /var/www/html
                    chown {{USERNAME}}:{{USERNAME}} /var/www/html
                    
                    # Create PHP info file for testing
                    cat > /var/www/html/info.php << 'PHP_EOF'
<?php
// Remove this file in production!
echo "<h1>PHP Configuration</h1>\n";
echo "<p>PHP Version: " . PHP_VERSION . "</p>\n";
echo "<p>Server: " . $_SERVER['SERVER_NAME'] . "</p>\n";
echo "<p>Document Root: " . $_SERVER['DOCUMENT_ROOT'] . "</p>\n";
echo "<h2>Loaded Extensions</h2>\n<ul>\n";
foreach (get_loaded_extensions() as $ext) {
    echo "<li>$ext</li>\n";
}
echo "</ul>\n";
?>
PHP_EOF
                    
                    # Test PHP-FPM installation
                    if systemctl is-active --quiet php8.4-fpm; then
                        echo "âœ… PHP 8.4 with php-fpm installed and configured"
                        echo "   â€¢ Version: $(php -v | head -1)"
                        echo "   â€¢ FPM Socket: /run/php/php8.4-fpm-security.sock"
                        echo "   â€¢ Web Directory: /var/www/html"
                        echo "   â€¢ Configuration: /etc/php/8.4/fpm/"
                        echo "   â€¢ Test file: /var/www/html/info.php (remove in production!)"
                    else
                        echo "âŒ PHP-FPM installation failed"
                    fi
                    ;;
                php-dev)
                    echo "===== 16.1.4 Installing PHP Development Tools ====="
                    
                    # Install additional PHP development packages
                    apt-get install -y php8.4-xdebug php8.4-dev php-pear build-essential
                    
                    # Install Composer
                    cd /tmp
                    curl -sS https://getcomposer.org/installer -o /tmp/composer-setup.php
                    php /tmp/composer-setup.php --install-dir=/usr/local/bin --filename=composer
                    chmod +x /usr/local/bin/composer
                    
                    # Configure Xdebug for development (disabled by default for performance)
                    cat > /etc/php/8.4/mods-available/xdebug.ini << 'XDEBUG_EOF'
; Xdebug configuration (disabled by default for production performance)
; Enable with: phpenmod xdebug
; Disable with: phpdismod xdebug

zend_extension=xdebug.so
xdebug.mode=develop,debug
xdebug.start_with_request=trigger
xdebug.client_host=127.0.0.1
xdebug.client_port=9003
xdebug.log=/var/log/xdebug.log
xdebug.max_nesting_level=256
xdebug.var_display_max_children=128
xdebug.var_display_max_data=512
xdebug.var_display_max_depth=3
XDEBUG_EOF
                    
                    # Disable Xdebug by default for performance
                    phpdismod xdebug
                    
                    # Test Composer installation
                    if command -v composer >/dev/null 2>&1; then
                        echo "âœ… PHP development tools installed"
                        echo "   â€¢ Composer version: $(composer --version)"
                        echo "   â€¢ Xdebug available (disabled by default for performance)"
                        echo "   â€¢ Enable Xdebug: phpenmod xdebug && systemctl reload php8.4-fpm"
                        echo "   â€¢ Disable Xdebug: phpdismod xdebug && systemctl reload php8.4-fpm"
                    else
                        echo "âŒ PHP development tools installation failed"
                    fi
                    ;;
                mariadb)
                    echo "===== 16.1.5 Installing MariaDB with Secure Configuration ====="
                    apt-get install -y mariadb-server mariadb-client
                    
                    # Secure MariaDB installation automatically
                    mysql_secure_installation --defaults <<EOF || true

y
{{DB_ROOT_PASSWORD:-$(openssl rand -base64 32)}}
{{DB_ROOT_PASSWORD:-$(openssl rand -base64 32)}}
y
y
y
y
EOF
                    
                    # Configure MariaDB for security
                    cat >> /etc/mysql/mariadb.conf.d/99-security.cnf << 'MARIADB_EOF'
[mysqld]
# Security settings
bind-address = 127.0.0.1
local-infile = 0
symbolic-links = 0
secure-file-priv = "/var/lib/mysql-files/"

# Performance and resource limits (calculated based on system resources)
max_connections = $DB_MAX_CONNECTIONS
max_user_connections = $((DB_MAX_CONNECTIONS / 2))
table_open_cache = 2000
innodb_buffer_pool_size = ${INNODB_BUFFER_POOL_MB}M
query_cache_size = ${QUERY_CACHE_SIZE}M
query_cache_limit = 2M
MARIADB_EOF
                    
                    systemctl restart mariadb
                    echo "âœ… MariaDB installed with secure defaults"
                    ;;
                postgresql)
                    echo "===== 16.1.6 Installing PostgreSQL with Secure Configuration ====="
                    apt-get install -y postgresql postgresql-contrib postgresql-client
                    
                    # Configure PostgreSQL for security
                    sudo -u postgres psql -c "ALTER USER postgres PASSWORD '{{DB_PG_PASSWORD:-$(openssl rand -base64 32)}}';"
                    
                    # Update pg_hba.conf for security
                    sed -i "s/#listen_addresses = 'localhost'/listen_addresses = 'localhost'/" /etc/postgresql/*/main/postgresql.conf
                    sed -i "s/local   all             all                                     peer/local   all             all                                     md5/" /etc/postgresql/*/main/pg_hba.conf
                    
                    # Add performance tuning to postgresql.conf
                    cat >> /etc/postgresql/*/main/postgresql.conf << 'POSTGRESQL_EOF'

# Performance tuning (calculated based on system resources)
max_connections = $DB_MAX_CONNECTIONS
shared_buffers = ${INNODB_BUFFER_POOL_MB}MB
effective_cache_size = $((TOTAL_RAM_MB * 75 / 100))MB
maintenance_work_mem = $((TOTAL_RAM_MB / 16))MB
checkpoint_completion_target = 0.9
wal_buffers = 16MB
default_statistics_target = 100
random_page_cost = 1.1
POSTGRESQL_EOF
                    
                    systemctl restart postgresql
                    echo "âœ… PostgreSQL installed with secure defaults"
                    ;;
                nodejs)
                    echo "===== 16.1.7 Installing Node.js with PM2 ====="
                    echo "Using official NodeSource repository (Node.js 22.x LTS - current active LTS)"
                    
                    # Add NodeSource repository for current LTS (v22)
                    curl -fsSL https://deb.nodesource.com/setup_lts.x | bash -
                    
                    # Install Node.js from NodeSource (gets current LTS v22)
                    apt-get install -y nodejs
                    
                    # Install PM2 globally
                    npm install -g pm2
                    
                    # Configure PM2 startup
                    sudo -u {{USERNAME}} pm2 startup systemd -u {{USERNAME}} --hp /home/{{USERNAME}}
                    
                    # Create optimized PM2 ecosystem template
                    cat > /home/{{USERNAME}}/ecosystem.config.js << "PM2_EOF"
module.exports = {
  apps: [{
    name: 'app',
    script: './app.js',
    instances: $PM2_INSTANCES,
    exec_mode: 'cluster',
    env: {
      NODE_ENV: 'production',
      PORT: 3000
    }
  }]
};
PM2_EOF
                    chown {{USERNAME}}:{{USERNAME}} /home/{{USERNAME}}/ecosystem.config.js
                    
                    echo "âœ… Node.js and PM2 installed from NodeSource (current LTS)"
                    echo "   â€¢ Node.js version: $(node --version)"
                    echo "   â€¢ NPM version: $(npm --version)"
                    echo "   â€¢ PM2 version: $(pm2 --version)"
                    echo "   â€¢ Using NodeSource for latest LTS security updates"
                    ;;
                nodejs-dev)
                    echo "===== 16.1.8 Installing Node.js Development Tools ====="
                    echo "Installing Yarn from official Yarn repository (maintains standard 'yarn' command)"
                    
                    # Add official Yarn repository to maintain 'yarn' command compatibility
                    curl -fsSL https://dl.yarnpkg.com/debian/pubkey.gpg | gpg --dearmor -o /usr/share/keyrings/yarn-archive-keyring.gpg
                    echo "deb [signed-by=/usr/share/keyrings/yarn-archive-keyring.gpg] https://dl.yarnpkg.com/debian stable main" > /etc/apt/sources.list.d/yarn.list
                    
                    # Install Yarn (external repo needed to maintain 'yarn' command)
                    apt-get update
                    apt-get install -y yarn
                    
                    # Install global development tools
                    npm install -g typescript @types/node nodemon eslint prettier
                    
                    echo "âœ… Node.js development tools installed"
                    echo "   â€¢ Yarn version: $(yarn --version)"
                    echo "   â€¢ TypeScript version: $(tsc --version)"
                    echo "   â€¢ Note: Standard 'yarn' command available (deployment-friendly)"
                    ;;
                redis)
                    echo "===== 16.1.9 Installing Redis with Secure Configuration ====="
                    apt-get install -y redis-server
                    
                    # Configure Redis for security and performance (calculated based on system resources)
                    sed -i "s/^# requirepass foobared/requirepass {{REDIS_PASSWORD:-\$(openssl rand -base64 32)}}/" /etc/redis/redis.conf
                    sed -i 's/^bind 127.0.0.1 ::1/bind 127.0.0.1/' /etc/redis/redis.conf
                    sed -i "s/^# maxmemory <bytes>/maxmemory ${REDIS_MAXMEMORY}mb/" /etc/redis/redis.conf
                    sed -i 's/^# maxmemory-policy noeviction/maxmemory-policy allkeys-lru/' /etc/redis/redis.conf
                    
                    systemctl restart redis-server
                    echo "âœ… Redis installed with secure configuration"
                    ;;
                git)
                    echo "===== 16.1.10 Installing Git with Optimized Configuration ====="
                    apt-get install -y git
                    
                    # Create optimized global Git configuration
                    cat > /etc/gitconfig << 'GIT_EOF'
[init]
    defaultBranch = main

[core]
    editor = nano
    autocrlf = input
    safecrlf = true
    filemode = true

[push]
    default = simple
    autoSetupRemote = true

[pull]
    rebase = false

[color]
    ui = auto

[alias]
    st = status
    co = checkout
    br = branch
    ci = commit
    df = diff
    lg = log --oneline --graph --decorate --all
GIT_EOF
                    
                    echo "âœ… Git installed with optimized configuration"
                    echo "   â€¢ Version: $(git --version)"
                    ;;
                *)
                    echo "Unknown component: $component"
                    ;;
            esac
        done
        echo "âœ… Component installation completed"
    else
        echo "Skipping component installation"
    fi
else
    echo "No additional components selected"
fi

echo "===== 17. Final configuration validation ====="
log_message "Performing final configuration validation..."

if validate_critical_configs; then
    log_message "âœ… All critical configurations validated successfully"
else
    log_error "âš ï¸ Some configuration validation issues detected"
    log_message "Check $LOG_FILE for details"
fi

echo "===== 17. Advanced Configuration Options ====="
log_message "Prompting for optional advanced settings"

# Define environment file for configuration updates
ENV_FILE="/opt/polyserver/config/defaults.env"

# Function to prompt for optional advanced settings
prompt_advanced_settings() {
    echo ""
    echo "ðŸš€ Advanced Configuration Options"
    echo "The following settings can help with debugging and monitoring in production:"
    echo ""
    
    # PHP slow log setting
    echo "ðŸ“ PHP Slow Query Logging:"
    echo "   â€¢ Logs PHP scripts that take longer than threshold (useful for performance debugging)"
    echo "   â€¢ Minimal performance impact, helps identify bottlenecks"
    echo "   â€¢ Recommended for production to catch performance issues"
    echo ""
    read -p "Enable PHP slow query logging? (Y/n): " -n 1 -r
    echo
    if [[ ! $REPLY =~ ^[Nn]$ ]]; then
        sed -i "s/PHP_SLOW_LOG_ENABLED=false/PHP_SLOW_LOG_ENABLED=true/" "$ENV_FILE" 2>/dev/null || true
        log_message "PHP slow query logging enabled"
        echo "âœ… PHP slow query logging enabled (threshold: 10 seconds)"
    fi
    
    # MySQL slow query log
    echo ""
    echo "ðŸ“Š MySQL/MariaDB Slow Query Logging:"
    echo "   â€¢ Logs database queries that take longer than threshold"
    echo "   â€¢ Essential for database performance optimization"
    echo "   â€¢ Very low performance impact, highly recommended"
    echo ""
    read -p "Enable MySQL slow query logging? (Y/n): " -n 1 -r
    echo
    if [[ ! $REPLY =~ ^[Nn]$ ]]; then
        sed -i "s/MYSQL_SLOW_LOG_ENABLED=true/MYSQL_SLOW_LOG_ENABLED=true/" "$ENV_FILE" 2>/dev/null || true
        log_message "MySQL slow query logging enabled"
        echo "âœ… MySQL slow query logging enabled (threshold: 2 seconds)"
    fi
    
    # Redis slow log
    echo ""
    echo "âš¡ Redis Slow Query Logging:"
    echo "   â€¢ Logs Redis commands that take longer than threshold"
    echo "   â€¢ Helps identify cache performance issues"
    echo "   â€¢ Very lightweight monitoring feature"
    echo ""
    read -p "Enable Redis slow query logging? (Y/n): " -n 1 -r
    echo
    if [[ ! $REPLY =~ ^[Nn]$ ]]; then
        sed -i "s/REDIS_SLOW_LOG_ENABLED=true/REDIS_SLOW_LOG_ENABLED=true/" "$ENV_FILE" 2>/dev/null || true
        log_message "Redis slow query logging enabled"
        echo "âœ… Redis slow query logging enabled (threshold: 10ms)"
    fi
    
    # PHP OPcache advanced settings
    echo ""
    echo "ðŸ”§ PHP OPcache Optimization:"
    echo "   â€¢ Enables advanced PHP bytecode caching for better performance"
    echo "   â€¢ Reduces CPU usage and improves response times"
    echo "   â€¢ Uses ~128MB RAM for caching compiled PHP code"
    echo ""
    read -p "Enable PHP OPcache optimization? (Y/n): " -n 1 -r
    echo
    if [[ ! $REPLY =~ ^[Nn]$ ]]; then
        sed -i "s/PHP_OPCACHE_ENABLED=true/PHP_OPCACHE_ENABLED=true/" "$ENV_FILE" 2>/dev/null || true
        log_message "PHP OPcache optimization enabled"
        echo "âœ… PHP OPcache optimization enabled"
    fi
    
    # Request termination timeout for PHP
    echo ""
    echo "â±ï¸ PHP Request Termination Timeout:"
    echo "   â€¢ Automatically kills long-running PHP processes"
    echo "   â€¢ Prevents resource exhaustion from runaway scripts"
    echo "   â€¢ Recommended for production to ensure stability"
    echo ""
    read -p "Enable PHP request termination timeout (600s)? (Y/n): " -n 1 -r
    echo
    if [[ ! $REPLY =~ ^[Nn]$ ]]; then
        sed -i "s/PHP_REQUEST_TERMINATE_TIMEOUT=\"\"/PHP_REQUEST_TERMINATE_TIMEOUT=\"600\"/" "$ENV_FILE" 2>/dev/null || true
        log_message "PHP request termination timeout enabled"
        echo "âœ… PHP request termination timeout enabled (600 seconds)"
    fi
    
    echo ""
    echo "ðŸŽ¯ Advanced settings configuration completed"
    echo "All settings can be modified later in: $ENV_FILE"
}

# Only prompt for advanced settings if not in automated mode
if [ -z "$AUTOMATED_INSTALL" ]; then
    prompt_advanced_settings
else
    log_message "Skipping advanced settings prompt in automated mode"
fi

echo "===== 18. Setup complete! ====="
log_message "Server setup completed successfully"
echo "Server has been secured and Docker installed."
echo "IMPORTANT: SSH is now running on port $SSH_PORT"
echo "Use the following command to connect: ssh -p $SSH_PORT $USERNAME@your-server-ip"
echo ""
echo ""
echo "ðŸ“Š System Resource Optimization Applied:"
if [ -n "$NGINX_WORKERS" ] && [ "$NGINX_WORKERS" != "auto" ]; then
    echo "   â€¢ Nginx: $NGINX_WORKERS workers, $NGINX_WORKER_CONNECTIONS connections each"
fi
if [ -n "$PHP_MAX_CHILDREN" ]; then
    echo "   â€¢ PHP-FPM: Up to $PHP_MAX_CHILDREN processes, ${PHP_MEMORY_LIMIT}MB memory limit per process"
fi
if [ -n "$MYSQL_INNODB_BUFFER_POOL_SIZE" ]; then
    echo "   â€¢ MariaDB: ${MYSQL_INNODB_BUFFER_POOL_SIZE}MB InnoDB buffer pool, $MYSQL_MAX_CONNECTIONS max connections"
fi
if [ -n "$REDIS_MAX_MEMORY" ]; then
    echo "   â€¢ Redis: ${REDIS_MAX_MEMORY}MB max memory, $REDIS_MAX_CLIENTS max clients"
fi
echo ""
echo "ðŸ“ Configuration templates available for deployment:"
if [ "$WEB_SERVER_TYPE" = "unit" ]; then
    echo "   â€¢ NGINX Unit: templates/unit/ (high-performance application server)"
    echo "   â€¢ PHP 8.4: templates/php/ (optimized for ${TOTAL_RAM_MB}MB RAM)"
else
    echo "   â€¢ Nginx: templates/nginx/ (optimized for $CPU_CORES cores)"
    echo "   â€¢ PHP 8.4: templates/php/ (optimized for ${TOTAL_RAM_MB}MB RAM)"
fi
echo "   â€¢ MariaDB: templates/mariadb/ (production-ready settings)"
echo "   â€¢ Redis: templates/redis/ (security-hardened)"
echo ""
echo "Next steps:"
echo "1. Edit /etc/dsgvo/contacts.conf to add your DPO contact information"
echo "2. Complete /etc/dsgvo/data_inventory.json with your actual data"
echo "3. Run compliance check: /opt/polyserver/scripts/dsgvo-compliance-check.sh"
if [ "$NETDATA_ENABLED" = "true" ]; then
    echo "4. Access Netdata dashboard: ssh -L 19999:127.0.0.1:19999 {{USERNAME}}@server"
    echo "5. Add to Netdata Cloud (optional): run 'netdata-access' for instructions"
    echo "6. Deploy your applications using the optimized configuration templates"
else
    echo "4. Deploy your applications using the optimized configuration templates"
fi
